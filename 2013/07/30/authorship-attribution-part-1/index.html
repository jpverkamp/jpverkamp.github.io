<!doctype html><html><head><title>Authorship attribution: Part 1 – jverkamp.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=utf-8><link rel=alternate type=application/atom+xml title="jverkamp.com (Atom 2.0)" href=//blog.jverkamp.com/feed/><script src=/jquery_5823201688106629450.min.8c7d803d89ebdecf2416d468f4ecb981a3acf645154a7a336f2e5d0190ea8163.js integrity="sha256-jH2APYnr3s8kFtRo9Oy5gaOs9kUVSnozby5dAZDqgWM=" defer></script>
<script src=/jquery.fancybox_6181813213021922412.min.921ca906a32e718ab61ac0b4da24e0eaa6bdd41912654a33b44bd3fc2f0c2a4d.js integrity="sha256-khypBqMucYq2GsC02iTg6qa91BkSZUoztEvT/C8MKk0=" defer></script>
<script src=/katex_12008035502722260518.min.1c3dce03daaf56a7d2fe0d0ec49bf35256837226f835adaf52c09502ef9bc5d1.js integrity="sha256-HD3OA9qvVqfS/g0OxJvzUlaDcib4Na2vUsCVAu+bxdE=" defer></script>
<script src=/auto-render_2152414756166376840.min.45ae2f6b03d0c7b867df0a6cb7d43215ec78369998685a5748c5b12f502321f2.js integrity="sha256-Ra4vawPQx7hn3wpst9QyFex4NpmYaFpXSMWxL1AjIfI=" defer></script>
<script src=/bigfoot_8444447145154709333.min.5e80bd85ebaeb95607834d6777bfe7013d1d161f0f02a31b845e4bd765898316.js integrity="sha256-XoC9heuuuVYHg01nd7/nAT0dFh8PAqMbhF5L12WJgxY=" defer></script>
<script src=/mermaid_12365941879912544862.min.973b5415b3fa1835d620c0e58236f859d5f80891f447e240cbbb9eb825251ff0.js integrity="sha256-lztUFbP6GDXWIMDlgjb4WdX4CJH0R+JAy7ueuCUlH/A=" defer></script>
<script src=/main.min.d60298c89fc4f1e938aceb45c60926efee8b03efc8b50683082e669a100da643.js integrity="sha256-1gKYyJ/E8ek4rOtFxgkm7+6LA+/ItQaDCC5mmhANpkM=" defer></script>
<link rel=stylesheet href=/katex_14163593549783030822.min.16bacd59fb224ae6c97a749ab0ac1e708cb5e0c9ce5c9a08d7fd73dc8e69429f.css integrity="sha256-FrrNWfsiSubJenSasKwecIy14MnOXJoI1/1z3I5pQp8="><link rel=stylesheet href=/bigfoot-default_16482899066638414220.min.f15d4faa4519addb976f9d69b42bd9eb491b3596b6b2eda83aa3e9e1f48b8f14.css integrity="sha256-8V1PqkUZrduXb51ptCvZ60kbNZa2su2oOqPp4fSLjxQ="><link rel=stylesheet href=/jquery.fancybox_16222217791602823071.min.e28b5d7d9d89efacb5f708ac30cbd76b1b9a0f816dfd9da96631d1d09cbbdd76.css integrity="sha256-4otdfZ2J76y19wisMMvXaxuaD4Ft/Z2pZjHR0Jy73XY="><link rel=stylesheet href=/css_4780214198035419921.min.246b6f8e7620eeb717bca5e7b121037906e5dfaa05805f427fcc5a09b6c99f5c.css integrity="sha256-JGtvjnYg7rcXvKXnsSEDeQbl36oFgF9Cf8xaCbbJn1w="><link rel=stylesheet href=/main.min.d99288811f82c16d031e4f6c01e50e18aeccbb9968db7c625a21660aef059ef5.css integrity="sha256-2ZKIgR+CwW0DHk9sAeUOGK7Mu5lo23xiWiFmCu8FnvU="></head><body><div id=wrapper><header id=page-header role=banner><h1><a href=/>JP's Blog</a></h1><ul id=page-header-links><li><a href=https://github.com/jpverkamp>GitHub</a> *
<a href=https://www.flickr.com/photos/jpverkamp>Flickr</a> *
<a href=/resume>Resume</a></li><li><form action=/search/ method=get class="navbar-form navbar-right" role=search _lpchecked=1><div class=form-group><input name=q type=text class=form-control placeholder=Search>
<button type=submit class="btn btn-default" value=Search>Search</button></div></form></li></ul><nav id=header-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=https://blog.jverkamp.com/reviews/>Reviews</a></li><li><a href=https://blog.jverkamp.com/photography/>Photography</a></li><li><a href=https://blog.jverkamp.com/programming/>Programming</a></li><li><a href=https://blog.jverkamp.com/maker/>Maker</a></li><li><a href=https://blog.jverkamp.com/writing/>Writing</a></li><li><a href=https://blog.jverkamp.com/research/>Research</a></li><li><a href=https://blog.jverkamp.com/search/>Search</a></li><li class=subscription data-subscription=rss><a href=/atom.xml rel=subscribe-rss title="subscribe via RSS">RSS</a></li></ul></nav></header><div id=page-content-wrapper><div id=page-content><article data-pagefind-body><header><h1 class=entry-title data-pagefind-meta=title>Authorship attribution: Part 1</h1><div class=entry-meta><span class=entry-date>2013-07-30</span></div><div class=entry-taxonomies><div class=entry-tags><ul class=taxonomy-keys><li><a class=taxonomy-key href=/programming/languages/>Languages</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2013/07/19/racket-roguelike-post-mortem/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/racket>Racket</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2013/06/29/a-programming-puzzle-ffn-n/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/scheme>Scheme</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/programming/topics/>Topics</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/computational-linguistics>Computational Linguistics</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2013/06/29/a-programming-puzzle-ffn-n/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/mathematics>Mathematics</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/research>Research</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2013/05/21/ludum-dare-26-vtanks-results/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/vectors>Vectors</a><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/programming>programming</a><ul><li><a href=https://blog.jverkamp.com/2013/07/19/racket-roguelike-post-mortem/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link>Next</a></ul></li><li><a class=taxonomy-key href=/>All Posts</a><ul><li><a href=https://blog.jverkamp.com/2013/07/30/the-wolverine/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=next-link>Next</a></ul></li></ul></div></div></header><div class=entry-content><p>About two weeks ago, the new crime fiction novel <a href="http://www.amazon.com/gp/product/0316206849/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0316206849&amp;linkCode=as2&amp;tag=jverkampcom-20">Cuckoo&rsquo;s Calling</a> was revealed to have actually been written by J.K. Rowling under the pseudonym Robert Galbraith. What&rsquo;s interesting is exactly how they came to that conclusion. Here&rsquo;s a quote from <a title="J.K. Rowling’s Secret: A Forensic Linguist Explains How He Figured It Out" href=http://entertainment.time.com/2013/07/15/j-k-rowlings-secret-a-forensic-linguist-explains-how-he-figured-it-out/>Time</a> magazine (via <a title="J K Rowling" href=http://programmingpraxis.com/2013/07/19/j-k-rowling/>Programming Praxis</a>):</p><blockquote><p>As one part of his work, Juola uses a program to pull out the hundred most frequent words across an author’s vocabulary. This step eliminates rare words, character names and plot points, leaving him with words like of and but, ranked by usage. Those words might seem inconsequential, but they leave an authorial fingerprint on any work.</p></blockquote><blockquote><p>“Propositions and articles and similar little function words are actually very individual,” Juola says. “It’s actually very, very hard to change them because they’re so subconscious.”</p></blockquote><p>It&rsquo;s actually pretty similar to what I did a few years ago for my undergraduate thesis: <a title=AnnGram href=http://blog.jverkamp.com/category/programming/anngram/>AnnGram</a>. In that case, I used a similar technique to what they described above, <a href=https://en.wikipedia.org/wiki/n-grams>n-grams</a>, and <a href=https://en.wikipedia.org/wiki/Self%20organizing%20map>self organizing maps</a> to classify works by author. It&rsquo;s been awhile, but let&rsquo;s take a crack at re-implementing some of these techniques.</p><p>(If you&rsquo;d like to follow along, you can see the full code here: <a href=https://github.com/jpverkamp/small-projects/tree/master/authorship>authorship attribution on github</a>)</p><p>First, we&rsquo;ll use the technique described above. The idea is to take the most common words throughout a book and rank them. Theoretically, this will give us a unique fingerprint for each author that should be able to identify them even under a pseudonym.</p><p>Let&rsquo;s start by cleaning up the words. For the time being, we want only alphabetic characters and only in lowercase. That way we should avoid position in sentences and the like. This should be an easy enough way to do that:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span><span style=color:#75715e>; Remove non word characters</span>
</span></span><span style=display:flex><span>(<span style=color:#66d9ef>define </span>(<span style=color:#a6e22e>fix-word</span> word)
</span></span><span style=display:flex><span>  (list-&gt;string 
</span></span><span style=display:flex><span>   (<span style=color:#a6e22e>for/list</span> ([c (<span style=color:#a6e22e>in-string</span> word)] 
</span></span><span style=display:flex><span>              <span style=color:#f92672>#</span>:when (char-alphabetic? c)) 
</span></span><span style=display:flex><span>     (char-downcase c))))
</span></span></code></pre></div><p>Easy enough. So let&rsquo;s actually count the words. To start, we&rsquo;ll keep a hash of counts. They&rsquo;re easy enough to work with in Racket, albeit not quite so easy as say Python. With that, we only need to loop through the words in the text:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span><span style=color:#75715e>; Store the word counts</span>
</span></span><span style=display:flex><span>(<span style=color:#66d9ef>define </span>counts (<span style=color:#a6e22e>make-hash</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>; Count all of the base words in the text</span>
</span></span><span style=display:flex><span>(<span style=color:#a6e22e>for*</span> ([line (<span style=color:#a6e22e>in-lines</span> in)]
</span></span><span style=display:flex><span>       [word (<span style=color:#a6e22e>in-list</span> (<span style=color:#a6e22e>string-split</span> line))])
</span></span><span style=display:flex><span>  (<span style=color:#66d9ef>define </span>fixed (<span style=color:#a6e22e>fix-word</span> word))
</span></span><span style=display:flex><span>  (<span style=color:#a6e22e>hash-set!</span> counts fixed (<span style=color:#a6e22e>add1</span> (<span style=color:#a6e22e>hash-ref</span> counts fixed <span style=color:#ae81ff>0</span>))))
</span></span></code></pre></div><p>Using the three argument form of <code>hash-ref</code> allows us to specify a default. That way the <code>hash</code> is effectively acting like Python&rsquo;s <code>defaultdict</code> (a particular favorite data structure of mine).</p><p>After we&rsquo;ve done that, we can find the <code>top-n</code> most common words:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span><span style=color:#75715e>; Extract the top limit words</span>
</span></span><span style=display:flex><span>(<span style=color:#66d9ef>define </span>top-n
</span></span><span style=display:flex><span>  (map first
</span></span><span style=display:flex><span>       (<span style=color:#a6e22e>take</span>
</span></span><span style=display:flex><span>        (<span style=color:#a6e22e>sort</span> 
</span></span><span style=display:flex><span>         (<span style=color:#a6e22e>for/list</span> ([(<span style=color:#a6e22e>word</span> count) (<span style=color:#a6e22e>in-hash</span> counts)])
</span></span><span style=display:flex><span>           (list word count))
</span></span><span style=display:flex><span>         (<span style=color:#66d9ef>lambda </span>(<span style=color:#a6e22e>a</span> b) (&gt; (<span style=color:#a6e22e>second</span> a) (<span style=color:#a6e22e>second</span> b))))
</span></span><span style=display:flex><span>        limit)))
</span></span></code></pre></div><p>Finally, we want to replace the count with the ordering. Later, we&rsquo;ll try using the relative frequencies but at the moment the ordering will do well enough. Since we&rsquo;re going to later use a default value of 0 which should be near to a low rank, we&rsquo;ll count down.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span><span style=color:#75715e>; Add an order to each, descending</span>
</span></span><span style=display:flex><span>(<span style=color:#a6e22e>for/hash</span> ([i (<span style=color:#a6e22e>in-range</span> limit <span style=color:#ae81ff>0</span> <span style=color:#ae81ff>-1</span>)]
</span></span><span style=display:flex><span>           [word (<span style=color:#a6e22e>in-list</span> top-n)])
</span></span><span style=display:flex><span>  (values word i)))
</span></span></code></pre></div><p>All together, this can take a text file (as input port) and return the most common words. For example, using Cuckoo&rsquo;s Calling:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span>&gt; (with-input-from-file <span style=color:#e6db74>&#34;Cuckoo&#39;s Calling.txt&#34;</span> word-rank)
</span></span><span style=display:flex><span><span style=color:#f92672>&#39;#</span>hash((<span style=color:#e6db74>&#34;the&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>10</span>)  (<span style=color:#e6db74>&#34;to&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>9</span>)   (<span style=color:#e6db74>&#34;and&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>8</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;a&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>7</span>)     (<span style=color:#e6db74>&#34;of&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>6</span>)   (<span style=color:#e6db74>&#34;he&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;was&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>4</span>)   (<span style=color:#e6db74>&#34;she&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>3</span>)  (<span style=color:#e6db74>&#34;in&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;her&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>1</span>))
</span></span></code></pre></div><p>If the post was correct (and they did identify JK Rowling after all), then this should be a similar ordering for any book written by her while other authors will be slightly different. Let&rsquo;s take for example the text of the 7th Harry Potter book:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span>&gt; (with-input-from-file <span style=color:#e6db74>&#34;Deathly Hallows.txt&#34;</span> word-rank)
</span></span><span style=display:flex><span><span style=color:#f92672>&#39;#</span>hash((<span style=color:#e6db74>&#34;the&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>10</span>)  (<span style=color:#e6db74>&#34;and&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>9</span>)    (<span style=color:#e6db74>&#34;&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>8</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;to&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>7</span>)    (<span style=color:#e6db74>&#34;of&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>6</span>)     (<span style=color:#e6db74>&#34;he&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>5</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;a&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>4</span>)     (<span style=color:#e6db74>&#34;harry&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>3</span>)  (<span style=color:#e6db74>&#34;was&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>       (<span style=color:#e6db74>&#34;it&#34;</span> <span style=color:#f92672>.</span> <span style=color:#ae81ff>1</span>))
</span></span></code></pre></div><p>It seems that <strong>and</strong> has moved up, <strong>a</strong> and <strong>she</strong> have swapped, and <strong>harry</strong> is there&ndash;It&rsquo;s pretty impressive that&rsquo;s the 7th most common word in the entire book but rather unlikely to appear in Cuckoo&rsquo;s Calling. But overall, it&rsquo;s pretty similar. So let&rsquo;s try to compare it to a few more books.</p><p>We do need one more peace first though. We need to be able to tell how similar two books are. In this case, we&rsquo;ll use the idea of <a href=https://en.wikipedia.org/wiki/cosine%20similarity>cosine similarity</a>. Essentially, given two vectors we can calculate the angle between them. The more similar two vectors are, the closer to zero the result will be.</p><p>One problem is that we have hashes instead of vectors. We can&rsquo;t even guarantee that the same words will appear in two different lists. So first, we&rsquo;ll unify the keys. Add zeros for missing words, put them in the same order, and we have vectors we can measure:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span><span style=color:#75715e>; Calculate the similarity between two vectors</span>
</span></span><span style=display:flex><span><span style=color:#75715e>; If inputs are hashes, merge them before calculating similarity</span>
</span></span><span style=display:flex><span>(<span style=color:#66d9ef>define </span>(<span style=color:#a6e22e>cosine-similarity</span> a b)
</span></span><span style=display:flex><span>  (<span style=color:#a6e22e>cond</span>
</span></span><span style=display:flex><span>    [(<span style=color:#66d9ef>and </span>(<span style=color:#a6e22e>hash?</span> a) (<span style=color:#a6e22e>hash?</span> b))
</span></span><span style=display:flex><span>     (<span style=color:#66d9ef>define </span>keys
</span></span><span style=display:flex><span>       (<span style=color:#a6e22e>set-&gt;list</span> (<span style=color:#a6e22e>set-union</span> (<span style=color:#a6e22e>list-&gt;set</span> (<span style=color:#a6e22e>hash-keys</span> a))
</span></span><span style=display:flex><span>                             (<span style=color:#a6e22e>list-&gt;set</span> (<span style=color:#a6e22e>hash-keys</span> b)))))
</span></span><span style=display:flex><span>     (<span style=color:#a6e22e>cosine-similarity</span>
</span></span><span style=display:flex><span>      (<span style=color:#a6e22e>for/vector</span> ([k (<span style=color:#a6e22e>in-list</span> keys)]) (<span style=color:#a6e22e>hash-ref</span> a k <span style=color:#ae81ff>0</span>))
</span></span><span style=display:flex><span>      (<span style=color:#a6e22e>for/vector</span> ([k (<span style=color:#a6e22e>in-list</span> keys)]) (<span style=color:#a6e22e>hash-ref</span> b k <span style=color:#ae81ff>0</span>)))]
</span></span><span style=display:flex><span>    [else
</span></span><span style=display:flex><span>     (<span style=color:#66d9ef>define </span>cossim (acos (/ (<span style=color:#a6e22e>dot-product</span> a b) (* (magnitude a) (magnitude b)))))
</span></span><span style=display:flex><span>     (- <span style=color:#ae81ff>1.0</span> (/ (abs cossim) (/ pi <span style=color:#ae81ff>2</span>)))]))
</span></span></code></pre></div><p>The last line normalizes it to the range [0, 1.0] where the higher the number, the better match. This isn&rsquo;t strictly necessary, but I think it looks nicer. 😄</p><p>Finally, we can calculate the similarity between two books. So how similar are Cuckoo&rsquo;s Calling and the Deathly Hallows?</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scheme data-lang=scheme><span style=display:flex><span>&gt; (<span style=color:#66d9ef>let </span>([a (with-input-from-file <span style=color:#e6db74>&#34;Cuckoo&#39;s Calling.txt&#34;</span> word-rank)]
</span></span><span style=display:flex><span>        [b (with-input-from-file <span style=color:#e6db74>&#34;Deathly Hallows.txt&#34;</span> word-rank)])
</span></span><span style=display:flex><span>    (<span style=color:#a6e22e>cosine-similarity</span> a b))
</span></span><span style=display:flex><span><span style=color:#ae81ff>0.6965</span>
</span></span></code></pre></div><p>About 70% (not that the numbers mean particularly much). So let&rsquo;s try a few more.</p><p>Unfortunately, I don&rsquo;t have much in the way of crime fiction&ndash;I&rsquo;m more interested in science fiction and fantasy. But that should work well enough. Using a bit of framework (<a href=https://github.com/jpverkamp/small-projects/blob/master/authorship/main.rkt>linky</a>), we can measure this easily enough.</p><p>So, who among the author I have could have written Cuckoo&rsquo;s Calling? Here are the most similar books:</p><table><thead><tr><th>1</th><th>0.740</th><th>Butcher, Jim</th><th>Storm Front</th></tr></thead><tbody><tr><td>2</td><td>0.739</td><td>Butcher, Jim</td><td>Side Jobs</td></tr><tr><td>3</td><td>0.738</td><td>Butcher, Jim</td><td>Turn Coat</td></tr><tr><td>4</td><td>0.736</td><td>Butcher, Jim</td><td>Small Favor</td></tr><tr><td>5</td><td>0.735</td><td>Butcher, Jim</td><td>White Night</td></tr><tr><td>6</td><td>0.734</td><td>Butcher, Jim</td><td>Cold Days</td></tr><tr><td>7</td><td>0.731</td><td>Butcher, Jim</td><td>Proven Guilty</td></tr><tr><td>8</td><td>0.729</td><td>Butcher, Jim</td><td>Ghost Story</td></tr><tr><td>9</td><td>0.728</td><td>Stirling, S. M. & Meier, Shirley</td><td>Shadow&rsquo;s Son</td></tr><tr><td>10</td><td>0.728</td><td>Stephen, King</td><td>Wizard and Glass</td></tr><tr><td>11</td><td>0.728</td><td>Lovegrove, James</td><td>The Age of Zeus</td></tr><tr><td>12</td><td>0.726</td><td>Butcher, Jim</td><td>Dead Beat</td></tr><tr><td>13</td><td>0.726</td><td>Duncan, Glen</td><td>Last Werewolf, The</td></tr><tr><td>14</td><td>0.724</td><td>Butcher, Jim</td><td>Fool Moon</td></tr><tr><td>15</td><td>0.723</td><td>Stephen, King</td><td>The Drawing of the Three</td></tr><tr><td>16</td><td>0.723</td><td>Adams, Douglas</td><td>So Long, and Thanks for All the Fish</td></tr><tr><td>17</td><td>0.722</td><td>Stephen, King</td><td>The Dark Tower</td></tr><tr><td>18</td><td>0.718</td><td>Lovegrove, James</td><td>The Age of Odin</td></tr><tr><td>19</td><td>0.718</td><td>Butcher, Jim</td><td>Changes</td></tr><tr><td>20</td><td>0.715</td><td>Chima, Cinda Williams</td><td>The Wizard Heir</td></tr></tbody></table><p>Perhaps it&rsquo;s not surprising that Jim Butcher&rsquo;s books are at the top of the list. After all, it&rsquo;s about the closest thing that I have to crime fiction. Still, it doesn&rsquo;t look good that absolutely none of JK Rowling&rsquo;s books are in the top 20. In fact, we have to go all of the way down to 43 to find Harry Potter and the Half-Blood Prince, with a score of 0.704.</p><p>What if we average each author&rsquo;s books? Perhaps JK Rowling is more consistently matched against Cuckoo&rsquo;s Calling?</p><table class="table table-striped"><tr><td>1</td><td>0.714</td><td>Stephen, King</td></tr><tr><td>2</td><td>0.709</td><td>Butcher, Jim</td></tr><tr><td>3</td><td>0.704</td><td>Briggs, Patricia</td></tr><tr><td>4</td><td>0.704</td><td>Benson, Amber</td></tr><tr><td>5</td><td>0.698</td><td>Robinson, Kim Stanley</td></tr><tr><td>6</td><td>0.694</td><td>Colfer, Eoin</td></tr><tr><td>7</td><td>0.693</td><td>Jordan, Robert</td></tr><tr><td>8</td><td>0.692</td><td>Rowling, J.K.</td></tr><tr><td>9</td><td>0.687</td><td>Steele, Allen</td></tr><tr><td>10</td><td>0.687</td><td>Orwell, George</td></tr><tr><td>11</td><td>0.682</td><td>Croggon, Alison</td></tr><tr><td>12</td><td>0.681</td><td>Adams, Douglas</td></tr><tr><td>13</td><td>0.680</td><td>Riordan, Rick</td></tr><tr><td>14</td><td>0.679</td><td>Card, Orson Scott</td></tr><tr><td>15</td><td>0.671</td><td>Brin, David</td></tr><table class="table table-striped"><p>Not so much better, that. I have a few ideas though. Perhaps in a few days, we&rsquo;ll see what we can do.</p><p>If you&rsquo;d like to see the full source, you can do so here: <a href=https://github.com/jpverkamp/small-projects/tree/master/authorship>authorship attribution on github</a></p></div></article></div></div><footer id=page-footer role=contentinfo><nav id=footer-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=/archive-by-date/>All posts: By Date</a></li><li><a href=/archive-by-tag/>All posts: By Tag</a></li><li><a href=/atom.xml>RSS: All <sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li><li><a href=/programming/atom.xml>RSS: programming<sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li></ul></nav><div id=page-footer-content data-pagefind-ignore=all><div class=legal><p>All posts unless otherwise mentioned are licensed under
<a rel=license href=//creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US><img alt="Creative Commons License" style=border-width:0 src=//i.creativecommons.org/l/by-nc-sa/3.0/80x15.png></a></p><p>Any source code unless otherwise mentioned is licensed under the <a href=//directory.fsf.org/wiki/License:BSD_3Clause>3 clause BSD license</a></p></div></div></footer></div></body></html>