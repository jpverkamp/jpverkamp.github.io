<!doctype html><html><head><title>Programming, Topic:
Research - jverkamp.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=utf-8><link rel=alternate type=application/atom+xml title="jverkamp.com (Atom 2.0)" href=//blog.jverkamp.com/feed/><script src=/jquery_17422284542669262002.min.834c1e2313951f0c25b90152fe8b62250eab4a2e8cbd2560fa1a1cdc91c71733.js integrity="sha256-g0weIxOVHwwluQFS/otiJQ6rSi6MvSVg+hoc3JHHFzM=" defer></script><script src=/jquery.fancybox_16245765822111608191.min.a8e11addf4349ee2ca5045f7f3cbf1febbf2c3a2840be2143ea69539c10f8c7f.js integrity="sha256-qOEa3fQ0nuLKUEX388vx/rvyw6KEC+IUPqaVOcEPjH8=" defer></script><script src=/katex_17296078054267651618.min.4a06464d8d6f8358d8896de62b53b5a89205d335dfd8c5b6b27edd7c039ae9d8.js integrity="sha256-SgZGTY1vg1jYiW3mK1O1qJIF0zXf2MW2sn7dfAOa6dg=" defer></script><script src=/auto-render_14944144240389301023.min.e694d9d5eae2917984179683ead27b998784a81398e8836c369373d2c67fc32a.js integrity="sha256-5pTZ1erikXmEF5aD6tJ7mYeEqBOY6INsNpNz0sZ/wyo=" defer></script><script src=/bigfoot_28293813221957978.min.af671f08986f0a2267c5a0cb2748b005489e47fa25f55479b200e2a563d23022.js integrity="sha256-r2cfCJhvCiJnxaDLJ0iwBUieR/ol9VR5sgDipWPSMCI=" defer></script><script src=/mermaid_9520146763733687737.min.a17078917a4403310cd19178939257b706fb5e1da76167c9f4a6d2123c9d59c4.js integrity="sha256-oXB4kXpEAzEM0ZF4k5JXtwb7Xh2nYWfJ9KbSEjydWcQ=" defer></script><script src=/main.min.d60298c89fc4f1e938aceb45c60926efee8b03efc8b50683082e669a100da643.js integrity="sha256-1gKYyJ/E8ek4rOtFxgkm7+6LA+/ItQaDCC5mmhANpkM=" defer></script><link rel=stylesheet href=/katex_13658330645258633971.min.16bacd59fb224ae6c97a749ab0ac1e708cb5e0c9ce5c9a08d7fd73dc8e69429f.css integrity="sha256-FrrNWfsiSubJenSasKwecIy14MnOXJoI1/1z3I5pQp8="><link rel=stylesheet href=/bigfoot-default_8781527669040159104.min.f15d4faa4519addb976f9d69b42bd9eb491b3596b6b2eda83aa3e9e1f48b8f14.css integrity="sha256-8V1PqkUZrduXb51ptCvZ60kbNZa2su2oOqPp4fSLjxQ="><link rel=stylesheet href=/jquery.fancybox_5330465509389191777.min.7420a1602c62a85d4b50881c1d8ce42f72c049dc2b097d440696425d6e54bb1e.css integrity="sha256-dCChYCxiqF1LUIgcHYzkL3LASdwrCX1EBpZCXW5Uux4="><link rel=stylesheet href=/css_1846377409604050217.min.fffe842bc000dd1fe8661ac6427a392a08faa95e8edab1ea7fb98c5f8dac6a6f.css integrity="sha256-//6EK8AA3R/oZhrGQno5Kgj6qV6O2rHqf7mMX42sam8="><link rel=stylesheet href=/main.min.61064b3964637440ee1c28e577377fcf238ddc5939020ef8b3c3cae543898111.css integrity="sha256-YQZLOWRjdEDuHCjldzd/zyON3Fk5Ag74s8PK5UOJgRE="></head><body><div id=wrapper><header id=page-header role=banner><h1><a href=/>JP's Blog</a></h1><ul id=page-header-links><li><a href=https://github.com/jpverkamp>GitHub</a> *
<a href=https://www.flickr.com/photos/jpverkamp>Flickr</a> *
<a href=/resume>Resume</a></li><li><form action=/search/ method=get class="navbar-form navbar-right" role=search _lpchecked=1><div class=form-group><input name=q type=text class=form-control placeholder=Search>
<button type=submit class="btn btn-default" value=Search>Search</button></div></form></li></ul><nav id=header-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=https://blog.jverkamp.com/programming/>Programming</a></li><li><a href=https://blog.jverkamp.com/reviews/>Reviews</a></li><li><a href=https://blog.jverkamp.com/maker/>Maker</a></li><li><a href=https://blog.jverkamp.com/photography/>Photography</a></li><li><a href=https://blog.jverkamp.com/home-automation/>Home Automation</a></li><li><a href=https://blog.jverkamp.com/writing/>Writing</a></li><li><a href=https://blog.jverkamp.com/research/>Research</a></li><li><a href=https://blog.jverkamp.com/search/>Search</a></li><li class=subscription data-subscription=rss><a href=/atom.xml rel=subscribe-rss title="subscribe via RSS">RSS</a></li></ul></nav></header><div id=page-content-wrapper><div id=page-content><h1 class=entry-title data-pagefind-meta=title>Programming, Topic:
Research</h1><div class=entry-content></div><h2>All posts</h2><ul><li><span class=entry-date>2013-08-06</span>:
<a href=https://blog.jverkamp.com/2013/08/06/authorship-attribution-part-3/>Authorship attribution: Part 3</a></li><li><span class=entry-date>2013-08-02</span>:
<a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/>Authorship attribution: Part 2</a></li><li><span class=entry-date>2013-07-30</span>:
<a href=https://blog.jverkamp.com/2013/07/30/authorship-attribution-part-1/>Authorship attribution: Part 1</a></li><li><span class=entry-date>2010-05-21</span>:
<a href=https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/>FLAIRS 2010 - Augmenting n-gram Based Authorship Attribution With Neural Networks</a></li><li><span class=entry-date>2010-03-17</span>:
<a href=https://blog.jverkamp.com/2010/03/17/anngram-ngrams-vs-words/>AnnGram - nGrams vs Words</a></li><li><span class=entry-date>2010-02-10</span>:
<a href=https://blog.jverkamp.com/2010/02/10/anngram-vs-k-means/>AnnGram vs k-means</a></li><li><span class=entry-date>2010-02-03</span>:
<a href=https://blog.jverkamp.com/2010/02/03/anngram-self-organizing-map-gui/>AnnGram - Self-Organizing Map GUI</a></li><li><span class=entry-date>2010-01-28</span>:
<a href=https://blog.jverkamp.com/2010/01/28/anngram-new-gui/>AnnGram - New GUI</a></li><li><span class=entry-date>2010-01-21</span>:
<a href=https://blog.jverkamp.com/2010/01/21/anngram-neural-network-progress/>AnnGram - Neural Network Progress</a></li><li><span class=entry-date>2010-01-15</span>:
<a href=https://blog.jverkamp.com/2010/01/15/anngram-ideas-for-improvement/>AnnGram - Ideas for improvement</a></li><li><span class=entry-date>2010-01-13</span>:
<a href=https://blog.jverkamp.com/2010/01/13/anngram-initial-ann-results/>AnnGram - Initial ANN Results</a></li><li><span class=entry-date>2010-01-12</span>:
<a href=https://blog.jverkamp.com/2010/01/12/anngram-neuralnetwork-library/>AnnGram - NeuralNetwork Library</a></li><li><span class=entry-date>2010-01-05</span>:
<a href=https://blog.jverkamp.com/2010/01/05/anngram-initial-gui/>AnnGram - Initial GUI</a></li><li><span class=entry-date>2010-01-01</span>:
<a href=https://blog.jverkamp.com/2010/01/01/anngram-cosine-distance/>AnnGram - Cosine Distance</a></li><li><span class=entry-date>2009-12-29</span>:
<a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/>AnnGram - Framework</a></li><li><span class=entry-date>2009-12-21</span>:
<a href=https://blog.jverkamp.com/2009/12/21/anngram-overview/>AnnGram - Overview</a></li></ul><h2>Recent posts</h2><div class=post-list><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2013/08/06/authorship-attribution-part-3/ class=clearfix>Authorship attribution: Part 3</a></h1><div class=entry-meta><span class=entry-date>2013-08-06</span></div></header><div class=entry-content><p>So far, we&rsquo;ve had three different ideas for figuring out the author of an unknown paper (top n word ordering in <a href=https://blog.jverkamp.com/2013/07/30/authorship-attribution-part-1/>Part 1</a> and stop word frequency / 4-grams in <a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/>Part 2</a>). Here&rsquo;s something interesting though from the comments on the <a title="JK Rowling" href=http://programmingpraxis.com/2013/07/19/j-k-rowling/>Programming Praxis post</a>:</p><blockquote><p><cite>Globules</cite> said
<small>July 19, 2013 at 12:29 PM</small>
Patrick Juola has a <a href="http://languagelog.ldc.upenn.edu/nll/?p=5315" rel=nofollow>guest post on Language Log</a> describing the approach he took.</p></blockquote><p><a href=/2013/08/06/authorship-attribution-part-3/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2013/08/02/authorship-attribution-part-2/ class=clearfix>Authorship attribution: Part 2</a></h1><div class=entry-meta><span class=entry-date>2013-08-02</span></div></header><div class=entry-content><p><a href=https://blog.jverkamp.com/2013/07/30/authorship-attribution-part-1/>Last time</a>, we used word rank to try to figure out who could possibly have written Cuckoo&rsquo;s calling. It didn&rsquo;t work out so well, but we at least have a nice framework in place. So perhaps we can try a few more ways of turning entire novels into a few numbers.</p><p><a href=/2013/08/02/authorship-attribution-part-2/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2013/07/30/authorship-attribution-part-1/ class=clearfix>Authorship attribution: Part 1</a></h1><div class=entry-meta><span class=entry-date>2013-07-30</span></div></header><div class=entry-content><p>About two weeks ago, the new crime fiction novel <a href="http://www.amazon.com/gp/product/0316206849/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0316206849&amp;linkCode=as2&amp;tag=jverkampcom-20">Cuckoo&rsquo;s Calling</a> was revealed to have actually been written by J.K. Rowling under the pseudonym Robert Galbraith. What&rsquo;s interesting is exactly how they came to that conclusion. Here&rsquo;s a quote from <a title="J.K. Rowling’s Secret: A Forensic Linguist Explains How He Figured It Out" href=http://entertainment.time.com/2013/07/15/j-k-rowlings-secret-a-forensic-linguist-explains-how-he-figured-it-out/>Time</a> magazine (via <a title="J K Rowling" href=http://programmingpraxis.com/2013/07/19/j-k-rowling/>Programming Praxis</a>):</p><p><a href=/2013/07/30/authorship-attribution-part-1/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/ class=clearfix>FLAIRS 2010 - Augmenting n-gram Based Authorship Attribution With Neural Networks</a></h1><div class=entry-meta><span class=entry-date>2010-05-21</span></div></header><div class=entry-content><p>Co-authors: <a href=http://www.rose-hulman.edu/~wollowsk/>Michael Wollowski</a>, and <a href=http://www.rose-hulman.edu/~hirotani/>Maki Hirotani</a></p><blockquote><p><strong>Abstract</strong>: While using statistical methods to determine authorship attribution is not a new idea and neural networks have been applied to a number of statistical problems, the two have not often been used together. We show that the use of articial neural networks, specically self-organizing maps, combined with n-grams provides a success rate on the order of previous work with purely statistical methods. Using a collection of documents including the works of Shakespeare, William Blake, and the King James Version of the Bible, we were able to demonstrate classication of documents into individual groups. Further experiments with The Federalist Papers exposed potential problems with the algorithm. Finally, first exchanging n-gram frequencies with word frequencies and then exchanging self-organizing maps with k-means clustering shows that it is the combination of the two factors contributing to the algorithms success.</p><p><a href=/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/03/17/anngram-ngrams-vs-words/ class=clearfix>AnnGram - nGrams vs Words</a></h1><div class=entry-meta><span class=entry-date>2010-03-17</span></div></header><div class=entry-content><p><strong>Overview</strong></p><p>For another comparison, I&rsquo;ve been looking for a way to replace the nGrams with another way of turning a document into a vector.  Based on word frequency instead of nGrams, I&rsquo;ve run a number of tests to see how the accuracy and speed of the algorithm compares for the two.</p><p><strong>nGrams</strong></p><figure><img src=/embeds/2010/SOM-ngram.png></figure><p>I still intend to look into why the Tragedy of Macbeth does not stay with the rest of Shakespeare&rsquo;s plays.  I still believe that it is because portions of it were possible written by another author.</p><p><a href=/2010/03/17/anngram-ngrams-vs-words/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/02/10/anngram-vs-k-means/ class=clearfix>AnnGram vs k-means</a></h1><div class=entry-meta><span class=entry-date>2010-02-10</span></div></header><div class=entry-content><p><strong>Overview</strong></p><p>As a set of benchmarks to test whether or not the new AnnGram algorithm is actually working correctly, I&rsquo;ve been trying to come up with different yet similar methods to compare it too.  Primarily, there are two possibilities:</p><ul><li>Replace the nGram vectors with another form</li><li>Process the nGrams using something other than Self-Organizing Maps</li></ul><p>I&rsquo;m still looking through the related literature to decide if there is some way to use something other than the nGrams to feed into the SOM; however, I haven&rsquo;t been having any luck.  So far, most of my work has been focused on comparing SOM to k-means clustering.</p><p><a href=/2010/02/10/anngram-vs-k-means/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/02/03/anngram-self-organizing-map-gui/ class=clearfix>AnnGram - Self-Organizing Map GUI</a></h1><div class=entry-meta><span class=entry-date>2010-02-03</span></div></header><div class=entry-content><p>They say a picture is worth a thousand words:</p><p><strong>One Thousand Words</strong></p><figure><img src=/embeds/2010/som-results-11.png></figure><p><a href=/2010/02/03/anngram-self-organizing-map-gui/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/01/28/anngram-new-gui/ class=clearfix>AnnGram - New GUI</a></h1><div class=entry-meta><span class=entry-date>2010-01-28</span></div></header><div class=entry-content><p>The old GUI framework just wasn&rsquo;t working out (so far as adding new features went).  So, long story short, I&rsquo;ve switched GUI layout.</p><p><a href=/2010/01/28/anngram-new-gui/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/01/21/anngram-neural-network-progress/ class=clearfix>AnnGram - Neural Network Progress</a></h1><div class=entry-meta><span class=entry-date>2010-01-21</span></div></header><div class=entry-content><p><a href=https://blog.jverkamp.com/2010/01/12/anngram-neuralnetwork-library/>As expected</a>, I&rsquo;ve decided to change libraries from the** **<a href=https://blog.jverkamp.com/2010/01/13/anngram-initial-ann-results/>poor results with the original tests</a> may have been a direct results of a misunderstanding with the code base.  I think that the layers were not being hooked up correctly, resulting in low/random values.</p><p><a href=/2010/01/21/anngram-neural-network-progress/>read more...</a></p></div><hr></article><article class=li><header><h1 class=entry-title><a href=https://blog.jverkamp.com/2010/01/15/anngram-ideas-for-improvement/ class=clearfix>AnnGram - Ideas for improvement</a></h1><div class=entry-meta><span class=entry-date>2010-01-15</span></div></header><div class=entry-content><p>After my meeting yesterday with my thesis advisers, I have a number of new ideas to try to improve the efficiency of the neural networks.  The most promising of those are described below.</p><p><strong>Sliding window</strong></p><p>The first idea was to replace the idea of applying the most common frequencies directly with a sliding window (almost a directly analogue to the nGrams themselves).  The best way that we could come up to implent this would be to give the neural networks some sort of memory which brought up recurring networks (see below).</p><p><a href=/2010/01/15/anngram-ideas-for-improvement/>read more...</a></p></div><hr></article></div><nav id=pagination-navigation role=navigation><ul class="pagination pagination-default"><li class="page-item disabled"><a aria-disabled=true aria-label=First class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;&#171;</span></a></li><li class="page-item disabled"><a aria-disabled=true aria-label=Previous class=page-link role=button tabindex=-1><span aria-hidden=true>&#171;</span></a></li><li class="page-item active"><a aria-current=page aria-label="Page 1" class=page-link role=button>1</a></li><li class=page-item><a href=/programming/topics/research/page/2/ aria-label="Page 2" class=page-link role=button>2</a></li><li class=page-item><a href=/programming/topics/research/page/2/ aria-label=Next class=page-link role=button><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/programming/topics/research/page/2/ aria-label=Last class=page-link role=button><span aria-hidden=true>&#187;&#187;</span></a></li></ul></nav></div></div><footer id=page-footer role=contentinfo><nav id=footer-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=/archive-by-date/>All posts: By Date</a></li><li><a href=/archive-by-tag/>All posts: By Tag</a></li><li><a href=/atom.xml>RSS: All <sup><svg width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li><li><a href=/programming/atom.xml>RSS: programming<sup><svg width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li></ul></nav><div id=page-footer-content data-pagefind-ignore=all><div class=legal><p>All posts unless otherwise mentioned are licensed under
<a rel=license href=//creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US><img alt="Creative Commons License" style=border-width:0 src=//i.creativecommons.org/l/by-nc-sa/3.0/80x15.png></a></p><p>Any source code unless otherwise mentioned is licensed under the <a href=//directory.fsf.org/wiki/License:BSD_3Clause>3 clause BSD license</a></p></div></div></footer></div></body></html>