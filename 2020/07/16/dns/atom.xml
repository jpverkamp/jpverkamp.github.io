<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DNS on jverkamp.com</title><link>https://blog.jverkamp.com/2020/07/16/dns/</link><description>Recent content in DNS on jverkamp.com</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 16 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.jverkamp.com/2020/07/16/dns/atom.xml" rel="self" type="application/rss+xml"/><item><title>An SPF DNS Server</title><link>https://blog.jverkamp.com/2020/07/16/an-spf-dns-server/</link><pubDate>Thu, 16 Jul 2020 00:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2020/07/16/an-spf-dns-server/</guid><description>&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Sender%20Policy%20Framework">Sender Policy Framework&lt;/a> is one of those things that&amp;rsquo;s really powerful and useful to help prevent phishing and email spam, but can be a royal pain to work with. Specifically, SPF is a series of DNS TXT records&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> with a specific format that can be looked up by any email service to verify that an email was sent by a server that should be authorized to send email on your behalf. For example&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">&amp;#34;v=spf1 ip4:192.0.2.0/24 ip4:198.51.100.123 a -all&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;code>v=spf1&lt;/code> - tells the client this is an SPF record and should always start the record&lt;/li>
&lt;li>&lt;code>{key}[:{value}]?&lt;/code> - one of many different key/value pairs that can define the record
&lt;ul>
&lt;li>in the case above a &lt;code>ip4&lt;/code> key species an &lt;a href="https://en.wikipedia.org/wiki/IPv4">IPv4&lt;/a> address range that can send emails on your behalf (the value can be optional)&lt;/li>
&lt;li>the &lt;code>a&lt;/code> above is another special case where if the sender domain (&lt;code>jp@example.com&lt;/code> would be &lt;code>example.com&lt;/code>) resolves via a &lt;code>DNS A&lt;/code> record to the server that sent the email, it&amp;rsquo;s allows&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>-all&lt;/code> is a fallthrough case meaning &amp;lsquo;fail all that didn&amp;rsquo;t match a previous case&lt;/li>
&lt;/ul>
&lt;p>There are a number of other cases, but we&amp;rsquo;ll get to the other interesting ones in a bit.&lt;/p></description></item><item><title>SSRF Protection in Rails</title><link>https://blog.jverkamp.com/2020/06/30/ssrf-protection-in-rails/</link><pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2020/06/30/ssrf-protection-in-rails/</guid><description>&lt;p>One of the more subtle bugs that a lot of companies miss is Server Side Request Forgery (SSRF). Like it&amp;rsquo;s cousin CSRF (cross-site request forgery), SSRF involves carefully crafting a request that runs in a way that the original developers didn&amp;rsquo;t expect to do things that shouldn&amp;rsquo;t be done. In the case of CSRF, one site is making a request on behalf of another in a user&amp;rsquo;s browser (cross-site), but in SSRF, a request is being made by a server on behalf of a client, but you can trick it into making a request that wasn&amp;rsquo;t intended.&lt;/p>
&lt;p>For a perhaps more obvious example, consider a website with a service that will render webpages as preview images&amp;ndash;consider sharing links on a social network. A user makes a request such as &lt;code>/render?url=https://www.google.com&lt;/code>. This goes to the server, which will then fetch &lt;a href="https://www.google.com" target="_blank" rel="noopener">https://www.google.com&lt;/a>, render the page to a screenshot, and then return that as a thumbnail.&lt;/p>
&lt;p>This seems like rather useful functionality, but what if instead, the user gives the url: &lt;code>/render?url=https://secret-internal-site.company.com&lt;/code>. Normally, &lt;code>company.com&lt;/code> would be an internal only domain that cannot be viewed by users, but in this case&amp;ndash;the server is within the corporate network. Off the server goes, helpfully taking and returning a screenshot. Another option&amp;ndash;if you&amp;rsquo;re hosted on AWS&amp;ndash;is the AWS &lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html" target="_blank" rel="noopener">metadata endpoint&lt;/a>: &lt;code>http://169.254.169.254/latest/meta-data/&lt;/code>. All sorts of interesting private things there. Or even more insidious, &lt;code>/render?url=file:///etc/password&lt;/code>. That shouldn&amp;rsquo;t work in most cases, since most libraries know better than to rener &lt;code>file://&lt;/code> protocol URLs, but&amp;hellip; not always!&lt;/p></description></item><item><title>Creating a temporary SMTP server to 'catch' domain validation emails</title><link>https://blog.jverkamp.com/2018/07/09/creating-a-temporary-smtp-server-to-catch-domain-validation-emails/</link><pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2018/07/09/creating-a-temporary-smtp-server-to-catch-domain-validation-emails/</guid><description>&lt;p>One problem that has come up a time or two is dealing with email-based domain validation (specifically in this case for the issuance of TLS certificates) on domains that aren&amp;rsquo;t actually configured to receive email. Yes, in a perfect world, it would be easier to switch to DNS-based validation (since we have to have control of the DNS for the domain, we need it later), but let&amp;rsquo;s just assume that&amp;rsquo;s not an option. So, how do we &amp;lsquo;catch&amp;rsquo; the activation email so we can prove we can receive email on that domain?&lt;/p></description></item><item><title>Generating zone files from Route53</title><link>https://blog.jverkamp.com/2018/03/12/generating-zone-files-from-route53/</link><pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2018/03/12/generating-zone-files-from-route53/</guid><description>&lt;p>Recently I found myself wanting to do some analysis on all of our DNS entires stored in AWS&amp;rsquo;s Route53 for security reasons (specifically to prevent subdomain takeover attacks, I&amp;rsquo;ll probably write that up soon). In doing so, I realized that while Route53 has the ability to import a &lt;a href="https://en.wikipedia.org/wiki/zone%20file">zone file&lt;/a>, it&amp;rsquo;s not possible to export one.&lt;/p>
&lt;p>To some extent, this makes sense. Since Route53 supports ALIAS records (which can automatically determine their values based on other AWS products, such as an ELB changing its public IP) and those aren&amp;rsquo;t actually &amp;lsquo;real&amp;rsquo; DNS entries, things will get confused. But I don&amp;rsquo;t currently intend to re-import these zone files, just use them. So let&amp;rsquo;s see what we can do.&lt;/p></description></item><item><title>Large scale asynchronous DNS scans</title><link>https://blog.jverkamp.com/2013/09/27/large-scale-asynchronous-dns-scans/</link><pubDate>Fri, 27 Sep 2013 14:00:11 +0000</pubDate><guid>https://blog.jverkamp.com/2013/09/27/large-scale-asynchronous-dns-scans/</guid><description>&lt;p>On Monday we &lt;a href="https://blog.jverkamp.com/2013/09/23/extending-racket-structs-to-bitfields/">laid out a framework&lt;/a> for converting structures into bytes. On Wednesday, we used that to &lt;a href="https://blog.jverkamp.com/2013/09/25/extending-rackets-dns-capabilities/">enhance Racket&amp;rsquo;s UDP and DNS capabilities&lt;/a>. Today, we&amp;rsquo;re going to take that all one step further and scan large portions of the Internet. The end goal will be to look for &lt;a href="https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/">DNS-based&lt;/a> on a worldwide scale.&lt;/p></description></item><item><title>Extending Racket's DNS capabilities</title><link>https://blog.jverkamp.com/2013/09/25/extending-rackets-dns-capabilities/</link><pubDate>Wed, 25 Sep 2013 14:00:35 +0000</pubDate><guid>https://blog.jverkamp.com/2013/09/25/extending-rackets-dns-capabilities/</guid><description>&lt;p>As I &lt;a href="https://blog.jverkamp.com/2013/09/23/extending-racket-structs-to-bitfields/">mentioned&lt;/a> on Monday, I wrote my &lt;a href="https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/">DNS-based censorship&lt;/a> around the world&amp;ndash;and to do that, I need a fair bit of control over the DNS packets that I&amp;rsquo;m sending back and over parsing the ones that I get back.&lt;/p></description></item><item><title>ISMA 2013 AIMS-5 - DNS Based Censorship</title><link>https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/</link><pubDate>Sat, 09 Feb 2013 15:00:06 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/</guid><description>&lt;p>I gave a presentation about research that I&amp;rsquo;m just starting out studying DNS-based censorship in specific around the world. In particularly, preliminary findings in China have confirmed that the &lt;a href="https://en.wikipedia.org/wiki/Great%20Firewall">Great Firewall&lt;/a> is responding via packet injection to many queries for either Facebook or Twitter (among others). Interestingly, the pool of IPs that they return is consistent yet none of the IPs seem to resolve to anything interesting. In addition, there is fallout in South Korea where some percentage of packets go through China and thus have the same behaviors.&lt;/p></description></item><item><title>AIMS-5 - Day 3</title><link>https://blog.jverkamp.com/2013/02/09/aims-5-day-3/</link><pubDate>Sat, 09 Feb 2013 14:00:02 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/09/aims-5-day-3/</guid><description>&lt;p>Yesterday was the third and final day of AIMS-5. With the main topic being &lt;em>Detection of Censorship, Filtering, and Outages&lt;/em>, many of these talks were much more in line with what I know and what I&amp;rsquo;m working on. I gave my presentation as well, you can see it (along with a link to my slides) down below.&lt;/p></description></item><item><title>AIMS-5 - Day 2</title><link>https://blog.jverkamp.com/2013/02/08/aims-5-day-2/</link><pubDate>Fri, 08 Feb 2013 14:00:06 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/08/aims-5-day-2/</guid><description>&lt;p>Today&amp;rsquo;s agenda had discussions on Mobile Measurements and IPv6 Annotations, none of which are areas that I find myself particularly interested in. Still, I did learn a few things.&lt;/p></description></item><item><title>AIMS-5 - Workshop on Active Internet Measurements</title><link>https://blog.jverkamp.com/2013/02/07/aims-5-workshop-on-active-internet-measurements/</link><pubDate>Thu, 07 Feb 2013 14:00:41 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/07/aims-5-workshop-on-active-internet-measurements/</guid><description>&lt;p>Yesterday was the first of three days for the fifth annual &lt;a href="https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/">ISC/CAIDA Workshop&lt;/a> I went to in Baltimore back in October at least, but even the ones that weren&amp;rsquo;t have still been interesting.&lt;/p>
&lt;p>I&amp;rsquo;ll be presenting on Friday and I&amp;rsquo;ll share my slides when I get that far (they aren&amp;rsquo;t actually finished yet). I&amp;rsquo;ll be talking about new work that I&amp;rsquo;m just getting off the ground focusing specifically on DNS-based censorship. There is a lot of interesting ground to cover there and this should be only the first in a series of updates about that work (I hope).&lt;/p></description></item><item><title>Scanning for DNS resolvers</title><link>https://blog.jverkamp.com/2013/01/31/scanning-for-dns-resolvers/</link><pubDate>Thu, 31 Jan 2013 14:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2013/01/31/scanning-for-dns-resolvers/</guid><description>&lt;p>For a research project I&amp;rsquo;m working on, it has become necessary to scan potentially large &lt;a href="https://en.wikipedia.org/wiki/Cidr">IPv4 prefixes&lt;/a> in order to find any &lt;a href="https://en.wikipedia.org/wiki/DNS%20resolver">DNS revolvers&lt;/a> that I can and classify them as either open (accepting queries from anyone) or closed.&lt;/p>
&lt;p>Disclaimer: This is a form of &lt;a href="https://en.wikipedia.org/wiki/port%20scanning">port scanning&lt;/a> and thus has associated ethical and legal considerations. Use it at your own risk. &lt;/p>
&lt;p>This project is available on GitHub: &lt;a href="https://github.com/jpverkamp/dnsscan" title="GitHub: jpverkamp: dnsscan">jpverkamp/dnsscan&lt;/a>&lt;/p></description></item><item><title>ISC/CAIDA Workshop</title><link>https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/</link><pubDate>Mon, 22 Oct 2012 23:00:58 +0000</pubDate><guid>https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/</guid><description>&lt;p>I&amp;rsquo;ve spent the day in Baltimore at the &lt;a title="ISC/CAIDA Workshop" href="http://rsf.isc.org/events/data-collab-workshop-2-2012/">ISC/CAIDA Data Collaboration Workshop&lt;/a> learning about and presenting about all things DNS related. It&amp;rsquo;s not really the sort of thing that my PhD work is focusing on but it&amp;rsquo;s still interesting.&lt;/p></description></item></channel></rss>