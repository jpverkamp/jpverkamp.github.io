<!doctype html><html><head><title>StackLang Part II: The Lexer â€“ jverkamp.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=utf-8><link rel=alternate type=application/atom+xml title="jverkamp.com (Atom 2.0)" href=//blog.jverkamp.com/feed/><script src=/jquery_5823201688106629450.min.8c7d803d89ebdecf2416d468f4ecb981a3acf645154a7a336f2e5d0190ea8163.js integrity="sha256-jH2APYnr3s8kFtRo9Oy5gaOs9kUVSnozby5dAZDqgWM=" defer></script>
<script src=/jquery.fancybox_6181813213021922412.min.921ca906a32e718ab61ac0b4da24e0eaa6bdd41912654a33b44bd3fc2f0c2a4d.js integrity="sha256-khypBqMucYq2GsC02iTg6qa91BkSZUoztEvT/C8MKk0=" defer></script>
<script src=/katex_12008035502722260518.min.1c3dce03daaf56a7d2fe0d0ec49bf35256837226f835adaf52c09502ef9bc5d1.js integrity="sha256-HD3OA9qvVqfS/g0OxJvzUlaDcib4Na2vUsCVAu+bxdE=" defer></script>
<script src=/bigfoot_8444447145154709333.min.5e80bd85ebaeb95607834d6777bfe7013d1d161f0f02a31b845e4bd765898316.js integrity="sha256-XoC9heuuuVYHg01nd7/nAT0dFh8PAqMbhF5L12WJgxY=" defer></script>
<script src=/mermaid_12365941879912544862.min.973b5415b3fa1835d620c0e58236f859d5f80891f447e240cbbb9eb825251ff0.js integrity="sha256-lztUFbP6GDXWIMDlgjb4WdX4CJH0R+JAy7ueuCUlH/A=" defer></script>
<script src=/main.min.982c2d7bb434b4cf8b19c2cf38ef7e7f7162ddbed610e5bdddbb937001e26574.js integrity="sha256-mCwte7Q0tM+LGcLPOO9+f3Fi3b7WEOW93buTcAHiZXQ=" defer></script>
<link rel=stylesheet href=/katex_14163593549783030822.min.16bacd59fb224ae6c97a749ab0ac1e708cb5e0c9ce5c9a08d7fd73dc8e69429f.css integrity="sha256-FrrNWfsiSubJenSasKwecIy14MnOXJoI1/1z3I5pQp8="><link rel=stylesheet href=/bigfoot-default_16482899066638414220.min.f15d4faa4519addb976f9d69b42bd9eb491b3596b6b2eda83aa3e9e1f48b8f14.css integrity="sha256-8V1PqkUZrduXb51ptCvZ60kbNZa2su2oOqPp4fSLjxQ="><link rel=stylesheet href=/jquery.fancybox_16222217791602823071.min.e28b5d7d9d89efacb5f708ac30cbd76b1b9a0f816dfd9da96631d1d09cbbdd76.css integrity="sha256-4otdfZ2J76y19wisMMvXaxuaD4Ft/Z2pZjHR0Jy73XY="><link rel=stylesheet href=/css_4780214198035419921.min.246b6f8e7620eeb717bca5e7b121037906e5dfaa05805f427fcc5a09b6c99f5c.css integrity="sha256-JGtvjnYg7rcXvKXnsSEDeQbl36oFgF9Cf8xaCbbJn1w="><link rel=stylesheet href=/main.min.e0e68b86dea32185ab89b0b9cc01649107cc6b0be3290c8c7b13c716bc0dabfa.css integrity="sha256-4OaLht6jIYWribC5zAFkkQfMawvjKQyMexPHFrwNq/o="></head><body><div id=wrapper><header id=page-header role=banner><h1><a href=/>JP's Blog</a></h1><ul id=page-header-links><li><a href=https://github.com/jpverkamp>GitHub</a> *
<a href=https://www.flickr.com/photos/jpverkamp>Flickr</a> *
<a href=/resume>Resume</a></li><li><form action=/search/ method=get class="navbar-form navbar-right" role=search _lpchecked=1><div class=form-group><input name=q type=text class=form-control placeholder=Search>
<button type=submit class="btn btn-default" value=Search>Search</button></div></form></li></ul><nav id=header-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=https://blog.jverkamp.com/reviews/>Reviews</a></li><li><a href=https://blog.jverkamp.com/photography/>Photography</a></li><li><a href=https://blog.jverkamp.com/programming/>Programming</a></li><li><a href=https://blog.jverkamp.com/maker/>Maker</a></li><li><a href=https://blog.jverkamp.com/writing/>Writing</a></li><li><a href=https://blog.jverkamp.com/research/>Research</a></li><li><a href=https://blog.jverkamp.com/search/>Search</a></li><li class=subscription data-subscription=rss><a href=/atom.xml rel=subscribe-rss title="subscribe via RSS">RSS</a></li></ul></nav></header><div id=page-content-wrapper><div id=page-content><article data-pagefind-body><header><h1 class=entry-title data-pagefind-meta=title>StackLang Part II: The Lexer</h1><div class=entry-meta><span class=entry-date>2023-04-16</span></div><div class=entry-taxonomies><div class=entry-tags><ul class=taxonomy-keys><li><a class=taxonomy-key href=/programming/languages/>Languages</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/rust>Rust</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/stacklang>StackLang</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/programming/topics/>Topics</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/assemblers>Assemblers</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/compilers>Compilers</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/data-structures>Data Structures</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/memory>Memory</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/stacks>Stacks</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/programming/topics/virtual-machines>Virtual Machines</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/series/>Series</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link></a><a class=taxonomy-value href=/series/stacklang>StackLang</a><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/programming>programming</a><ul><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/ class=next-link>Next</a></ul></li><li><a class=taxonomy-key href=/>All Posts</a><ul><li><a href=https://blog.jverkamp.com/2023/04/16/ultimate-x-men-vol.-12-hard-lessons/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2023/04/17/ultimate-galactus-volume-1-nightmare/ class=next-link>Next</a></ul></li></ul></div></div></header><div class=entry-content><p>StackLang, part 2: lexing.</p><p>It&rsquo;s quite often the simplest part of implementing a programming language (although parsers for s-expression based languages come close), but it&rsquo;s still something that needs done. So here we go!</p><hr><p>Posts in this series:</p><div class=ranking><h3 class=title>Posts in <a href=/series/stacklang/>StackLang</a>:</h3><div class=content><ul><li><a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/>StackLang Part I: The Idea</a></li><li><a href=https://blog.jverkamp.com/2023/04/16/stacklang-part-ii-the-lexer/>StackLang Part II: The Lexer</a></li><li><a href=https://blog.jverkamp.com/2023/04/24/stacklang-part-iii-the-parser/>StackLang Part III: The Parser</a></li><li><a href=https://blog.jverkamp.com/2023/05/01/stacklang-part-iv-an-interpreter/>StackLang Part IV: An Interpreter</a></li><li><a href=https://blog.jverkamp.com/2023/07/12/stacklang-part-v-compiling-to-c/>StackLang Part V: Compiling to C</a></li><li><a href=https://blog.jverkamp.com/2023/07/16/stacklang-part-vi-some-examples/>StackLang Part VI: Some Examples</a></li><li><a href=https://blog.jverkamp.com/2023/08/05/stacklang-part-vii-new-cli-and-datatypes/>StackLang Part VII: New CLI and Datatypes</a></li><li><a href=https://blog.jverkamp.com/2023/08/11/stacklang-part-viii-compiler-stacks/>StackLang Part VIII: Compiler Stacks</a></li><li><a href=https://blog.jverkamp.com/2023/08/12/stacklang-part-ix-better-testing/>StackLang Part IX: Better Testing</a></li></ul></div></div><p>This post:</p><nav id=TableOfContents><ul><li><a href=#general-structure>General structure</a></li><li><a href=#mainrs-the-entry-point><code>main.rs</code>: The entry point</a></li><li><a href=#typesrs-the-type-of-tokens><code>types.rs</code>: The type of Tokens</a></li><li><a href=#lexerrs-actually-lexing><code>lexer.rs</code>: Actually lexing</a></li><li><a href=#lexerrs-test-cases><code>lexer.rs</code>: Test cases</a></li></ul></nav><p>Full source code for StackLang: <a href=https://github.com/jpverkamp/stacklang/ target=_blank rel=noopener>github:jpverkamp/stacklang</a></p><h2 id=general-structure>General structure</h2><p>My goal is to split everything out into modules this time around, so we have:</p><h2 id=mainrs-the-entry-point><code>main.rs</code>: The entry point</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>use</span> log;
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> std::io::BufReader;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>mod</span> types;
</span></span><span style=display:flex><span><span style=color:#66d9ef>mod</span> lexer;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[derive(Parser, Debug)]</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#[command(author, version, about, long_about = None)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Args</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>/// Name of the person to greet
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>    <span style=color:#75715e>#[arg(short, long)]</span>
</span></span><span style=display:flex><span>    file: String,
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>main</span>() {
</span></span><span style=display:flex><span>    pretty_env_logger::init();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> args <span style=color:#f92672>=</span> Args::parse();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> file <span style=color:#f92672>=</span> std::fs::File::open(args.file).unwrap();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> lexer::tokenize(BufReader::new(file));
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    log::info!(
</span></span><span style=display:flex><span>        <span style=color:#e6db74>&#34;Tokens: {}&#34;</span>,
</span></span><span style=display:flex><span>        tokens
</span></span><span style=display:flex><span>            .iter()
</span></span><span style=display:flex><span>            .map(<span style=color:#f92672>|</span>token<span style=color:#f92672>|</span> token.token.clone())
</span></span><span style=display:flex><span>            .collect::<span style=color:#f92672>&lt;</span>Vec<span style=color:#f92672>&lt;</span>String<span style=color:#f92672>&gt;&gt;</span>()
</span></span><span style=display:flex><span>            .join(<span style=color:#e6db74>&#34; &#34;</span>)
</span></span><span style=display:flex><span>    );
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=typesrs-the-type-of-tokens><code>types.rs</code>: The type of Tokens</h2><p>Easy enough. Next up, we need the type of a token:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#e6db74>/// A token is a single unit of a program.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#75715e>#[derive(Clone, Debug, PartialEq, Eq)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>struct</span> <span style=color:#a6e22e>Token</span> {
</span></span><span style=display:flex><span>    <span style=color:#e6db74>/// The row of the token in the source code.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>    <span style=color:#66d9ef>pub</span> row: <span style=color:#66d9ef>usize</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>/// The column of the token in the source code.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>    <span style=color:#66d9ef>pub</span> column: <span style=color:#66d9ef>usize</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>/// The token itself.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span>    <span style=color:#66d9ef>pub</span> token: String,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>I want row and column to print where code actually was in error messages.</p><h2 id=lexerrs-actually-lexing><code>lexer.rs</code>: Actually lexing</h2><p>It&rsquo;s so relatively short that I can actually put it all inline:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>use</span> std::io::BufRead;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> regex::Regex;
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> substring::Substring;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>use</span> <span style=color:#66d9ef>crate</span>::types::Token;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#e6db74>/// Tokenizes a stream of characters into a vector of tokens.
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>tokenize</span>(reader: <span style=color:#a6e22e>impl</span> BufRead) -&gt; Vec<span style=color:#f92672>&lt;</span>Token<span style=color:#f92672>&gt;</span> {
</span></span><span style=display:flex><span>    log::debug!(<span style=color:#e6db74>&#34;tokenize()&#34;</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> tokens <span style=color:#f92672>=</span> vec![];
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> token_patterns <span style=color:#f92672>=</span> vec![
</span></span><span style=display:flex><span>        <span style=color:#75715e>// single characters
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[\{}()\[\]]&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// &lt;numbers&gt;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// complex numbers
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;-?\d+(\.\d*)?[+-]-?\d+(\.\d*)?i&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// floats (including scientific notation)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;-?\d+(\.\d*)?[eE]-?\d+(\.\d*)?&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// rationals
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;-?\d+/\d+&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// hex literals
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;0x[0-9a-fA-F]+&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// binary literals
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;0b[01]+&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// integers
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;-?\d+(\.\d*)?&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// &lt;/numbers&gt;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#75715e>// strings
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>(</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>.|[^</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>])*</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// basic identifiers, must start with a letter or _
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z][^\{}()\[\]\s\.]*&#34;</span>,
</span></span><span style=display:flex><span>        <span style=color:#75715e>// purely symbolic identifiers, cannot contain letters or numbers
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[^a-zA-Z0-9\{}()\[\]\s\.]+&#34;</span>,
</span></span><span style=display:flex><span>    ];
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> token_regex <span style=color:#f92672>=</span> Regex::new(format!(<span style=color:#e6db74>&#34;^(</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>)&#34;</span>, token_patterns.join(<span style=color:#e6db74>&#34;|&#34;</span>)).as_str()).unwrap();
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>let</span> whitespace_regex <span style=color:#f92672>=</span> Regex::new(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;^\s+&#34;</span>).unwrap();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Scan the input line by line tracking rows
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span> (row, line) <span style=color:#66d9ef>in</span> reader.lines().enumerate() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> line <span style=color:#f92672>=</span> line.unwrap();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> line <span style=color:#f92672>=</span> line.as_str();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> <span style=color:#66d9ef>mut</span> column <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        log::debug!(<span style=color:#e6db74>&#34;tokenize: line {}: {:?}&#34;</span>, row, line);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e>// Within a row, scan for tokens character by character
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        <span style=color:#66d9ef>loop</span> {
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Skip whitespace
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>if</span> <span style=color:#66d9ef>let</span> Some(c) <span style=color:#f92672>=</span> whitespace_regex.captures(line) {
</span></span><span style=display:flex><span>                line <span style=color:#f92672>=</span> line.substring(c[<span style=color:#ae81ff>0</span>].len(), line.len());
</span></span><span style=display:flex><span>                column <span style=color:#f92672>+=</span> c[<span style=color:#ae81ff>0</span>].len();
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Read the next token (patterns above)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>if</span> <span style=color:#66d9ef>let</span> Some(c) <span style=color:#f92672>=</span> token_regex.captures(line) {
</span></span><span style=display:flex><span>                <span style=color:#75715e>// Ignore comments
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>                <span style=color:#66d9ef>if</span> c[<span style=color:#ae81ff>0</span>].starts_with(<span style=color:#e6db74>&#39;#&#39;</span>) {
</span></span><span style=display:flex><span>                    <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>                tokens.push(Token {
</span></span><span style=display:flex><span>                    row,
</span></span><span style=display:flex><span>                    column,
</span></span><span style=display:flex><span>                    token: <span style=color:#a6e22e>c</span>[<span style=color:#ae81ff>0</span>].to_string(),
</span></span><span style=display:flex><span>                });
</span></span><span style=display:flex><span>                line <span style=color:#f92672>=</span> line.substring(c[<span style=color:#ae81ff>0</span>].len(), line.len());
</span></span><span style=display:flex><span>                column <span style=color:#f92672>=</span> c[<span style=color:#ae81ff>0</span>].len();
</span></span><span style=display:flex><span>            } <span style=color:#66d9ef>else</span> <span style=color:#66d9ef>if</span> line.len() <span style=color:#f92672>!=</span> <span style=color:#ae81ff>0</span> {
</span></span><span style=display:flex><span>                panic!(<span style=color:#e6db74>&#34;no token found at </span><span style=color:#e6db74>{row}</span><span style=color:#e6db74>:</span><span style=color:#e6db74>{column}</span><span style=color:#e6db74> = </span><span style=color:#e6db74>{line:?}</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> line.len() <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> {
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>break</span>;
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    tokens
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The entire point of the thing is to do a few parts:</p><ul><li>Iterate line by line through the input<ul><li>TODO: Handle multi-line strings, somehow</li></ul></li><li>Within a string, consume any leading whitespace</li><li>As soon as we have none, try each regex in order<ul><li>If it starts with <code>#</code>, it&rsquo;s a comment, don&rsquo;t include in the token stream</li><li>Return the first matching one</li><li>Update the column index based on the length of the token</li></ul></li><li>As soon as the line is empty, we&rsquo;re done, move on</li></ul><p>And&mldr; that&rsquo;s really it.</p><p>It&rsquo;s probably not the best thing in the world to pass the complexity of parsing directly off to regexes&mldr; but they really do exactly what I need.</p><p>The only gotcha is that you have to be a little careful about order, since as mentioned I will take the <em>first</em> match on the list of regexes. So originally, I had integers parsed first, but it turns out that you&rsquo;d parse <code>1/2</code> as <code>["1", "/", "2"]</code> instead of `[&ldquo;1/2&rdquo;] as I want. That&rsquo;s why you write tests!</p><p>Another special case: splitting identifiers. As mentioned in <a href=https://blog.jverkamp.com/2023/04/14/stacklang-part-i-the-idea/>StackLang Part I: The Idea</a>, I have a rather broad allowance for what can be in an identifier. Anything that isn&rsquo;t already used elsewhere (brackets, whitespaces, and dots) can be part of an identifier, but it has to start with a letter.</p><p>If it doesn&rsquo;t, it falls into the purely symbolic identifiers, which are mostly built in functions (like <code>+</code> and <code>&lt;=</code>) or special prefixes (like <code>@</code> and <code>!</code>). We&rsquo;ll see if this continues to make sense.</p><h2 id=lexerrs-test-cases><code>lexer.rs</code>: Test cases</h2><p>Speaking of which:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#75715e>#[cfg(test)]</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>mod</span> test {
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_brackets</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;[](){}&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>6</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;[&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;]&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;(&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;)&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;{&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;}&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_integers</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1 2 3 100 8675309 0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>6</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;1&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;2&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;3&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;100&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;8675309&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_negative_integers</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;-1 -2 -3 -100 -8675309 -0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>6</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;-1&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;-2&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;-3&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;-100&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;-8675309&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;-0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_rationals</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1/2 3/4 5/6 7/8 9/10&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>5</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;1/2&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;3/4&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;5/6&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;7/8&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;9/10&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_floats</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1.0 2.0 3.0 100.0 8675309.0 0.0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>6</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;1.0&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;2.0&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;3.0&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;100.0&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;8675309.0&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;0.0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_float_scientific</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;1e1 1.1e2 1.0e3 1.0e2 8.6e6 0e0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>6</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;1e1&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;1.1e2&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;1.0e3&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;1.0e2&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;8.6e6&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;0e0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_hex</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;0x1 0xFF 0xdeadbeef 0x0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;0x1&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;0xFF&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;0xdeadbeef&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;0x0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_binary</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;0b1 0b1111 0b1101 0b0&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;0b1&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;0b1111&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;0b1101&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;0b0&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_strings</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;\&#34;</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello world</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74> </span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>nworld</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;\&#34;</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello world</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>hello</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>nworld</span><span style=color:#ae81ff>\&#34;</span><span style=color:#e6db74>&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_identifiers</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;test fact camelCase snake_case with-symbols?&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>5</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;test&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;fact&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;camelCase&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;snake_case&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;with-symbols?&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_symbolic</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;+ - * &amp;! | ^ ~!! &lt;==&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>8</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;+&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;-&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;*&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;&amp;!&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>4</span>].token, <span style=color:#e6db74>&#34;|&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>5</span>].token, <span style=color:#e6db74>&#34;^&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>6</span>].token, <span style=color:#e6db74>&#34;~!!&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>7</span>].token, <span style=color:#e6db74>&#34;&lt;==&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>#[test]</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>fn</span> <span style=color:#a6e22e>test_prefixed</span>() {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> input <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;@fact !fact&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> tokens <span style=color:#f92672>=</span> <span style=color:#66d9ef>super</span>::tokenize(input.as_bytes());
</span></span><span style=display:flex><span>        assert_eq!(tokens.len(), <span style=color:#ae81ff>4</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>0</span>].token, <span style=color:#e6db74>&#34;@&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>1</span>].token, <span style=color:#e6db74>&#34;fact&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>2</span>].token, <span style=color:#e6db74>&#34;!&#34;</span>);
</span></span><span style=display:flex><span>        assert_eq!(tokens[<span style=color:#ae81ff>3</span>].token, <span style=color:#e6db74>&#34;fact&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Is it exhaustive? Probably not. Did it take surprisingly little time to write, since I let Copilot help me? Awesomelutely.</p></div></article></div></div><footer id=page-footer role=contentinfo><nav id=footer-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=/archive-by-date/>All posts: By Date</a></li><li><a href=/archive-by-tag/>All posts: By Tag</a></li><li><a href=/atom.xml>RSS: All <sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li><li><a href=/programming/atom.xml>RSS: programming<sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li></ul></nav><div id=page-footer-content data-pagefind-ignore=all><div class=legal><p>All posts unless otherwise mentioned are licensed under
<a rel=license href=//creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US><img alt="Creative Commons License" style=border-width:0 src=//i.creativecommons.org/l/by-nc-sa/3.0/80x15.png></a></p><p>Any source code unless otherwise mentioned is licensed under the <a href=//directory.fsf.org/wiki/License:BSD_3Clause>3 clause BSD license</a></p></div></div></footer></div></body></html>