<!doctype html><html><head><title>AnnGram - Overview – jverkamp.com</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=utf-8><link rel=alternate type=application/atom+xml title="jverkamp.com (Atom 2.0)" href=//blog.jverkamp.com/feed/><script src=/jquery_5823201688106629450.min.30448892aa1f91e9c4cb5494e5c5e5abc13b7778de7786e5256cdc7d2424813a.js defer></script>
<script src=/jquery.fancybox_6181813213021922412.min.6ba037466db9f8843b66c38c32fe5a353344e7fd68ecda97efb63a84c881f828.js defer></script>
<script src=/katex_12008035502722260518.min.3cc3a080c0368785179e37b0cd0a71c6cf60c4fc5a8dce503f5a542ec0a25043.js defer></script>
<script src=/bigfoot_8444447145154709333.min.5e80bd85ebaeb95607834d6777bfe7013d1d161f0f02a31b845e4bd765898316.js defer></script>
<script src=/mermaid_12365941879912544862.min.e8f19283a632077085b9ad74aecad54abe84429c69789fd29ffa3a254d86abdd.js defer></script>
<script src=/custom.min.9bb1a6d1e0b58ced38df246e4479317e4561461cfabab31b36fbc36035186214.js defer></script>
<link rel=stylesheet href=/katex_14163593549783030822.min.16bacd59fb224ae6c97a749ab0ac1e708cb5e0c9ce5c9a08d7fd73dc8e69429f.css><link rel=stylesheet href=/bigfoot-default_16482899066638414220.min.f15d4faa4519addb976f9d69b42bd9eb491b3596b6b2eda83aa3e9e1f48b8f14.css><link rel=stylesheet href=/jquery.fancybox_16222217791602823071.min.e28b5d7d9d89efacb5f708ac30cbd76b1b9a0f816dfd9da96631d1d09cbbdd76.css><link rel=stylesheet href=/css_4780214198035419921.min.7cfac95bdd962d85ceec560e50fe7b04c44b58a76e5202006ef36ca8c0a7d836.css><link rel=stylesheet href=/custom.min.3bcba67844fc4a76aa7c1947a1fcf14cddaf8e9e0f1e734fde0fa219416f058d.css></head><body><div id=wrapper><header id=page-header role=banner><h1><a href=/>JP's Blog</a></h1><ul id=page-header-links><li><a href=https://github.com/jpverkamp>GitHub</a> *
<a href=https://www.flickr.com/photos/jpverkamp>Flickr</a> *
<a href=/resume>Resume</a></li><li><form action=//www.google.com/search method=get onsubmit='(function(e){e.q.value="site:blog.jverkamp.com "+e.qfront.value})(this)' class="navbar-form navbar-right" role=search _lpchecked=1><div class=form-group><input name=q type=hidden>
<input name=qfront type=text class=form-control placeholder=Search>
<button type=submit class="btn btn-default" value=Search>Search</button></div></form></li></ul><nav id=header-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=https://blog.jverkamp.com/programming/>Programming</a></li><li><a href=https://blog.jverkamp.com/reviews/>Reviews</a></li><li><a href=https://blog.jverkamp.com/photography/>Photography</a></li><li><a href=https://blog.jverkamp.com/maker/>Maker</a></li><li><a href=https://blog.jverkamp.com/writing/>Writing</a></li><li><a href=https://blog.jverkamp.com/research/>Research</a></li><li class=subscription data-subscription=rss><a href=/atom.xml rel=subscribe-rss title="subscribe via RSS">RSS</a></li></ul></nav></header><div id=page-content-wrapper><div id=page-content><article><header><h1 class=entry-title>AnnGram - Overview</h1><div class=entry-meta><span class=entry-date>2009-12-21</span></div><div class=entry-taxonomies><div class=entry-tags><ul class=taxonomy-keys><li><a class=taxonomy-key href=/programming/languages/>Languages</a><ul class=taxonomy-values><li><a href=https://blog.jverkamp.com/2009/12/09/sandbox-multiple-definitions/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/.net>.NET</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li><li><a href=https://blog.jverkamp.com/2009/12/09/sandbox-multiple-definitions/ class=previous-link></a><a class=taxonomy-value href=/programming/languages/c>C#</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/programming/topics/>Topics</a><ul class=taxonomy-values><li><a class=taxonomy-value href=/programming/topics/computational-linguistics>Computational Linguistics</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li><li><a class=taxonomy-value href=/programming/topics/natural-language-processing>Natural Language Processing</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li><li><a class=taxonomy-value href=/programming/topics/neural-networks>Neural Networks</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li><li><a class=taxonomy-value href=/programming/topics/research>Research</a><a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link></a></li></ul></li><li><a class=taxonomy-key href=/research>research</a><ul><li><a href=https://blog.jverkamp.com/2009/03/07/sigcse-2009-rasql-query-grammar-conversion-project/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link>Next</a></ul></li><li><a class=taxonomy-key href=/>All Posts</a><ul><li><a href=https://blog.jverkamp.com/2009/12/09/sandbox-multiple-definitions/ class=previous-link>Prev</a>
<a href=https://blog.jverkamp.com/2009/12/29/anngram-framework/ class=next-link>Next</a></ul></li></ul></div></div></header><div class=entry-content><p><strong>Basic Premise</strong></p><p>For my senior thesis at Rose-Hulman Institute of Technology, I am attempting to combine the fields of Computational Linguistics and Artificial Intelligence in a new and useful manner.  Specifically, I am planning on making use of Artificial Neural Networks to enhance the performance of n-gram based document classification.  Over the next few months, I will be updating this category with background and information and further progress.</p><p>First, I&rsquo;ll start with some basic background information.</p><p><strong>Artificial Neural Network (ANN)</strong></p><p>From <a href=https://en.wikipedia.org/wiki/Artificial%20neural%20network>Wikipedia</a>:</p><p><em>An artificial neural network (ANN), usually called &ldquo;neural network&rdquo; (NN), is a mathematical model or computational model that tries to simulate the structure and/or functional aspects of biological neural networks. It consists of an interconnected group of artificial neurons and processes information using a connectionist approach to computation. In most cases an ANN is an adaptive system that changes its structure based on external or internal information that flows through the network during the learning phase. Neural networks are non-linear statistical data modeling tools. They can be used to model complex relationships between inputs and outputs or to find patterns in data.</em></p><p><strong>Example ANN</strong>*
*</p><img class=alignnone title="Artificial Neural Network" src=http://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/500px-Artificial_neural_network.svg.png alt="Diagram of an artificial neural network" width=300 height=268><p>In the above image, the colored circles are individual neurons.  The above arrangement is a traditional one, with three layers: input, hidden, and output.  The input layer takes input from outside of the system and certain nodes fire based on said input.  These nodes then pass their values along to the hidden layer (neither input nor output).  The hidden nodes are what allow a neural network to adopt to non-linear problems.  These then pass their values along to the output which are sent out from the system.</p><p><strong>n-gram</strong></p><p>From <a href=https://en.wikipedia.org/wiki/N-gram>Wikipedia</a>:</p><p>*An n-gram is a subsequence of n items from a given sequence. The items in question can be phonemes, syllables, letters, words or base pairs according to the application.</p><p>An n-gram of size 1 is referred to as a &ldquo;unigram&rdquo;; size 2 is a &ldquo;bigram&rdquo; (or, less commonly, a &ldquo;digram&rdquo;); size 3 is a &ldquo;trigram&rdquo;; and size 4 or more is simply called an &ldquo;n-gram&rdquo;. Some language models built from n-grams are &ldquo;(n - 1)-order Markov models&rdquo;.</p><p>An n-gram model is a type of probabilistic model for predicting the next item in such a sequence. n-grams are used in various areas of statistical natural language processing and genetic sequence analysis.*</p><p>**Example ****n-gram
**</p><p>As an example, consider &ldquo;ROSE-HULMAN&rdquo; with the following 4-grams:</p><ul><li>ROSE</li><li>OSE-</li><li>SE-H</li><li>E-HU</li><li>-HUL</li><li>HULM</li><li>ULMA</li><li>LMAN</li></ul><p>One of the most interesting features of n-grams is that they encode not only the letters and words used by the author, but also the relationships between them.   As such, n-grams can be used to paint a more complete picture of an author.</p><p><strong>Future Plans</strong></p><ul><li>Describe prior algorithms</li><li>Implement prior algorithms as benchmarks</li><li>Add neural networks</li><li>Tune efficiency</li></ul></div></article></div></div><footer id=page-footer role=contentinfo><nav id=footer-navigation role=navigation class=ribbon><ul class=main-navigation><li><a href=/archive-by-date/>All posts: By Date</a></li><li><a href=/archive-by-tag/>All posts: By Tag</a></li><li><a href=/atom.xml>RSS: All <sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li><li><a href=/research/atom.xml>RSS: research<sup><svg xmlns="http://www.w3.org/2000/svg" width="8" height="8" viewBox="0 0 24 24"><path fill="#fff" d="M6.503 20.752C6.503 22.546 5.047 24 3.252 24c-1.796.0-3.252-1.454-3.252-3.248s1.456-3.248 3.252-3.248c1.795.001 3.251 1.454 3.251 3.248zM0 8.18v4.811c6.05.062 10.96 4.966 11.022 11.009h4.817C15.777 15.29 8.721 8.242.0 8.18zm0-3.368C10.58 4.858 19.152 13.406 19.183 24H24c-.03-13.231-10.755-23.954-24-24v4.812z"/></svg></sup></a></li></ul></nav><div id=page-footer-content><div class=legal><p>All posts unless otherwise mentioned are licensed under
<a rel=license href=//creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US><img alt="Creative Commons License" style=border-width:0 src=//i.creativecommons.org/l/by-nc-sa/3.0/80x15.png></a></p><p>Any source code unless otherwise mentioned is licensed under the <a href=//directory.fsf.org/wiki/License:BSD_3Clause>3 clause BSD license</a></p></div></div></footer></div></body></html>