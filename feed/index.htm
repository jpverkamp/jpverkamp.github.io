<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jverkamp.com</title><link href="http://blog.jverkamp.com" /><link rel="self" href="http://blog.jverkamp.com/feed/" /><updated>2015-07-20T00:00:00Z</updated><author><name>JP Verkamp</name></author><id>urn:uuid:f148b655-ada3-c720-0c01-ca384ab68088</id><entry><title>Configuring Websockets behind an AWS ELB</title><link href="http://blog.jverkamp.com/2015/07/20/configuring-websockets-behind-an-aws-elb" /><id>urn:uuid:7dcd0d64-5bf4-e7c8-1c43-b21d96bd35e0</id><updated>2015-07-20T00:00:00Z</updated><summary type="html"><![CDATA[<p>Recently at work, we were trying to get an application that uses <a href="https://en.wikipedia.org/wiki/websockets">websockets</a> working on an <a href="https://aws.amazon.com/">AWS</a> instance behind an <a href="https://aws.amazon.com/elasticloadbalancing/">ELB (load balancer)</a> and <a href="http://nginx.org/">nginx</a> on the instance.</p>
<p>If you're either not using a secure connection or handling the cryptography on the instance (either in nginx or Flask), it works right out of the box. But if you want the ELB to handle TLS termination it doesn't work nearly as well... Luckily, after a bit of fiddling, I got it working.</p>
]]></summary><content type="html"><![CDATA[<p>Recently at work, we were trying to get an application that uses <a href="https://en.wikipedia.org/wiki/websockets">websockets</a> working on an <a href="https://aws.amazon.com/">AWS</a> instance behind an <a href="https://aws.amazon.com/elasticloadbalancing/">ELB (load balancer)</a> and <a href="http://nginx.org/">nginx</a> on the instance.</p>
<p>If you're either not using a secure connection or handling the cryptography on the instance (either in nginx or Flask), it works right out of the box. But if you want the ELB to handle TLS termination it doesn't work nearly as well... Luckily, after a bit of fiddling, I got it working.</p>
<!--more-->
<p>First, we have a basic application. For my purposes, I wrote a quick Websocket chat app: <a href="https://github.com/jpverkamp/ws-chat">ws-chat</a>. The particular implementation details aren't as important. We'll start with the nginx config file:</p>
<pre class="nginx"><code>upstream webserver {
    server 127.0.0.1:8000;
}

upstream wsserver {
    server 127.0.0.1:9000;
}

server {
    listen 80 proxy_protocol;

    location / {
        if ($http_x_forwarded_proto = "http") {
            return 301 https://$host$request_uri;
        }

        proxy_pass http://webserver;
    }

    location /ws/ {
        proxy_pass http://wsserver;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}</code></pre>
<p>Straight forward enough. We have two backend services: a <a href="https://github.com/jpverkamp/ws-chat/blob/master/app/web-server.py">web server</a> running on port 8000 (a simple Flask server that just servers a single <a href="https://github.com/jpverkamp/ws-chat/blob/master/app/templates/index.html">HTML page</a>) and the <a href="https://github.com/jpverkamp/ws-chat/blob/master/app/ws-server.py">websocket backend</a> running on port 9000. Alternatively, these could be the same codebase. The important parts are that you allow the Websocket <code>upgrade</code> header to pass through to establish the connection and that you tell nginx to listen using the <code>proxy_protocol</code>, an extra header that passes through extra information:</p>
<pre class="text"><code>PROXY_STRING + single space + INET_PROTOCOL + single space + CLIENT_IP + single space + PROXY_IP + single space + CLIENT_PORT + single space + PROXY_PORT + "\r\n"</code></pre>
<p>This seems like it wouldn't be necessary, except that without <code>proxy_protocol</code> AWS ELBs seem to strip something important to the connection.</p>
<p>Next, we need to configure the load balancer. One complication here is that telling the load balancer to forward HTTPS traffic to HTTP will not work for the websockets. Instead, you have to configure it to forward TCP (SSL) to TCP. This will still work for HTTP/HTTPS traffic (as HTTP is just a specific protocol over TCP and HTTPS is just HTTP with a TLS layer), but it will also allow the non-HTTP websocket traffic to pass through successfully. Something like this:</p>
<p><a href="http://blog.jverkamp.com/2015/07/20/configuring-websockets-behind-an-aws-elb/configure-elb.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/07/20/configuring-websockets-behind-an-aws-elb/configure-elb.png" /></a></p>
<p>(Don't forget to set the certificate :))</p>
<p>Finally, you have to configure the ELB also to speak proxy protocol. This part is slightly more annoying, since (at least now), there's no way to configure this through the AWS console. You have to use the <a href="https://aws.amazon.com/cli/">AWS CLI</a>.</p>
<p>First, create the new policy (assuming you have an environment variable <code>ELB_NAME</code> defined):</p>
<pre class="bash"><code>aws elb create-load-balancer-policy \
    --load-balancer-name $ELB_NAME \
    --policy-name $ELB_NAME-proxy-protocol \
    --policy-type-name ProxyProtocolPolicyType \\
    --policy-attributes AttributeName=ProxyProtocol,AttributeValue=True</code></pre>
<p>Then, attach it to the load balancer. You will have to run this once for each port that the instance is listening on:</p>
<pre class="bash"><code>aws elb set-load-balancer-policies-for-backend-server \
    --load-balancer-name $ELB_NAME \
    --instance-port 80 \
    --policy-names $ELB_NAME-proxy-protocol</code></pre>
<p>Make sure that you're using <code>https://</code> for the web traffic and <code>wss://</code> for the websocket and you're golden. Encrypted websockets behind an AWS ELB. Now if only they would expose the proxy protocol options in the console...</p>]]></content></entry><entry><title>Finding AWS IAM users by access key</title><link href="http://blog.jverkamp.com/2015/07/20/finding-aws-iam-users-by-access-key" /><id>urn:uuid:de410b08-f76c-4ca3-fb5a-30fccb14273b</id><updated>2015-07-20T00:00:00Z</updated><summary type="html"><![CDATA[<p>Every once in a while<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, I find myself with an <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html">AWS access key</a> and need to figure out who in the world it belongs to. Unfortunately, so far as I've been able to find, there's no way to directly do this in either the <a href="https://aws.amazon.com/console/">AWS console</a> or with the <a href="https://aws.amazon.com/cli/">AWS api</a>.</p>
]]></summary><content type="html"><![CDATA[<p>Every once in a while<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, I find myself with an <a href="https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSGettingStartedGuide/AWSCredentials.html">AWS access key</a> and need to figure out who in the world it belongs to. Unfortunately, so far as I've been able to find, there's no way to directly do this in either the <a href="https://aws.amazon.com/console/">AWS console</a> or with the <a href="https://aws.amazon.com/cli/">AWS api</a>.</p>
<!--more-->
<p>Luckily, <a href="https://aws.amazon.com/cli/">boto</a>:</p>
<pre class="python"><code>#!/usr/bin/env python3

import boto.iam.connection
import pprint
import sys

if len(sys.argv) == 1:
    print('Usage: who-iam [access-key ...]')
    sys.exit(0)

conn = boto.iam.connection.IAMConnection()
users = conn.get_all_users()

for user in users['list_users_response']['list_users_result']['users']:
    keys = conn.get_all_access_keys(user['user_name'])
    for key in keys['list_access_keys_response']['list_access_keys_result']['access_key_metadata']:
        for target in sys.argv[1:]:
            if key['access_key_id'] == target:
                print(key['access_key_id'], user['user_name'])</code></pre>
<p>Check it out (keys changed on the off chance that actually matters):</p>
<pre class="bash"><code>$ who-iam AKIAIOSWISKB6EXAMPLE AKIAIOSGWISN7EXAMPLE
AKIAIOSWISKB6EXAMPLE luke
AKIAIOSGWISN7EXAMPLE han</code></pre>
<p>It's rather slow (since it has to make <code>O(n)</code> requests and doesn't short circuit), but this should be something you do rarely enough that it doesn't matter.</p>
<p>If you'd like to download the script, it's available in my <a href="https://github.com/jpverkamp/dotfiles">dotfiles</a>: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/who-iam">who-iam</a></p>]]></content></entry><entry><title>Pacifica II</title><link href="http://blog.jverkamp.com/2015/07/19/pacifica-ii" /><id>urn:uuid:383c47d0-4a3c-abcc-e80d-8b6da43ee4d0</id><updated>2015-07-19T00:00:00Z</updated><summary type="html"><![CDATA[<p>Another trip to Pacifica towards the end of the day. I had a bit of fun with a polarizing filter and HDR shots. Take a wild guess which shots those were. :)</p>
<div><div class="flickr-gallery" data-set-id="72157655694180549" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157655694180549">View on Flickr</a></p></div>]]></summary><content type="html"><![CDATA[<p>Another trip to Pacifica towards the end of the day. I had a bit of fun with a polarizing filter and HDR shots. Take a wild guess which shots those were. :)</p>
<div><div class="flickr-gallery" data-set-id="72157655694180549" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157655694180549">View on Flickr</a></p></div>]]></content></entry><entry><title>Automagically storing Python objects in Redis</title><link href="http://blog.jverkamp.com/2015/07/16/automagically-storing-python-objects-in-redis" /><id>urn:uuid:e83d21ba-8555-bfba-b05f-ceefc0808723</id><updated>2015-07-16T00:00:00Z</updated><summary type="html"><![CDATA[<p>When you're starting out on a simple web application, eventually<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> you will reach the point where you need to store some form of persistant data. Basically, you have three options<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>:</p>
<ul>
    <li>Store the information in flat files on the file system</li>
    <li>Store the information in a database (<a href="https://www.mysql.com/">MySQL</a>, <a href="https://www.sqlite.org/">SQLite</a> etc)</li>
    <li>Store the information in a key/value store (<a href="https://www.mongodb.org/">mongoDB</a>, <a href="http://redis.io/">reddis</a>)</li>
</ul>
<p>There are all manner of pros and cons to each, in particular how easy they are to get started in, how well they fit the data you are using, and how well they will scale horizontally (adding more machines rather than bigger ones).</p>
]]></summary><content type="html"><![CDATA[<p>When you're starting out on a simple web application, eventually<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> you will reach the point where you need to store some form of persistant data. Basically, you have three options<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>:</p>
<ul>
    <li>Store the information in flat files on the file system</li>
    <li>Store the information in a database (<a href="https://www.mysql.com/">MySQL</a>, <a href="https://www.sqlite.org/">SQLite</a> etc)</li>
    <li>Store the information in a key/value store (<a href="https://www.mongodb.org/">mongoDB</a>, <a href="http://redis.io/">reddis</a>)</li>
</ul>
<p>There are all manner of pros and cons to each, in particular how easy they are to get started in, how well they fit the data you are using, and how well they will scale horizontally (adding more machines rather than bigger ones).</p>
<!--more-->
<p>For the project that I was working on (I'll post about it eventually), I didn't have terribly many different kinds of data to store, so it would be easy enough to start with anything. I started with a simple file system backing, with one json file per object that I was storing. That worked well enough, but I didn't particularly care for having to write all of the code myself to join / find child objects. I wanted something a little more powerful.</p>
<p>Next, I considered using a database with an <a href="https://en.wikipedia.org/wiki/Object-relational_mapping">ORM</a> layer. That would let me define everything as Python objects and let the library handle all of the mappings to the actual database. That way, I could write a bare minimum of code for my actual models. Unfortunately, the data wasn't particularly well structured for a relational database, being more hierarchical in struture. It's entirely possible to represent hierarchical data in a relational database, it's just not what they are best suited for.</p>
<p>Finally, I came to Redis. I've used Redis in a few projects at work and come to really like it. It works great as a simple key/value store and even better when you start taking advatage of some of their other data structures. In particular, Redis hashes and lists map nicely to Python dicts and lists. So that's what I ended up doing: Writing a pair of base classes (<code>RedisDict</code> and <code>RedisList</code>) which to the programmer act just like a Python dict or list, but actually store all of their data transparently in Redis.</p>
<p>Let's get to it.</p>
<p>First, there is a bit of shared code that both <code>RedisDict</code> and <code>RedisList</code> share, which we can factor out into a base class for the two of them: <code>RedisObject</code>.</p>
<pre class="python"><code>import base64
import json
import redis
import os

class RedisObject(object):
    '''
    A base object backed by redis.
    Genrally, use RedisDict or RedisList rather than this directly.
    '''

    def __init__(self, id = None):
        '''Create or load a RedisObject.'''

        self.redis = redis.StrictRedis(host = 'redis', decode_responses = True)

        if id:
            self.id = id
        else:
            self.id = base64.urlsafe_b64encode(os.urandom(9)).decode('utf-8')

        if ':' not in self.id:
            self.id = self.__class__.__name__ + ':' + self.id

    def __bool__(self):
        '''Test if an object currently exists'''

        return self.redis.exists(self.id)

    def __eq__(self, other):
        '''Tests if two redis objects are equal (they have the same key)'''

        return self.id == other.id

    def __str__(self):
        '''Return this object as a string for testing purposes.'''

        return self.id

    def delete(self):
        '''Delete this object from redis'''

        self.redis.delete(self.id)

    @staticmethod
    def decode_value(type, value):
        '''Decode a value if it is non-None, otherwise, decode with no arguments.'''

        if value == None:
            return type()
        else:
            return type(value)

    @staticmethod
    def encode_value(value):
        '''Encode a value using json.dumps, with default = str'''

        return str(value)</code></pre>
<p>Most of that should be pretty straight forward. The basic idea is that any <code>RedisObject</code>, be it a <code>RedisDict</code> or a <code>RedisList</code> has an ID. This will be used as the key that Redis stores the object under. In particular, I've used a neat (in my opinion) trick to generate random alphanumeric identifiers:</p>
<pre class="python"><code>&gt;&gt;&gt; base64.urlsafe_b64encode(os.urandom(9)).decode('utf-8')
u'UQTfwq8XLZr6'</code></pre>
<p>Neat. Alternatively, if you want to use a specific value for an ID (such as a user's email address), you can just specify that instead. Next, the <code>__bool__</code> method will make a <code>RedisObject</code> 'truthy'. You can use Python's <code>if</code> to tell if an object acutally exists or not. Finally, <code>delete</code>. I wanted to use <code>__del__</code> originally, but that actually gets called when an object is garbage collected, which doesn't quite work for this usage<span class="footnote"><sup><a href="#footnote-3">[3]</a></sup></span></p>
<p>Finally, static helper functions <code>decode_value</code> and <code>encode_value</code>. These will be used in a bit, since Redis only stores strings. Thus a <code>RedisObject</code> stores the type of each value and needs to know how to read/write that in a systematic way. For that, I'm using Python's <code>json</code> encoding, falling back to <code>str</code> (and thus the <code>__str__</code> magic function on objects). This will deal nicely with most default Python objects and can be easily extended for all manner of more interesting ones if you'd like (I've done it for <code>RedisObject</code>s).</p>
<p>One oddity that you've probably noticed is that I've hard coded the Reids IP to connect to. I'm using <a href="https://github.com/docker/compose">docker-compose</a> to run my project, which sets up hostnames automagically within the various containers.</p>
<p>Next, <code>RedisDict</code>:</p>
<pre class="python"><code>import json
import redis

from lib.RedisObject import RedisObject

class RedisDict(RedisObject):
    '''An equivalent to dict where all keys/values are stored in Redis.'''

    def __init__(self, id = None, fields = {}, defaults = None):
        '''
        Create a new RedisObject
        id: If specified, use this as the redis ID, otherwise generate a random ID.
        fields: A map of field name to construtor used to read values from redis.
            Objects will be written with json.dumps with default = str, so override __str__ for custom objects.
            This should generally be set by the subobject's constructor.
        defaults: A map of field name to values to store when constructing the object.
        '''

        RedisObject.__init__(self, id)

        self.fields = fields

        if defaults:
            for key, val in defaults.items():
                self[key] = val

    def __getitem__(self, key):
        '''
        Load a field from this redis object.
        Keys that were not specified in self.fields will raise an exception.
        Keys that have not been set (either in defaults or __setitem__) will return the default for their type (if set)
        '''

        if key == 'id':
            return self.id

        if not key in self.fields:
            raise KeyError('{} not found in {}'.format(key, self))

        return RedisObject.decode_value(self.fields[key], self.redis.hget(self.id, key))

    def __setitem__(self, key, val):
        '''
        Store a value in this redis object.
        Keys that were not specified in self.fields will raise an exception.
        Keys will be stored with json.dumps with a default of str, so override __str__ for custom objects.
        '''

        if not key in self.fields:
            raise KeyError('{} not found in {}'.format(key, self))

        self.redis.hset(self.id, key, RedisObject.encode_value(val))

    def __iter__(self):
        '''Return (key, val) pairs for all values stored in this RedisDict.'''

        yield ('id', self.id.rsplit(':', 1)[-1])

        for key in self.fields:</code></pre>
<p>Basically, there are three interesting parts to this code: <code>__init__</code> stores the fields that this object has (and should be set by the constructors in subclasses) and can also be used as as a constructor for new objects. <code>__get/setitem__</code> will load/store items via Redis. Given the <code>encode/decode_value</code> functions in <code>RedisObject</code>, this is actually really straight forward.</p>
<p>So how would you use something like this?</p>
<p>Here's is most of the <code>User</code> class from the project I am working on:</p>
<pre class="python"><code>import bcrypt

import lib
import models
import utils

class User(lib.RedisDict):
    '''A user. Duh.'''

    def __init__(self, id = None, email = None, **defaults):

        # Use email as id, if specified
        if email:
            id = email
            defaults['email'] = email

        lib.RedisDict.__init__(
            self,
            id = email,
            fields = {
                'name': str,
                'email': str,
                'password': str,
                'friends': lib.RedisList.as_child(self, 'friends', models.User),
            },
            defaults = defaults
        )

    def __setitem__(self, key, val):
        '''Override the behavior if user is trying to change the password'''

        if key == 'password':
            val = bcrypt.hashpw(
                val.encode('utf-8'),
                bcrypt.gensalt()
            ).decode('utf-8')

        lib.RedisDict.__setitem__(self, key, val)

    def verifyPassword(self, testPassword):
        '''Verify if a given password is correct'''

        hashedTestPassword = bcrypt.hashpw(
            testPassword.encode('utf-8'),
            self['password'].encode('utf-8')
        ).decode('utf-8')

        return hashedTestPassword == self['password']</code></pre>
<p>A <code>User</code> will have four fields: a <code>name</code>, an <code>email</code>, a <code>password</code>, and a list of <code>friends</code> (we'll get to how that works in a bit). Then, I've added some custom code to automatically store passwords using <a href="https://en.wikipedia.org/wiki/bcrypt">bcrypt</a><span class="footnote"><sup><a href="#footnote-4">[4]</a></sup></span>. You can use it just like you would a <code>dict</code>:</p>
<pre class="python"><code>&gt;&gt;&gt; han = User(
...     name = 'Luke Skywalker',
...     email = 'luke@rebel-alliance.io',
...     password = 'TheForce',
... )
...

&gt;&gt;&gt; print(luke['name'])
Luke Skywalker

&gt;&gt;&gt; luke.verifyPassword('password')
False

&gt;&gt;&gt; luke.verifyPassword('TheForce')
True

&gt;&gt;&gt; han = User(
...     name = 'Han Solo',
...     email = 'han@rebel-alliance.io',
...     password = 'LetTheWookieWin',
... )
...

&gt;&gt;&gt; luke['friends'].append(han)

&gt;&gt;&gt; han['friends'].append(luke)

&gt;&gt;&gt; print(luke['friends'][0]['name'])
'Han Solo'</code></pre>
<p>Then we can go into the <code>redis-cli</code> to verify that everything saved correctly:</p>
<pre class="bash"><code>127.0.0.1:6379&gt; keys *
1) "User:han@rebel-alliance.io:friends"
2) "User:han@rebel-alliance.io"
3) "User:luke@rebel-alliance.io:friends"
4) "User:luke@rebel-alliance.io"

127.0.0.1:6379&gt; hgetall User:luke@rebel-alliance.io
1) "name"
2) "Luke Skywalker"
3) "email"
4) "luke@rebel-alliance.io"
5) "password"
6) "$2b$12$XQ1zDvl5PLS6g.K64H27xewPQMnkELa3LvzFSyay8p9kz0XXHVOFq"

127.0.0.1:6379&gt; lrange User:luke@rebel-alliance.io:friends 0 -1
1) "User:han@rebel-alliance.io"</code></pre>
<p>There are two entires for each, since technically the <code>friends</code> list is a <code>RedisList</code>. Originally, I was storing these as JSON encoded lists, but as they got larger, this started to get a little unweildy.</p>
<p>Another plus is that since all of the objects are backed by Redis, you get automatic persistance. Stop Python completely, start it back up, and you can just load the same objects again (remember, for these objects, I'm using the <code>email</code> as the ID):</p>
<pre class="python"><code>&gt;&gt;&gt; luke = User('luke@rebel-alliance.io')

&gt;&gt;&gt; print(luke['friends'][0]['name'])
'Han Solo'</code></pre>
<p>Very cool.</p>
<p>So, speaking of <code>RedisList</code>, how does that work? Mostly the same as <code>RedisDict</code> (although I had a few more functions to implement):</p>
<pre class="python"><code>import json
import redis

from lib.RedisObject import RedisObject

class RedisList(RedisObject):
    '''An equivalent to list where all items are stored in Redis.'''

    def __init__(self, id = None, item_type = str, items = None):
        '''
        Create a new RedisList
        id: If specified, use this as the redis ID, otherwise generate a random ID.
        item_type: The constructor to use when reading items from redis.
        values: Default values to store during construction.
        '''

        RedisObject.__init__(self, id)

        self.item_type = item_type

        if items:
            for item in items:
                self.append(item)

    @classmethod
    def as_child(cls, parent, tag, item_type):
        '''Alternative callable constructor that instead defines this as a child object'''

        def helper(_ = None):
            return cls(parent.id + ':' + tag, item_type)

        return helper

    def __getitem__(self, index):
        '''
        Load an item by index where index is either an int or a slice
        Warning: this is O(n))
        '''

        if isinstance(index, slice):
            if slice.step != 1:
                raise NotImplemented('Cannot specify a step to a RedisObject slice')

            return [
                RedisObject.decode_value(self.item_type, el)
                for el in self.redis.lrange(self.id, slice.start, slice.end)
            ]
        else:
            return RedisObject.decode_value(self.item_type, self.redis.lindex(self.id, index))

    def __setitem__(self, index, val):
        '''Update an item by index
        Warning: this is O(n)
        '''

        self.redis.lset(self.id, index, RedisObject.encode_value(val))

    def __len__(self):
        '''Return the size of the list.'''

        return self.redis.llen(self.id)

    def __delitem__(self, index):
        '''Delete an item from a RedisList by index. (warning: this is O(n))'''

        self.redis.lset(self.id, index, '__DELETED__')
        self.redis.lrem(self.id, 1, '__DELETED__')

    def __iter__(self):
        '''Iterate over all items in this list.'''

        for el in self.redis.lrange(self.id, 0, -1):
            yield RedisObject.decode_value(self.item_type, el)

    def lpop(self):
        '''Remove and return a value from the left (low) end of the list.'''

        return RedisObject.decode_value(self.item_type, self.redis.lpop(self.id))

    def rpop(self):
        '''Remove a value from the right (high) end of the list.'''

        return RedisObject.decode_value(self.item_type, self.redis.rpop(self.id))

    def lpush(self, val):
        '''Add an item to the left (low) end of the list.'''

        self.redis.lpush(self.id, RedisObject.encode_value(val))

    def rpush(self, val):
        '''Add an item to the right (high) end of the list.'''

        self.redis.rpush(self.id, RedisObject.encode_value(val))

    def append(self, val):
        self.rpush(val)</code></pre>
<p>Basically, I'm mapping a lot of the default Python <code>list</code> functionality to Redis lists and vice versa<span class="footnote"><sup><a href="#footnote-5">[5]</a></sup></span>. It's a little odd and some things aren't as efficient as I'd like (you only get <code>O(1)</code> access to the beginning and end of the list), but so it goes. It works great, as you saw in the <code>friends</code> example above.</p>
<p>The one interesting function is <code>as_child</code>. Since either a <code>RedisDict</code> or a <code>RedisList</code> expect a 'constructor-like' function as the data type, I need something that will correctly store a <code>RedisList</code> inside of a <code>RedisDict</code> while generating a human readable ID (with <code>:friends</code> appended in the example above). I love <a href="https://en.wikipedia.org/wiki/higher_order functions">higher order functions</a>.</p>
<p>And... that's it. Eventually, I think I'll look into publishing this as a library to <code>pip</code> or the like. But since I've never done that before and this post is already a little on the long sice, we'll leave that for another day. All of the code is included in the post, so you can copy and paste it into your project if you'd like to try it out before I publish it. Once I have, I'll edit this post.</p>]]></content></entry><entry><title>Backing up Moves Data</title><link href="http://blog.jverkamp.com/2015/07/10/backing-up-moves-data" /><id>urn:uuid:2eed2118-1b61-a7ab-1b50-35fe8d9c2baa</id><updated>2015-07-10T00:00:00Z</updated><summary type="html"><![CDATA[<p>Another <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup post</a>, this time I'm going to back up my data from the <a href="https://www.moves-app.com/">Moves App</a> (step counter + GPS tracker). Theoretically, it should be possible to get this same data from the app as part of my <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">iOS Backup</a> series, but the data there is in a strange binary format. Much easier to use their API.</p>
]]></summary><content type="html"><![CDATA[<p>Another <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup post</a>, this time I'm going to back up my data from the <a href="https://www.moves-app.com/">Moves App</a> (step counter + GPS tracker). Theoretically, it should be possible to get this same data from the app as part of my <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">iOS Backup</a> series, but the data there is in a strange binary format. Much easier to use their API.</p>
<!--more-->
<p>The first step will be to make a few helper methods. As I often do with web scripts, I'll be using <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the excellent <a href="http://docs.python-requests.org/en/latest/">Requests</a> library. First things first, we have to get an <code>access_token</code> using an <a href="https://en.wikipedia.org/wiki/OAuth">OAuth</a> handshake. It's a little complicated since our app is designed to run from the command line, yet needs to interact with the user on initial set up, but luckily that only has to be done once:</p>
<pre class="python"><code># Request a new access token

if not 'access_token' in config:
    url = 'https://api.moves-app.com/oauth/v1/authorize?response_type=code&client_id={client_id}&scope={scope}'.format(
        client_id = config['client_id'],
        scope = 'activity location'
    )
    print('Opening URL in browser...')
    webbrowser.open(url)
    code = raw_input('Please follow prompts and enter code: ')

    response = requests.post('https://api.moves-app.com/oauth/v1/access_token?grant_type=authorization_code&code={code}&client_id={client_id}&client_secret={client_secret}&redirect_uri={redirect_uri}'.format(
        code = code,
        client_id = config['client_id'],
        client_secret = config['client_secret'],
        redirect_uri = 'http://localhost/',
    ))
    js = response.json()
    print(js)

    config['access_token'] = js['access_token']
    config['refresh_token'] = js['refresh_token']
    config['user_id'] = js['user_id']

    with open('config.yaml', 'w') as fout:
        yaml.safe_dump(config, fout, default_flow_style=False)</code></pre>
<p>Basically, we have to have two values to start the handshake: <code>client_id</code> and <code>client_secret</code>. I've put those in a separate file (<code>config.yaml</code>) so that we don't have secrets in a repository. From there, we make a request to a given endpoint (see above), which opens in a browser. The user then gets an eight digit code which they enter in the app on the phone, prompting the web browser in turn to redirect with a <code>code</code> parameter. This part is a little ugly and I could make it much nicer by running a temporary single endpoint server, but since this only needs to be done once, I didn't bother.</p>
<p>After that, we take the <code>code</code> we just got, along with the <code>client_id</code> and <code>client_secret</code> and get the initial <code>access_token</code> and a <code>refresh_token</code> we can periodically use to prove we're still the same person.</p>
<p>Next, a little bit of framework. We'll wrap the default <code>requests</code> object to automatically provide an <code>access_token</code> to any <code>GET</code> or <code>POST</code> requests I want to make to the API, now that I've gotten one:</p>
<pre class="python"><code>def makeMethod(f):
    def run(url, **kwargs):

        if 'access_token' in config:
            headers = {'Authorization': 'Bearer {access_token}'.format(access_token = config['access_token'])}
        else:
            headers = {}

        url = 'https://api.moves-app.com/api/1.1' + url.format(**kwargs)

        if 'data' in kwargs:
            return f(url, data = kwargs['data'], headers = headers)
        else:
            return f(url, headers = headers)

    return run

get = makeMethod(requests.get)
post = makeMethod(requests.post)</code></pre>
<p>With that, we can just always use that <code>refresh_token</code> we got above every time we run the script. This is definitely over kill, but it saves a little bit of logic telling when we have to refresh the code or not and doesn't really cost anything more than a single extra request:</p>
<pre class="python"><code># Perform a refresh on the access token just as a matter of course

response = requests.post('https://api.moves-app.com/oauth/v1/access_token', data = {
    'grant_type': 'refresh_token',
    'refresh_token': config['refresh_token'],
    'client_id': config['client_id'],
    'client_secret': config['client_secret']
})
js = response.json()

config['access_token'] = js['access_token']
config['refresh_token'] = js['refresh_token']
config['user_id'] = js['user_id']

with open('config.yaml', 'w') as fout:
    yaml.safe_dump(config, fout, default_flow_style=False)</code></pre>
<p>Next, fetch my user profile:</p>
<pre class="python"><code># Load the user profile to see how far back data goes

user_profile = get('/user/profile').json()</code></pre>
<p>The most interesting bit of information here is <code>.profile.firstDate</code>, which tells us when we first started using Moves. We can then loop from that date forward in time, grabbing any days we are missing. Since sometimes previous days aren't completely done processing the next morning, I'll also always re-download the last week's worth of data no matter what.</p>
<pre class="python"><code># Loop through all missing files, or force load anything less than a week ago

date = datetime.datetime.strptime(user_profile['profile']['firstDate'], '%Y%m%d')
today = datetime.datetime.now()
oneWeekAgo = today - datetime.timedelta(days = 7)

while date &lt; today:
    dir = os.path.join('data', date.strftime('%Y'), date.strftime('%m'))
    filename = os.path.join(dir, date.strftime('%d') + '.json')

    if not date &gt; oneWeekAgo and os.path.exists(filename):
        date += datetime.timedelta(days = 1)
        continue

    if not os.path.exists(dir):
        os.makedirs(dir)

    print(filename)

    response = get('/user/storyline/daily/{date}?trackPoints=true', date = date.strftime('%Y%m%d'))

    if response.status_code != 200:
        print('Bad response, stopping')
        print(response.text)
        sys.exit(0)

    if int(response.headers['x-ratelimit-minuteremaining']) &lt; 1:
        print('Rate limited, waiting one minute before continuing')
        time.sleep(60)

    if int(response.headers['x-ratelimit-hourremaining']) &lt; 1:
        print('Rate limited, wait one hour and try again')
        time.sleep(3600)

    with codecs.open(filename, 'w', 'utf-8') as fout:
        fout.write(response.text)

    date += datetime.timedelta(days = 1)</code></pre>
<p>There is a neat bit in there with the <code>x-ratelimit-minuteremaining</code> and <code>x-ratelimit-hourremaining</code>. If we're downloading the entire history for the first time, you're going to get rate limited. So in this case, we'll wait a minute or an hour until the rate limit has expired.</p>
<p>And that's it. In the end, I end up with a pile of files, one for each day, each with exactly where I was on that day. I can use that data for all sorts of interesting analytics, like how far I walk in the average week, what my area of influence is, or even to combine with my <a href="http://blog.jverkamp.com/category/photography">photography</a> so that I can geotag my pictures. It's a lot of fun.</p>
<p>So, yes. I am something of a digital hoarder. But on the flip side, storage space is cheap and data is interesting. Perhaps I'll get a post or two out of making pretty pretty pictures out of where all I've been!</p>
<p>If you'd like to see / download the entire script for my Moves backup (or any of my other non-iOS backups, those are <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">here</a>), you can do so here: <a href="https://github.com/jpverkamp/backup">jpverkamp/backup on GitHub</a></p>]]></content></entry><entry><title>Muir Woods</title><link href="http://blog.jverkamp.com/2015/07/03/muir-woods" /><id>urn:uuid:c635c0f1-c2f0-1d7c-9141-7ae3bdcca075</id><updated>2015-07-03T00:00:00Z</updated><summary type="html"><![CDATA[<p>Finally made it to Muir Woods. A lovely place, even if entirely too busy. Also, my camera's battery ran out, so half of these were actually taken with my phone--which actually works pretty well.</p>
<div><div class="flickr-gallery" data-set-id="72157653090636294" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157653090636294">View on Flickr</a></p></div>]]></summary><content type="html"><![CDATA[<p>Finally made it to Muir Woods. A lovely place, even if entirely too busy. Also, my camera's battery ran out, so half of these were actually taken with my phone--which actually works pretty well.</p>
<div><div class="flickr-gallery" data-set-id="72157653090636294" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157653090636294">View on Flickr</a></p></div>]]></content></entry><entry><title>Scraping Kindle Highlights</title><link href="http://blog.jverkamp.com/2015/07/02/scraping-kindle-highlights" /><id>urn:uuid:607a86a7-2b7b-24ef-d68a-fed6db77517e</id><updated>2015-07-02T00:00:00Z</updated><summary type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
]]></summary><content type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
<!--more-->
<p>First, we are going to be using a Requests <code>session</code>. This will keep track of any cookies that Amazon decides to send us so that we know that we're logged in.</p>
<pre class="python"><code>session = requests.Session()</code></pre>
<p>After that, the next thing we need to do is to use requests to log into Amazon. Loading up the login page (<code>https://kindle.amazon.com/login</code>), we see that the <code>form</code> target is a <code>POST</code> request to <code>https://www.amazon.com/ap/signin</code>, specifying the fields <code>email</code> and <code>password</code>. Something like this:</p>
<pre class="python"><code>signin_data = {}

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)</code></pre>
<p>I'm reading my Amazon username and password from the environment. In general, that means I can have a simple file like this:</p>
<pre class="bash"><code>export AMAZON_USERNAME="me@example.com"
export AMAZON_PASSWORD="correct horse battery staple"</code></pre>
<p>Then I can source that script before running my program:</p>
<pre class="bash"><code>. ./env.conf && python3 kindle-highlights-backups.py</code></pre>
<p>That should work, but unfortunately it doesn't. It looks like Amazon is sending a small pile of hidden fields. Theoretically, I could look at the page and hard code them, but where's the fun in that? Instead, let's use Requests to grab the login page and BeautifulSoup to parse out all of the fiels we're going to send:</p>
<pre class="python"><code># Log in to Amazon, we have to get the real login page to bypass CSRF
print('Logging in...')
response = session.get('https://kindle.amazon.com/login')
soup = bs4.BeautifulSoup(response.text)

signin_data = {}
signin_form = soup.find('form', {'name': 'signIn'})
for field in signin_form.find_all('input'):
    try:
        signin_data[field['name']] = field['value']
    except:
        pass

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)
if response.status_code != 200:
    print('Failed to login: {0} {1}'.format(response.status_code, response.reason))
    sys.exit(0)</code></pre>
<p>... Still doesn't work. I'm getting a page back that says I need to enable cookies, which I most definitely have enabled (that's why I created the <code>session</code>). A bit of Google-fu later, and I find out that Amazon will only allow connections from semi-reasonable <a href="https://en.wikipedia.org/wiki/User_Agents">User Agents</a>. Let's set it to a recent Chrome build on Windows 8.1:</p>
<pre class="python"><code>session = requests.Session()
session.headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.61 Safari/537.36'
}</code></pre>
<p>Ah ha! That works. Finally logged in. Next, we know that we can get a list of your current books by going to <code>https://kindle.amazon.com/your_reading/0/0/0</code>. The last three numbers are:</p>
<ul>
    <li>mode (all, read, reading)</li>
    <li>starting index / page (increments in 25)</li>
    <li>all books (0) versus kindle only (1)</li>
</ul>
<p>So let's write a loop to keep fetching pages of these books, 25 at a time:</p>
<pre class="python"><code># Iterate through pages of books, 25 at a time
# Note: The last three parts of the URL are:
#   - mode (all, read, reading)
#   - starting index / page (increments in 25)
#   - all books (0) versus kindle only (1)
print('Getting books...')
book_page = 0
while True:
    time.sleep(0.5) # Half a second between pages

    response = session.get('https://kindle.amazon.com/your_reading/0/{book_page}/0'.format(book_page = book_page))
    soup = bs4.BeautifulSoup(response.text)
    found_book = False

    ...

    if found_book:
        book_page += 25
    else:
        break</code></pre>
<p>Within that page, there are a series of <code>td</code> elements linking to books, each with the class <code>titleAndAuthor</code>. That's the beauty of BeautifulSoup:</p>
<pre class="python"><code>...

# For each page of books, find all of the individual book links
# The last part of each URL is Amazon's internal ID for that book
for el in soup.findAll('td', {'class': 'titleAndAuthor'}, recursive = True):
    time.sleep(0.1) # 1/10 of a second between books

    found_book = True

    book_id = el.find('a')['href'].split('/')[-1]
    title = el.find('a').text
    sys.stdout.write(title + ' ... ')

    highlights = []
    cursor = 0

    ...</code></pre>
<p>Luckily, the next part is a little easier to deal with. There is actually an API of sorts of Kindle highlights, once you have a user ID. All you have to do is hit <code>https://kindle.amazon.com/kcw/highlights?asin={book_id}</code> (potentially many times, it's <a href="https://en.wikipedia.org/wiki/paginated">paginated</a>):</p>
<pre class="python"><code>...

# Ask the Amazon API for highlights one page of 10 at a time until we have them all
while True:
    response = session.get('https://kindle.amazon.com/kcw/highlights?asin={book_id}&cursor={cursor}&count=10'.format(
        book_id = book_id,
        cursor = cursor,
    ))
    js = response.json()

    found_highlight = False
    for item in js['items']:
        found_highlight = True
        item['highlight'] = html_unescape(item['highlight'])
        highlights.append(item)

    if found_highlight:
        cursor +=1
    else:
        break

...</code></pre>
<p>One caveat is that we don't want to store HTML entities (like <code>&amp;rsquo;</code>), we want the real characters. This is a little annoying, since the library to parse that has moved around in various Python versions:</p>
<pre class="python"><code># Get a function to unescape html entites
try:
    import html
    html_unescape = html.unescape
except:
    try:
        import html.parser
        html_unescape = html.parser.HTMLParser().unescape
    except:
        import HTMLParser
        html_unescape = HTMLParser.HTMLParser().unescape</code></pre>
<p>Yeah...</p>
<p>Now that we have a list of highlights, let's save them to disk. Generate a filename from the book title, and use the <code>json</code> library to write them out. Make sure that we're writing everything as UTF8 so that any more unusual characters (like more interesting quotes) save correctly:</p>
<pre class="python"><code># Use book title as filename, but strip out 'dangerous' characters
print('{count} highlights found'.format(count = len(highlights)))
if highlights:
    filename = re.sub(r'[\/:*?"&lt;&gt;|"\']', '', title).strip() + '.json'
    path = os.path.join('Kindle Highlights', filename)

    with open(path, 'w', encoding = 'utf8') as fout:
        fout.write(json.dumps(highlights, fout, indent = 4, sort_keys = True, ensure_ascii = False))</code></pre>
<p>And there you have it. A simple(ish) way to download your Kindle highlights.</p>
<p>Unfortunately... that's not all she wrote. After running my script for a few days, it started to fail. Why? Because Amazon detected some strange activity on my account and started displaying a captcha. I can detect it easily enough:</p>
<pre class="python"><code>warning = soup.find('div', {'id': 'message_warning'})
if warning:
    print('Failed to login: {0}'.format(warning.text))
    sys.exit(0)</code></pre>
<p>Put that just after the previous 'Failed to login' block and you'll seem some text to the order of 'please enter these characters to continue'. It's actually not that hard to solve a catcha programmatically... but we'll save that for another post.</p>
<p>And that's it for today. So far I have 308 highlights spread over 20 books and it's only growing. It's fun to go back and read them again.</p>]]></content></entry><entry><title>Half Moon Bay II</title><link href="http://blog.jverkamp.com/2015/06/27/half-moon-bay-ii" /><id>urn:uuid:cdd234b5-81ef-db26-158c-887e1b22cdb9</id><updated>2015-06-27T00:00:00Z</updated><summary type="html"><![CDATA[<p>Back to Half Moon Bay. We didn't park on site, but given all the neat things we saw, I'm okay with this.</p>
<div><div class="flickr-gallery" data-set-id="72157654753756870" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157654753756870">View on Flickr</a></p></div>]]></summary><content type="html"><![CDATA[<p>Back to Half Moon Bay. We didn't park on site, but given all the neat things we saw, I'm okay with this.</p>
<div><div class="flickr-gallery" data-set-id="72157654753756870" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157654753756870">View on Flickr</a></p></div>]]></content></entry><entry><title>Rama</title><link href="http://blog.jverkamp.com/2015/06/21/rama" /><id>urn:uuid:c1c3658d-eaa4-7e51-eefd-9ef913d82666</id><updated>2015-06-21T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a> <a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<p><a href="https://www.goodreads.com/series/49121-rama">Rama</a> by <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a> and <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>.</p>
<p>I'm going to try something a little different this time. On previous series, I found it hard to write a blog post after reading several books back to back, I've been reviewing each book individual <a href="https://www.goodreads.com/user/show/8261480-jp">on Goodreads</a> as I've read it. I have a short summary for the entire series, followed by the individual books. We'll see how it goes.</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a> <a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<p><a href="https://www.goodreads.com/series/49121-rama">Rama</a> by <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a> and <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>.</p>
<p>I'm going to try something a little different this time. On previous series, I found it hard to write a blog post after reading several books back to back, I've been reviewing each book individual <a href="https://www.goodreads.com/user/show/8261480-jp">on Goodreads</a> as I've read it. I have a short summary for the entire series, followed by the individual books. We'll see how it goes.</p>
<!--more-->
<p>Overall, I like the first book (the only by only <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a>, the rest were all co-authored by<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>). It's the kind of science fiction driven not particularly by plot or character, but rather by discovery and exploration. It's not always done well, but in this case I particularly enjoyed it. Conversely though, the other three in the series have much more focus on character conflict and to a lesser extent (but more than Rama) a central plot.</p>
<p>That change in style really turned me off the second book in the series, to the extent that I almost didn't finish the series. I'm glad I did though. Each of the sequels (in particularly the first part of #2 and most of #4) has some interesting ideas and solid extensions of Clarke's original world.</p>
<p>If you're into more interested in the science part of science fiction, you could do far worse than Rama. If, on the other hand, you want a story with more depth to the characters and plots, give Rama II a chance (although just keep in mind that Rama and Rama II are fairly different). If you are a completionist, the last book is actually pretty good and does a reasonably good job of tying up a lot of loose ends from the previous books.</p>
<p>Now, the individual reviews. Warning, there will be (usually minor) spoilers!</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a></p>
<h3>Rama</h3>
<p>It's been a little while since I've read much science fiction, particularly any of the sort that Clarke is known for. Forget strong plot or characters and focus entirely around the big idea: In this case, the starship Rama is plenty large.</p>
<p>It starts off quickly, only a few chapters before you're on the ship. From there, you have situation after situation, describing how interesting the world that Clarke has built is and how the explorers react to it. The lack of a more specific antagonist becomes more of a problem towards then end, in that the book just sort of ends. There are various problems throughout the book, but no sense of building. I'm still not entirely sure how much I like this style.</p>
<p>Overall though, I think it's a cool world and I want to know more. Given that the sequels were written many years later and co-written by an author with a somewhat different style (based on the forward in Rama II), it will be interesting to see how different they are.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a></p>
<h3>Rama II</h3>
<p>This book feels rather different from Rendezvous with Rama.</p>
<p>For the first half, I wasn't sure that I actually liked the difference. Rather than the almost sterile science fiction that Clarke is better known for, the sequel deals a lot more with characters, drama, and to some extent matters of faith. It's especially interesting in how long it takes them to even get to Rama, especially compared to the first book.</p>
<p>Through the next quarter though, it really started picking up. I started to actually care about the characters and couldn't put it down. The feel of the ship, especially with some of the new findings, is just different enough that I wanted to know more.</p>
<p>At first, I wasn't sure that I was going to read the other two sequels. After this, I'm not sure how I couldn't.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a></p>
<h3>The Garden of Rama</h3>
<p>Like Rama #2, I went back and forth while reading this one on if I was actually enjoying it or if I would finish it at all. In the end, I did finish it and I think I'll even start the last one mostly out of a sense of completionism.</p>
<p>Essentially, there are five sections:</p>
<p>In the first, the three explorers from Rama II are leaving the solar system at high speeds. The parts where they are exploring the ship and learning how to live with the local 3D printer and interacting with other alien species is neat. The part where they decide that two men and a woman are enough to start a colony... That's just a little weird. I missed the first book, where the science and sense of exploration was the core of the story.</p>
<p>In the second, they get to a sort of routing section and finally meet an alien intelligence (even if it's still a robot). They (and by extension, we) get some neat answers. I liked this section for precisely the same reason I didn't like the first section: it's about exploring the world of Rama.</p>
<p>In the third, they go back to Earth, both in the context of the story and for a few scenes. They are all new characters and I cannot figure out why I care about any of them. Then they're sent off to a colony on Mars, except... surprise, they're actually going to make a new colony on the rebuilt Rama II. This is fine, but I feel like it could have been shortened.</p>
<p>In the fourth, the colony grows and thrives. Or not. Turns out people are people and people are terrible. Really, this whole section was depressing and not really what I was hoping to see in this book. I liked the smaller scales of the first 2.5 books. This not so much. Especially since it all ends up with exactly the sort of power struggle and corruption that I both see as entirely too plausible and hope isn't actually inevitable in such situations.</p>
<p>Finally, there's a big jump in the last ten percent or so where Robert goes to meet with the avian colony from the previous books. Suffice it to say, they have a strange lifecycle that we'd previously , which would have been much more interesting had Orson Scott Card not done it ~4 years earlier in Speaker for the Dead. It is exactly the sort of thing I wanted though, I just wish it had more relation to the rest of the story and had more than 10% of the pages. This is why I'm reading the 4th book, hoping there will be more of this.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<h3>Rama Revealed</h3>
<p>In my opinion, this was by far the best of the sequels.</p>
<p>They start by doing exactly what I wanted out of the middle two books: getting away from the human settlement and into a situation where they are learning and experiencing something strange. In this case, they go to live among the octospiders, an intelligent civilization highly skilled in genetics and biological science who are completely deaf and only speak in color. It's a fascinating and nicely thought out situation and I did like it.</p>
<p>Even when, halfway through the book, the focus shifts back partially to the rest of the human colony in Rama, it still maintains a tight focus, with the bigger scale events going on behind the scenes. There was still a particular feel of exploring how different societies deal with issues (such as war: the octospiders view all war as terrible, not just certain kinds).</p>
<p>The final section, when the return to another Node felt a little strange. Either because it was rushed or because it felt sort of artificial. I didn't particularly mind though, since it still was working out echoes of events from all of the previous books and acted as a sufficient capstone to the series. I did think it was nice that Michael and Simone make another appearance, even if the latter replied her mother's odd fixation with a two person continuation of the species.</p>
<p>At the very end, the book veers somewhat towards a philosophical / religions tangent, which felt a little odd (the Ramas are essentially God) but still thought provoking.</p>
<p>Overall, I was pleasantly surprised by this book. If you made it through the middle two books, you should probably read this one as well.</p>
<hr />
<p>Side note: I didn't finish Whitechapel Gods (which was actually next on my original <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>) since, after 20%, I just really wasn't getting into it. There are some really interesting ideas (a steampunkification disease for example), but it was hard to get a grasp on exactly what was going on. So it goes.</p>
<p>Overall, that 47 of 100 books for the year, exactly on schedule. Next up: <a href="https://www.goodreads.com/book/show/337048.The_Engines_of_God">The Engines of God</a> by <a href="https://www.goodreads.com/author/show/73812.Jack_McDevitt">Jack McDevitt</a>. At the same time, I'm also reading <a href="https://www.goodreads.com/book/show/101869.The_Atrocity_Archives">The Laundry Files</a> by <a href="https://www.goodreads.com/author/show/8794.Charles_Stross">Charles Stross</a> on a one chapter a day email list.</p>]]></content></entry><entry><title>American Gods</title><link href="http://blog.jverkamp.com/2015/05/26/american-gods" /><id>urn:uuid:37aa9547-ccce-5a9b-642f-434049c3983f</id><updated>2015-05-26T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/4407.American_Gods"><img src="http://blog.jverkamp.com/2015/05/26/american-gods/american-gods.jpg" /></a></p>
<p><a href="https://www.goodreads.com/book/show/4407.American_Gods">American Gods</a> falls on the unfortunately long list of books that I wish were better. It won (or was at least nominated) for a whole pile of awards<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>. It's by <a href="https://en.wikipedia.org/wiki/Neil_Gaiman">an author</a> who's works in other genres I've enjoyed (e.g. the movie Corline or his episodes on Doctor Who) and who seems like a solid person in real life.</p>
<p>I just couldn't get into it.</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/4407.American_Gods"><img src="http://blog.jverkamp.com/2015/05/26/american-gods/american-gods.jpg" /></a></p>
<p><a href="https://www.goodreads.com/book/show/4407.American_Gods">American Gods</a> falls on the unfortunately long list of books that I wish were better. It won (or was at least nominated) for a whole pile of awards<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>. It's by <a href="https://en.wikipedia.org/wiki/Neil_Gaiman">an author</a> who's works in other genres I've enjoyed (e.g. the movie Corline or his episodes on Doctor Who) and who seems like a solid person in real life.</p>
<p>I just couldn't get into it.</p>
<!--more-->
<p>It's a bummer, because it's such a fascinating world. I like the idea (shared by <a href="http://blog.jverkamp.com/2015/02/20/the-iron-druid-chronicles">The Iron Druid Chronicles</a>) that not only are the gods still walking among us, but also that a god can have more than one form, depending on how and when it was worshipped. I like the idea that the old gods are pissed at the new gods (Media / The Internet) for encroaching on their territory. I like how the old gods feel more 'human', only somehow <em>more</em> yet also somehow <em>less</em>.</p>
<p>But the story itself drags at points, with several sections (the dreams in particular) which I thought were interesting, but I wasn't entirely sure why they were there. I've heard it said that Gaiman cut half of American Gods even before it was released, but at ~650 pages, it's still a hefty tome. I think it could have lost a little more.</p>
<p>Conversely, I did think that most of the characters were pretty solid. I thought Shadow was a solid enough protagonist, going along with a world gone mad until he'd had enough... and then a step or two more. I felt for Mr. Wednesday, trying to take back pieces of a world gone wrong. I liked the little hints and pieces of how the gods' lives had changed on coming to the new world.</p>
<p>All in all, it's the sort of book that I'm glad that I've read... but I doubt I will ever reread. There are a few interesting ideas buried in there that I'm sure will surface years from now, long after I've forgotten where they came from.</p>
<p>Since it took me so long (Two weeks? Was it really that long?) to read American Gods, I'm now at only 42 of 100 for my <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, fallen from 7 ahead to 3. Still, onwards! Next up, with an amusingly related title<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>, <a href="https://www.goodreads.com/book/show/2302159.Whitechapel_Gods">Whitechapel Gods</a>.</p>]]></content></entry></feed>