<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jverkamp.com</title><link href="http://blog.jverkamp.com" /><link rel="self" href="http://blog.jverkamp.com/feed/" /><updated>2015-07-10T00:00:00Z</updated><author><name>JP Verkamp</name></author><id>urn:uuid:f148b655-ada3-c720-0c01-ca384ab68088</id><entry><title>Backing up Moves Data</title><link href="http://blog.jverkamp.com/2015/07/10/backing-up-moves-data" /><id>urn:uuid:2eed2118-1b61-a7ab-1b50-35fe8d9c2baa</id><updated>2015-07-10T00:00:00Z</updated><summary type="html"><![CDATA[<p>Another <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup post</a>, this time I'm going to back up my data from the <a href="https://www.moves-app.com/">Moves App</a> (step counter + GPS tracker). Theoretically, it should be possible to get this same data from the app as part of my <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">iOS Backup</a> series, but the data there is in a strange binary format. Much easier to use their API.</p>
]]></summary><content type="html"><![CDATA[<p>Another <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup post</a>, this time I'm going to back up my data from the <a href="https://www.moves-app.com/">Moves App</a> (step counter + GPS tracker). Theoretically, it should be possible to get this same data from the app as part of my <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">iOS Backup</a> series, but the data there is in a strange binary format. Much easier to use their API.</p>
<!--more-->
<p>The first step will be to make a few helper methods. As I often do with web scripts, I'll be using <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the excellent <a href="http://docs.python-requests.org/en/latest/">Requests</a> library. First things first, we have to get an <code>access_token</code> using an <a href="https://en.wikipedia.org/wiki/OAuth">OAuth</a> handshake. It's a little complicated since our app is designed to run from the command line, yet needs to interact with the user on initial set up, but luckily that only has to be done once:</p>
<pre class="python"><code># Request a new access token

if not 'access_token' in config:
    url = 'https://api.moves-app.com/oauth/v1/authorize?response_type=code&client_id={client_id}&scope={scope}'.format(
        client_id = config['client_id'],
        scope = 'activity location'
    )
    print('Opening URL in browser...')
    webbrowser.open(url)
    code = raw_input('Please follow prompts and enter code: ')

    response = requests.post('https://api.moves-app.com/oauth/v1/access_token?grant_type=authorization_code&code={code}&client_id={client_id}&client_secret={client_secret}&redirect_uri={redirect_uri}'.format(
        code = code,
        client_id = config['client_id'],
        client_secret = config['client_secret'],
        redirect_uri = 'http://localhost/',
    ))
    js = response.json()
    print(js)

    config['access_token'] = js['access_token']
    config['refresh_token'] = js['refresh_token']
    config['user_id'] = js['user_id']

    with open('config.yaml', 'w') as fout:
        yaml.safe_dump(config, fout, default_flow_style=False)</code></pre>
<p>Basically, we have to have two values to start the handshake: <code>client_id</code> and <code>client_secret</code>. I've put those in a separate file (<code>config.yaml</code>) so that we don't have secrets in a repository. From there, we make a request to a given endpoint (see above), which opens in a browser. The user then gets an eight digit code which they enter in the app on the phone, prompting the web browser in turn to redirect with a <code>code</code> parameter. This part is a little ugly and I could make it much nicer by running a temporary single endpoint server, but since this only needs to be done once, I didn't bother.</p>
<p>After that, we take the <code>code</code> we just got, along with the <code>client_id</code> and <code>client_secret</code> and get the initial <code>access_token</code> and a <code>refresh_token</code> we can periodically use to prove we're still the same person.</p>
<p>Next, a little bit of framework. We'll wrap the default <code>requests</code> object to automatically provide an <code>access_token</code> to any <code>GET</code> or <code>POST</code> requests I want to make to the API, now that I've gotten one:</p>
<pre class="python"><code>def makeMethod(f):
    def run(url, **kwargs):

        if 'access_token' in config:
            headers = {'Authorization': 'Bearer {access_token}'.format(access_token = config['access_token'])}
        else:
            headers = {}

        url = 'https://api.moves-app.com/api/1.1' + url.format(**kwargs)

        if 'data' in kwargs:
            return f(url, data = kwargs['data'], headers = headers)
        else:
            return f(url, headers = headers)

    return run

get = makeMethod(requests.get)
post = makeMethod(requests.post)</code></pre>
<p>With that, we can just always use that <code>refresh_token</code> we got above every time we run the script. This is definitely over kill, but it saves a little bit of logic telling when we have to refresh the code or not and doesn't really cost anything more than a single extra request:</p>
<pre class="python"><code># Perform a refresh on the access token just as a matter of course

response = requests.post('https://api.moves-app.com/oauth/v1/access_token', data = {
    'grant_type': 'refresh_token',
    'refresh_token': config['refresh_token'],
    'client_id': config['client_id'],
    'client_secret': config['client_secret']
})
js = response.json()

config['access_token'] = js['access_token']
config['refresh_token'] = js['refresh_token']
config['user_id'] = js['user_id']

with open('config.yaml', 'w') as fout:
    yaml.safe_dump(config, fout, default_flow_style=False)</code></pre>
<p>Next, fetch my user profile:</p>
<pre class="python"><code># Load the user profile to see how far back data goes

user_profile = get('/user/profile').json()</code></pre>
<p>The most interesting bit of information here is <code>.profile.firstDate</code>, which tells us when we first started using Moves. We can then loop from that date forward in time, grabbing any days we are missing. Since sometimes previous days aren't completely done processing the next morning, I'll also always re-download the last week's worth of data no matter what.</p>
<pre class="python"><code># Loop through all missing files, or force load anything less than a week ago

date = datetime.datetime.strptime(user_profile['profile']['firstDate'], '%Y%m%d')
today = datetime.datetime.now()
oneWeekAgo = today - datetime.timedelta(days = 7)

while date &lt; today:
    dir = os.path.join('data', date.strftime('%Y'), date.strftime('%m'))
    filename = os.path.join(dir, date.strftime('%d') + '.json')

    if not date &gt; oneWeekAgo and os.path.exists(filename):
        date += datetime.timedelta(days = 1)
        continue

    if not os.path.exists(dir):
        os.makedirs(dir)

    print(filename)

    response = get('/user/storyline/daily/{date}?trackPoints=true', date = date.strftime('%Y%m%d'))

    if response.status_code != 200:
        print('Bad response, stopping')
        print(response.text)
        sys.exit(0)

    if int(response.headers['x-ratelimit-minuteremaining']) &lt; 1:
        print('Rate limited, waiting one minute before continuing')
        time.sleep(60)

    if int(response.headers['x-ratelimit-hourremaining']) &lt; 1:
        print('Rate limited, wait one hour and try again')
        time.sleep(3600)

    with codecs.open(filename, 'w', 'utf-8') as fout:
        fout.write(response.text)

    date += datetime.timedelta(days = 1)</code></pre>
<p>There is a neat bit in there with the <code>x-ratelimit-minuteremaining</code> and <code>x-ratelimit-hourremaining</code>. If we're downloading the entire history for the first time, you're going to get rate limited. So in this case, we'll wait a minute or an hour until the rate limit has expired.</p>
<p>And that's it. In the end, I end up with a pile of files, one for each day, each with exactly where I was on that day. I can use that data for all sorts of interesting analytics, like how far I walk in the average week, what my area of influence is, or even to combine with my <a href="http://blog.jverkamp.com/category/photography">photography</a> so that I can geotag my pictures. It's a lot of fun.</p>
<p>So, yes. I am something of a digital hoarder. But on the flip side, storage space is cheap and data is interesting. Perhaps I'll get a post or two out of making pretty pretty pictures out of where all I've been!</p>
<p>If you'd like to see / download the entire script for my Moves backup (or any of my other non-iOS backups, those are <a href="http://blog.jverkamp.com/category/programming/by-project/ios-backup">here</a>), you can do so here: <a href="https://github.com/jpverkamp/backup">jpverkamp/backup on GitHub</a></p>]]></content></entry><entry><title>Muir Woods</title><link href="http://blog.jverkamp.com/2015/07/03/muir-woods" /><id>urn:uuid:c635c0f1-c2f0-1d7c-9141-7ae3bdcca075</id><updated>2015-07-03T00:00:00Z</updated><summary type="html"><![CDATA[<p>Finally made it to Muir Woods. A lovely place, even if entirely too busy. Also, my camera's battery ran out, so half of these were actually taken with my phone--which actually works pretty well.</p>
<div><div class="flickr-gallery" data-set-id="72157653090636294" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157653090636294">View on Flickr</a></p></div>]]></summary><content type="html"><![CDATA[<p>Finally made it to Muir Woods. A lovely place, even if entirely too busy. Also, my camera's battery ran out, so half of these were actually taken with my phone--which actually works pretty well.</p>
<div><div class="flickr-gallery" data-set-id="72157653090636294" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157653090636294">View on Flickr</a></p></div>]]></content></entry><entry><title>Scraping Kindle Highlights</title><link href="http://blog.jverkamp.com/2015/07/02/scraping-kindle-highlights" /><id>urn:uuid:607a86a7-2b7b-24ef-d68a-fed6db77517e</id><updated>2015-07-02T00:00:00Z</updated><summary type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
]]></summary><content type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
<!--more-->
<p>First, we are going to be using a Requests <code>session</code>. This will keep track of any cookies that Amazon decides to send us so that we know that we're logged in.</p>
<pre class="python"><code>session = requests.Session()</code></pre>
<p>After that, the next thing we need to do is to use requests to log into Amazon. Loading up the login page (<code>https://kindle.amazon.com/login</code>), we see that the <code>form</code> target is a <code>POST</code> request to <code>https://www.amazon.com/ap/signin</code>, specifying the fields <code>email</code> and <code>password</code>. Something like this:</p>
<pre class="python"><code>signin_data = {}

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)</code></pre>
<p>I'm reading my Amazon username and password from the environment. In general, that means I can have a simple file like this:</p>
<pre class="bash"><code>export AMAZON_USERNAME="me@example.com"
export AMAZON_PASSWORD="correct horse battery staple"</code></pre>
<p>Then I can source that script before running my program:</p>
<pre class="bash"><code>. ./env.conf && python3 kindle-highlights-backups.py</code></pre>
<p>That should work, but unfortunately it doesn't. It looks like Amazon is sending a small pile of hidden fields. Theoretically, I could look at the page and hard code them, but where's the fun in that? Instead, let's use Requests to grab the login page and BeautifulSoup to parse out all of the fiels we're going to send:</p>
<pre class="python"><code># Log in to Amazon, we have to get the real login page to bypass CSRF
print('Logging in...')
response = session.get('https://kindle.amazon.com/login')
soup = bs4.BeautifulSoup(response.text)

signin_data = {}
signin_form = soup.find('form', {'name': 'signIn'})
for field in signin_form.find_all('input'):
    try:
        signin_data[field['name']] = field['value']
    except:
        pass

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)
if response.status_code != 200:
    print('Failed to login: {0} {1}'.format(response.status_code, response.reason))
    sys.exit(0)</code></pre>
<p>... Still doesn't work. I'm getting a page back that says I need to enable cookies, which I most definitely have enabled (that's why I created the <code>session</code>). A bit of Google-fu later, and I find out that Amazon will only allow connections from semi-reasonable <a href="https://en.wikipedia.org/wiki/User_Agents">User Agents</a>. Let's set it to a recent Chrome build on Windows 8.1:</p>
<pre class="python"><code>session = requests.Session()
session.headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.61 Safari/537.36'
}</code></pre>
<p>Ah ha! That works. Finally logged in. Next, we know that we can get a list of your current books by going to <code>https://kindle.amazon.com/your_reading/0/0/0</code>. The last three numbers are:</p>
<ul>
    <li>mode (all, read, reading)</li>
    <li>starting index / page (increments in 25)</li>
    <li>all books (0) versus kindle only (1)</li>
</ul>
<p>So let's write a loop to keep fetching pages of these books, 25 at a time:</p>
<pre class="python"><code># Iterate through pages of books, 25 at a time
# Note: The last three parts of the URL are:
#   - mode (all, read, reading)
#   - starting index / page (increments in 25)
#   - all books (0) versus kindle only (1)
print('Getting books...')
book_page = 0
while True:
    time.sleep(0.5) # Half a second between pages

    response = session.get('https://kindle.amazon.com/your_reading/0/{book_page}/0'.format(book_page = book_page))
    soup = bs4.BeautifulSoup(response.text)
    found_book = False

    ...

    if found_book:
        book_page += 25
    else:
        break</code></pre>
<p>Within that page, there are a series of <code>td</code> elements linking to books, each with the class <code>titleAndAuthor</code>. That's the beauty of BeautifulSoup:</p>
<pre class="python"><code>...

# For each page of books, find all of the individual book links
# The last part of each URL is Amazon's internal ID for that book
for el in soup.findAll('td', {'class': 'titleAndAuthor'}, recursive = True):
    time.sleep(0.1) # 1/10 of a second between books

    found_book = True

    book_id = el.find('a')['href'].split('/')[-1]
    title = el.find('a').text
    sys.stdout.write(title + ' ... ')

    highlights = []
    cursor = 0

    ...</code></pre>
<p>Luckily, the next part is a little easier to deal with. There is actually an API of sorts of Kindle highlights, once you have a user ID. All you have to do is hit <code>https://kindle.amazon.com/kcw/highlights?asin={book_id}</code> (potentially many times, it's <a href="https://en.wikipedia.org/wiki/paginated">paginated</a>):</p>
<pre class="python"><code>...

# Ask the Amazon API for highlights one page of 10 at a time until we have them all
while True:
    response = session.get('https://kindle.amazon.com/kcw/highlights?asin={book_id}&cursor={cursor}&count=10'.format(
        book_id = book_id,
        cursor = cursor,
    ))
    js = response.json()

    found_highlight = False
    for item in js['items']:
        found_highlight = True
        item['highlight'] = html_unescape(item['highlight'])
        highlights.append(item)

    if found_highlight:
        cursor +=1
    else:
        break

...</code></pre>
<p>One caveat is that we don't want to store HTML entities (like <code>&amp;rsquo;</code>), we want the real characters. This is a little annoying, since the library to parse that has moved around in various Python versions:</p>
<pre class="python"><code># Get a function to unescape html entites
try:
    import html
    html_unescape = html.unescape
except:
    try:
        import html.parser
        html_unescape = html.parser.HTMLParser().unescape
    except:
        import HTMLParser
        html_unescape = HTMLParser.HTMLParser().unescape</code></pre>
<p>Yeah...</p>
<p>Now that we have a list of highlights, let's save them to disk. Generate a filename from the book title, and use the <code>json</code> library to write them out. Make sure that we're writing everything as UTF8 so that any more unusual characters (like more interesting quotes) save correctly:</p>
<pre class="python"><code># Use book title as filename, but strip out 'dangerous' characters
print('{count} highlights found'.format(count = len(highlights)))
if highlights:
    filename = re.sub(r'[\/:*?"&lt;&gt;|"\']', '', title).strip() + '.json'
    path = os.path.join('Kindle Highlights', filename)

    with open(path, 'w', encoding = 'utf8') as fout:
        fout.write(json.dumps(highlights, fout, indent = 4, sort_keys = True, ensure_ascii = False))</code></pre>
<p>And there you have it. A simple(ish) way to download your Kindle highlights.</p>
<p>Unfortunately... that's not all she wrote. After running my script for a few days, it started to fail. Why? Because Amazon detected some strange activity on my account and started displaying a captcha. I can detect it easily enough:</p>
<pre class="python"><code>warning = soup.find('div', {'id': 'message_warning'})
if warning:
    print('Failed to login: {0}'.format(warning.text))
    sys.exit(0)</code></pre>
<p>Put that just after the previous 'Failed to login' block and you'll seem some text to the order of 'please enter these characters to continue'. It's actually not that hard to solve a catcha programmatically... but we'll save that for another post.</p>
<p>And that's it for today. So far I have 308 highlights spread over 20 books and it's only growing. It's fun to go back and read them again.</p>]]></content></entry><entry><title>Half Moon Bay II</title><link href="http://blog.jverkamp.com/2015/06/27/half-moon-bay-ii" /><id>urn:uuid:cdd234b5-81ef-db26-158c-887e1b22cdb9</id><updated>2015-06-27T00:00:00Z</updated><summary type="html"><![CDATA[<p>Back to Half Moon Bay. We didn't park on site, but given all the neat things we saw, I'm okay with this.</p>
<div><div class="flickr-gallery" data-set-id="72157654753756870" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157654753756870">View on Flickr</a></p></div>]]></summary><content type="html"><![CDATA[<p>Back to Half Moon Bay. We didn't park on site, but given all the neat things we saw, I'm okay with this.</p>
<div><div class="flickr-gallery" data-set-id="72157654753756870" data-per-page="30"></div><p><a href="https://flickr.com/photos/jpverkamp/sets/72157654753756870">View on Flickr</a></p></div>]]></content></entry><entry><title>Rama</title><link href="http://blog.jverkamp.com/2015/06/21/rama" /><id>urn:uuid:c1c3658d-eaa4-7e51-eefd-9ef913d82666</id><updated>2015-06-21T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a> <a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<p><a href="https://www.goodreads.com/series/49121-rama">Rama</a> by <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a> and <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>.</p>
<p>I'm going to try something a little different this time. On previous series, I found it hard to write a blog post after reading several books back to back, I've been reviewing each book individual <a href="https://www.goodreads.com/user/show/8261480-jp">on Goodreads</a> as I've read it. I have a short summary for the entire series, followed by the individual books. We'll see how it goes.</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a> <a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a> <a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<p><a href="https://www.goodreads.com/series/49121-rama">Rama</a> by <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a> and <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>.</p>
<p>I'm going to try something a little different this time. On previous series, I found it hard to write a blog post after reading several books back to back, I've been reviewing each book individual <a href="https://www.goodreads.com/user/show/8261480-jp">on Goodreads</a> as I've read it. I have a short summary for the entire series, followed by the individual books. We'll see how it goes.</p>
<!--more-->
<p>Overall, I like the first book (the only by only <a href="https://www.goodreads.com/author/show/7779.Arthur_C_Clarke">Arthur C. Clarke</a>, the rest were all co-authored by<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> <a href="https://www.goodreads.com/author/show/65129.Gentry_Lee">Gentry Lee</a>). It's the kind of science fiction driven not particularly by plot or character, but rather by discovery and exploration. It's not always done well, but in this case I particularly enjoyed it. Conversely though, the other three in the series have much more focus on character conflict and to a lesser extent (but more than Rama) a central plot.</p>
<p>That change in style really turned me off the second book in the series, to the extent that I almost didn't finish the series. I'm glad I did though. Each of the sequels (in particularly the first part of #2 and most of #4) has some interesting ideas and solid extensions of Clarke's original world.</p>
<p>If you're into more interested in the science part of science fiction, you could do far worse than Rama. If, on the other hand, you want a story with more depth to the characters and plots, give Rama II a chance (although just keep in mind that Rama and Rama II are fairly different). If you are a completionist, the last book is actually pretty good and does a reasonably good job of tying up a lot of loose ends from the previous books.</p>
<p>Now, the individual reviews. Warning, there will be (usually minor) spoilers!</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112537.Rendezvous_with_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/1-rendezvous-with-rama.jpg" /></a></p>
<h3>Rama</h3>
<p>It's been a little while since I've read much science fiction, particularly any of the sort that Clarke is known for. Forget strong plot or characters and focus entirely around the big idea: In this case, the starship Rama is plenty large.</p>
<p>It starts off quickly, only a few chapters before you're on the ship. From there, you have situation after situation, describing how interesting the world that Clarke has built is and how the explorers react to it. The lack of a more specific antagonist becomes more of a problem towards then end, in that the book just sort of ends. There are various problems throughout the book, but no sense of building. I'm still not entirely sure how much I like this style.</p>
<p>Overall though, I think it's a cool world and I want to know more. Given that the sequels were written many years later and co-written by an author with a somewhat different style (based on the forward in Rama II), it will be interesting to see how different they are.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112520.Rama_II"><img src="http://blog.jverkamp.com/2015/06/21/rama/2-rama-ii.jpg" /></a></p>
<h3>Rama II</h3>
<p>This book feels rather different from Rendezvous with Rama.</p>
<p>For the first half, I wasn't sure that I actually liked the difference. Rather than the almost sterile science fiction that Clarke is better known for, the sequel deals a lot more with characters, drama, and to some extent matters of faith. It's especially interesting in how long it takes them to even get to Rama, especially compared to the first book.</p>
<p>Through the next quarter though, it really started picking up. I started to actually care about the characters and couldn't put it down. The feel of the ship, especially with some of the new findings, is just different enough that I wanted to know more.</p>
<p>At first, I wasn't sure that I was going to read the other two sequels. After this, I'm not sure how I couldn't.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112518.The_Garden_of_Rama"><img src="http://blog.jverkamp.com/2015/06/21/rama/3-the-garden-of-rama.jpg" /></a></p>
<h3>The Garden of Rama</h3>
<p>Like Rama #2, I went back and forth while reading this one on if I was actually enjoying it or if I would finish it at all. In the end, I did finish it and I think I'll even start the last one mostly out of a sense of completionism.</p>
<p>Essentially, there are five sections:</p>
<p>In the first, the three explorers from Rama II are leaving the solar system at high speeds. The parts where they are exploring the ship and learning how to live with the local 3D printer and interacting with other alien species is neat. The part where they decide that two men and a woman are enough to start a colony... That's just a little weird. I missed the first book, where the science and sense of exploration was the core of the story.</p>
<p>In the second, they get to a sort of routing section and finally meet an alien intelligence (even if it's still a robot). They (and by extension, we) get some neat answers. I liked this section for precisely the same reason I didn't like the first section: it's about exploring the world of Rama.</p>
<p>In the third, they go back to Earth, both in the context of the story and for a few scenes. They are all new characters and I cannot figure out why I care about any of them. Then they're sent off to a colony on Mars, except... surprise, they're actually going to make a new colony on the rebuilt Rama II. This is fine, but I feel like it could have been shortened.</p>
<p>In the fourth, the colony grows and thrives. Or not. Turns out people are people and people are terrible. Really, this whole section was depressing and not really what I was hoping to see in this book. I liked the smaller scales of the first 2.5 books. This not so much. Especially since it all ends up with exactly the sort of power struggle and corruption that I both see as entirely too plausible and hope isn't actually inevitable in such situations.</p>
<p>Finally, there's a big jump in the last ten percent or so where Robert goes to meet with the avian colony from the previous books. Suffice it to say, they have a strange lifecycle that we'd previously , which would have been much more interesting had Orson Scott Card not done it ~4 years earlier in Speaker for the Dead. It is exactly the sort of thing I wanted though, I just wish it had more relation to the rest of the story and had more than 10% of the pages. This is why I'm reading the 4th book, hoping there will be more of this.</p>
<hr />
<p><a href="https://www.goodreads.com/book/show/112517.Rama_Revealed"><img src="http://blog.jverkamp.com/2015/06/21/rama/4-rama-revealed.jpg" /></a></p>
<h3>Rama Revealed</h3>
<p>In my opinion, this was by far the best of the sequels.</p>
<p>They start by doing exactly what I wanted out of the middle two books: getting away from the human settlement and into a situation where they are learning and experiencing something strange. In this case, they go to live among the octospiders, an intelligent civilization highly skilled in genetics and biological science who are completely deaf and only speak in color. It's a fascinating and nicely thought out situation and I did like it.</p>
<p>Even when, halfway through the book, the focus shifts back partially to the rest of the human colony in Rama, it still maintains a tight focus, with the bigger scale events going on behind the scenes. There was still a particular feel of exploring how different societies deal with issues (such as war: the octospiders view all war as terrible, not just certain kinds).</p>
<p>The final section, when the return to another Node felt a little strange. Either because it was rushed or because it felt sort of artificial. I didn't particularly mind though, since it still was working out echoes of events from all of the previous books and acted as a sufficient capstone to the series. I did think it was nice that Michael and Simone make another appearance, even if the latter replied her mother's odd fixation with a two person continuation of the species.</p>
<p>At the very end, the book veers somewhat towards a philosophical / religions tangent, which felt a little odd (the Ramas are essentially God) but still thought provoking.</p>
<p>Overall, I was pleasantly surprised by this book. If you made it through the middle two books, you should probably read this one as well.</p>
<hr />
<p>Side note: I didn't finish Whitechapel Gods (which was actually next on my original <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>) since, after 20%, I just really wasn't getting into it. There are some really interesting ideas (a steampunkification disease for example), but it was hard to get a grasp on exactly what was going on. So it goes.</p>
<p>Overall, that 47 of 100 books for the year, exactly on schedule. Next up: <a href="https://www.goodreads.com/book/show/337048.The_Engines_of_God">The Engines of God</a> by <a href="https://www.goodreads.com/author/show/73812.Jack_McDevitt">Jack McDevitt</a>. At the same time, I'm also reading <a href="https://www.goodreads.com/book/show/101869.The_Atrocity_Archives">The Laundry Files</a> by <a href="https://www.goodreads.com/author/show/8794.Charles_Stross">Charles Stross</a> on a one chapter a day email list.</p>]]></content></entry><entry><title>American Gods</title><link href="http://blog.jverkamp.com/2015/05/26/american-gods" /><id>urn:uuid:37aa9547-ccce-5a9b-642f-434049c3983f</id><updated>2015-05-26T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/4407.American_Gods"><img src="http://blog.jverkamp.com/2015/05/26/american-gods/american-gods.jpg" /></a></p>
<p><a href="https://www.goodreads.com/book/show/4407.American_Gods">American Gods</a> falls on the unfortunately long list of books that I wish were better. It won (or was at least nominated) for a whole pile of awards<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>. It's by <a href="https://en.wikipedia.org/wiki/Neil_Gaiman">an author</a> who's works in other genres I've enjoyed (e.g. the movie Corline or his episodes on Doctor Who) and who seems like a solid person in real life.</p>
<p>I just couldn't get into it.</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/4407.American_Gods"><img src="http://blog.jverkamp.com/2015/05/26/american-gods/american-gods.jpg" /></a></p>
<p><a href="https://www.goodreads.com/book/show/4407.American_Gods">American Gods</a> falls on the unfortunately long list of books that I wish were better. It won (or was at least nominated) for a whole pile of awards<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>. It's by <a href="https://en.wikipedia.org/wiki/Neil_Gaiman">an author</a> who's works in other genres I've enjoyed (e.g. the movie Corline or his episodes on Doctor Who) and who seems like a solid person in real life.</p>
<p>I just couldn't get into it.</p>
<!--more-->
<p>It's a bummer, because it's such a fascinating world. I like the idea (shared by <a href="http://blog.jverkamp.com/2015/02/20/the-iron-druid-chronicles">The Iron Druid Chronicles</a>) that not only are the gods still walking among us, but also that a god can have more than one form, depending on how and when it was worshipped. I like the idea that the old gods are pissed at the new gods (Media / The Internet) for encroaching on their territory. I like how the old gods feel more 'human', only somehow <em>more</em> yet also somehow <em>less</em>.</p>
<p>But the story itself drags at points, with several sections (the dreams in particular) which I thought were interesting, but I wasn't entirely sure why they were there. I've heard it said that Gaiman cut half of American Gods even before it was released, but at ~650 pages, it's still a hefty tome. I think it could have lost a little more.</p>
<p>Conversely, I did think that most of the characters were pretty solid. I thought Shadow was a solid enough protagonist, going along with a world gone mad until he'd had enough... and then a step or two more. I felt for Mr. Wednesday, trying to take back pieces of a world gone wrong. I liked the little hints and pieces of how the gods' lives had changed on coming to the new world.</p>
<p>All in all, it's the sort of book that I'm glad that I've read... but I doubt I will ever reread. There are a few interesting ideas buried in there that I'm sure will surface years from now, long after I've forgotten where they came from.</p>
<p>Since it took me so long (Two weeks? Was it really that long?) to read American Gods, I'm now at only 42 of 100 for my <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, fallen from 7 ahead to 3. Still, onwards! Next up, with an amusingly related title<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>, <a href="https://www.goodreads.com/book/show/2302159.Whitechapel_Gods">Whitechapel Gods</a>.</p>]]></content></entry><entry><title>Generating YouTube user RSS feeds</title><link href="http://blog.jverkamp.com/2015/05/11/generating-youtube-user-rss-feeds" /><id>urn:uuid:a097ad77-6800-c1be-c4de-26a9af4348d9</id><updated>2015-05-11T00:00:00Z</updated><summary type="html"><![CDATA[<p>On 4 March 2014, YouTube deprecated the v2.0 API for YouTube (<a href="https://developers.google.com/youtube/2.0/developers_guide_protocol_deprecated">source</a>). One of the unfortunate side effects was that RSS feeds for user uploads were included in what was deprecated.</p>
<p>Previously, you could get an RSS feed with a link of the form: <code>https://gdata.youtube.com/feeds/base/users/{user}/uploads</code> For the longest time, even after the deprecation, those links still worked, but a couple weeks ago, more and more of the video feeds I was subscribed to started redirecting to <a href="https://www.youtube.com/channel/UCMDQxm7cUx3yXkfeHa5zJIQ/videos">YouTube Help account</a>. As thrilling as that channel is, it's not what I'm looking for.</p>
<p>Let's fix it.</p>
]]></summary><content type="html"><![CDATA[<p>On 4 March 2014, YouTube deprecated the v2.0 API for YouTube (<a href="https://developers.google.com/youtube/2.0/developers_guide_protocol_deprecated">source</a>). One of the unfortunate side effects was that RSS feeds for user uploads were included in what was deprecated.</p>
<p>Previously, you could get an RSS feed with a link of the form: <code>https://gdata.youtube.com/feeds/base/users/{user}/uploads</code> For the longest time, even after the deprecation, those links still worked, but a couple weeks ago, more and more of the video feeds I was subscribed to started redirecting to <a href="https://www.youtube.com/channel/UCMDQxm7cUx3yXkfeHa5zJIQ/videos">YouTube Help account</a>. As thrilling as that channel is, it's not what I'm looking for.</p>
<p>Let's fix it.</p>
<!--more-->
<p>First step, we need a YouTube Data API (v3) key. Unfortunately it doesn't look like they provide un-authenticated use of the API as before. That's easy enough though, just <a href="https://developers.google.com/youtube/registering_an_application">go through the steps to register an application</a>. Next, dig through the APIs. It doesn't look like there is a way to directly get a user's videos, but you can get a list of a users 'uploads' playlist, which functions much the same way.</p>
<p>Using Python's <a href="http://docs.python-requests.org/en/latest/">requests</a> library, we just have to hit the correct endpoint:</p>
<pre class="python"><code># Use the channel to get the 'uploads' playlist id
response = requests.get(
    'https://www.googleapis.com/youtube/v3/channels',
    params = {
        'part': 'contentDetails',
        'forUsername': user,
        'key': API_KEY,
    }
)</code></pre>
<p>One example response:</p>
<pre class="json"><code>{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/6wRGj4eVz7tGNiDQjCMuhP6B4vQ\"",
 "items": [{"contentDetails": {"googlePlusUserId": "112244684143881021368",
                               "relatedPlaylists": {"likes": "LL6nSFpj9HTCZ5t-N3Rm3-HA",
                                                    "uploads": "UU6nSFpj9HTCZ5t-N3Rm3-HA"}},
            "etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/yMieoczWtu9QiK_MEdJrC0hqmdU\"",
            "id": "UC6nSFpj9HTCZ5t-N3Rm3-HA",
            "kind": "youtube#channel"}],
 "kind": "youtube#channelListResponse",
 "pageInfo": {"resultsPerPage": 5, "totalResults": 1}}</code></pre>
<p>That's some progress. Specifically, you can get the playlist ID for the user uploads:</p>
<pre class="python"><code>playlistId = response.json()['items'][0]['contentDetails']['relatedPlaylists']['uploads']</code></pre>
<p>From there, we can query the API again in order to get the most recent 20 items from that specific playlist:</p>
<pre class="python"><code># Get the most recent 20 videos on the 'uploads' playlist
response = requests.get(
    'https://www.googleapis.com/youtube/v3/playlistItems',
    params = {
        'part': 'snippet',
        'maxResults': 20,
        'playlistId': playlistId,
        'key': API_KEY
    }
)</code></pre>
<p>Some snippets from that output (it's rather large):</p>
<pre class="json"><code>{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/PH2ohKtd9aLBba_d7dVtVUfFle0\"",
 "items": [{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/-LUTubHPIceTTTPMrBW-Qs9KOZQ\"",
            "id": "UUKzDohq4XHVIEl9O19Nd8rKuqCo1VravR",
            "kind": "youtube#playlistItem",
            "snippet": {"channelId": "UC6nSFpj9HTCZ5t-N3Rm3-HA",
                        "channelTitle": "Vsauce",
                        "description": "Vsauce is nominated for a Webby "
                                       "in Science & Education! You can "
                                       ...,
                        "playlistId": "UU6nSFpj9HTCZ5t-N3Rm3-HA",
                        "position": 0,
                        "publishedAt": "2015-04-13T19:26:03.000Z",
                        "resourceId": {"kind": "youtube#video",
                                       "videoId": "f8WsO__XcI0"},
                        "thumbnails": {"default": {"height": 90,
                                                   "url": "https://i.ytimg.com/vi/f8WsO__XcI0/default.jpg",
                                                   "width": 120},
                                       ...},
                       "title": "When Will We Run Out Of Names?"}},
           {"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/kCpPYobMQgr7w9gfxaR-_cfkJkc\"",
           ...]}</code></pre>
<p>In that snippets blob, we have everything we need. Specifically, the <code>title</code>, <code>thumbnails</code>, and <code>link</code> (by way of <code>resourceID.videoId</code>). Specifically, we can start to construct an RSS feed using the <a href="https://pypi.python.org/pypi/feedgen/">feedgen</a> library<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>:</p>
<pre class="python"><code># Generate a list of results that can be used as feed items
feed = feedgen.feed.FeedGenerator()
feed.title(user + ' (YRSS)')
feed.author({'name': user + ' (YRSS)'})
feed.id('YRSS:' + user)

for item in response.json()['items']:
    title = item['snippet']['title']
    video_id = item['snippet']['resourceId']['videoId']
    published = item['snippet']['publishedAt']
    thumbnail = item['snippet']['thumbnails']['high']['url']
    video_url = 'https://www.youtube.com/watch?v=' + video_id

    item = feed.add_entry()
    item.title(title)
    item.link(href = video_url)
    item.published(dateutil.parser.parse(published))
    item.updated(dateutil.parser.parse(published))
    item.id(video_id)
    item.content('''
&lt;a href="{url}"&gt;&lt;img src="{img}" /&gt;&lt;/a&gt;
&lt;a href="{url}"&gt;{title}&lt;/a&gt;
'''.format(
        url = video_url,
        img = thumbnail,
        title = title,
    ))</code></pre>
<p>And generate the feed:</p>
<pre class="python"><code>feed.atom_str()</code></pre>
<p>I love how (relatively) elegant that was. You don't have to worry about or even know anything about how the underlying XML will be structured.</p>
<p>Since eventually I want this to be a web service, I used Flask to generate a simple API:</p>
<pre class="python"><code>app = flask.Flask(__name__)

@app.route('/&lt;user&gt;.xml')
@app.route('/&lt;user&gt;/atom.xml')
def generatefeed(user):
    ...

    return feed.atom_str()</code></pre>
<p>That way, if you go to <code>http://myserver.com/{user}.xml</code>, you would get an RSS feed for that user's most recent 20 videos. There are a few other considerations to keep in mind (For example, I have a cache that only re-queries the YouTube API once per hour and otherwise re-serves the same feed. And better error handling.)</p>
<p>If you'd like to see the full source in all it's glory, it's available on GitHub: <a href="https://github.com/jpverkamp/yrss">jpverkamp/yrss</a>. You will have to supply an <code>API_KEY</code> as an environment variable to run it, but that should be relatively straight forward.</p>]]></content></entry><entry><title>The Unnaturalists</title><link href="http://blog.jverkamp.com/2015/05/10/the-unnaturalists" /><id>urn:uuid:c2b87157-2f5a-d1bb-528c-7712235d8008</id><updated>2015-05-10T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/12988074-the-unnaturalists"><img src="http://blog.jverkamp.com/2015/05/10/the-unnaturalists/the-unnaturalists.jpg" /></a></p>
<p>Right on the heels of <a href="http://blog.jverkamp.com/2015/04/28/year-zero">Year Zero</a>, I have another book that got itself on my list based on the potential in its world building: <a href="https://www.goodreads.com/book/show/12988074-the-unnaturalists">The Unnaturalists</a>. I mean, how can you <em>not</em> be intrigued by a world where London seems to have been yanked into another world, where Science<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> has grown into a religion.</p>
<p>You have things like people cursing with "by Saint Darwin and all his apes". A world where you hear someone say (with a straight face) "I turn my attention to another window, the one in which Saint Pasteur smites the Demon Byron for his licentious poetry."</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/12988074-the-unnaturalists"><img src="http://blog.jverkamp.com/2015/05/10/the-unnaturalists/the-unnaturalists.jpg" /></a></p>
<p>Right on the heels of <a href="http://blog.jverkamp.com/2015/04/28/year-zero">Year Zero</a>, I have another book that got itself on my list based on the potential in its world building: <a href="https://www.goodreads.com/book/show/12988074-the-unnaturalists">The Unnaturalists</a>. I mean, how can you <em>not</em> be intrigued by a world where London seems to have been yanked into another world, where Science<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> has grown into a religion.</p>
<p>You have things like people cursing with "by Saint Darwin and all his apes". A world where you hear someone say (with a straight face) "I turn my attention to another window, the one in which Saint Pasteur smites the Demon Byron for his licentious poetry."</p>
<!--more-->
<p>Therein lies the problem with the world though. It never quite gelled for me. There is quite a lot of world there, just waiting to be tapped, but it seemed too busy. It seemed to be a steampunk London torn from our world some time in the past, sent into a world where magic still holds sway--which is particularly odd. How do you have Science grow to the point it has in this story in a world where there are literal living fairies and sphinxes hanging around?</p>
<p>Also, it was never entirely clear what the rules were in the world. I don't strictly speaking have to know what the worlds are for magic systems, but I do prefer that there are rules. I never get the impression that is the case here. We have the last Witch in the world; Architects which can do... something; Tinkers with the ability to commune with Elemantals (essentially animstic spirits); and all manner of magical beasties. Don't get me wrong, there were some particularly cool visuals, it just didn't quite get beyond that.</p>
<p>Beyond the world building, the writing style was odd. There were two story lines: a rich girl rebelling against Victorian gender roles and a Tinker boy from the outskirts with the only remaining Tinker magic among his people. The former was written in first person present tense<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>, the latter in third person. I can see where the two characters tie together, but for the most part, there seem to almost be two stories going on in parallel.</p>
<p>Finally, the love story just felt strange. Pedant Lumin/Hal/Bayne/The Architect is referred to four different ways at different points in the book; it took me a while to figure out they were all the same person. As a result, I couldn't figure out who he was and what in the world Vespa saw in him. It felt like the author was trying to make him adequately interesting, but it felt forced.</p>
<p>Overall, it took me a while to get finish this book. It never quite got to the point where I just wanted to put it down, but at the same point, it didn't keep me turning pages. So it goes. I'm sure there are many people who would enjoy this style of book. I'm just not one of them. So it goes.</p>
<p>So far, I've finished 41 of 100 books for the year, keeping me at a solid 6 books ahead of schedule<span class="footnote"><sup><a href="#footnote-3">[3]</a></sup></span>. Next up, <a href="https://www.goodreads.com/author/show/1221698.Neil_Gaiman">Neil Gaiman's</a> <a href="https://www.goodreads.com/book/show/4407.American_Gods">American Gods</a>.</p>]]></content></entry><entry><title>Tupper's self-referential formula</title><link href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula" /><id>urn:uuid:bf58a9a0-f27e-d83e-acd1-97ca1db67a9b</id><updated>2015-05-07T00:00:00Z</updated><summary type="html"><![CDATA[<p>Quick post today. Let's implement <a href="https://en.wikipedia.org/wiki/Tupper's_self-referential formula">Tupper's self-referential formula</a> in Racket!</p>
<div>$$ \frac{1}{2} < \left \lfloor mod \left ( \left \lfloor \frac{y}{17} 2^{-17 \lfloor x \rfloor - mod(\lfloor y \rfloor, 2)} \right \rfloor, 2 \right ) \right \rfloor $$</div>
<pre class="racket"><code> (tupper 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719) </code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" /></a></p>
<p>That's the result of graphing the above function at a point rather far away from the origin. Specifically, where <code>y</code> is around that crazy big number. Look familiar?</p>
]]></summary><content type="html"><![CDATA[<p>Quick post today. Let's implement <a href="https://en.wikipedia.org/wiki/Tupper's_self-referential formula">Tupper's self-referential formula</a> in Racket!</p>
<div>$$ \frac{1}{2} < \left \lfloor mod \left ( \left \lfloor \frac{y}{17} 2^{-17 \lfloor x \rfloor - mod(\lfloor y \rfloor, 2)} \right \rfloor, 2 \right ) \right \rfloor $$</div>
<pre class="racket"><code> (tupper 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719) </code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" /></a></p>
<p>That's the result of graphing the above function at a point rather far away from the origin. Specifically, where <code>y</code> is around that crazy big number. Look familiar?</p>
<!--more-->
<p>The basic idea behind the formula is that it can encode any arbitrary bitmap (so long as it's black and white and only 106x17 pixels). Essentially under the hood everything is in base 17. First, let's fairly directly translate the original formula into Racket:</p>
<pre class="racket"><code>; Tupper's "self-referential" formula
; Encodes a bitmap as an integer
(define (tupper k)
  (flomap-&gt;bitmap
   (build-flomap*
    1 106 17
    ( (x y)
      (set! y (+ y k))
      (set! x (- 105 x))
      (cond
        [(&lt; 1/2 (floor (mod (* (floor (/ y 17)) (expt 2 (- (* -17 (floor x)) (mod (floor y) 17)))) 2)))
         (vector 0)]
        [else
         (vector 1)])))))</code></pre>
<p>One amusing caveat that we have to deal with here is that <code>modulus</code> doesn't work on numbers this large. So instead, we're going to have to do it manually:</p>
<pre class="racket"><code>; Modulus that will work with really large numbers
(define (mod a b)
  (define q (floor (/ a b)))
  (define r (- a (* b q)))
  r)</code></pre>
<p>Whee!</p>
<p>Another neat trick I was playing with is "rendering" the image by adding one digit at a time (in base 10, so it's mostly noise):</p>
<pre class="racket"><code>(define (render-to target)
  (define str-target (number-&gt;string target))
  (define str-buffer (make-string (string-length str-target) #\0))

  (for/list ([i (in-range (sub1 (string-length str-target)) -1)])
    (string-set! str-buffer i (string-ref str-target i))
    (tupper (string-&gt;number str-buffer))))

&gt; (write-animated-gif
   (render-to 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719)
   5
   "tupper.gif"
   #:last-frame-delay 50)</code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.gif" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.gif" /></a></p>
<p>If you look carefully, you'll occasionally see flashes of the final image being rendered. This happens whenever the base-10 numbers that we're adding line up with the base-17 encoding.</p>
<p>I'm not sure it's particularly useful for anything, but I found it amusing.</p>
<p>Code: <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/tupper.rkt">tupper.rkt</a></p>]]></content></entry><entry><title>Year Zero</title><link href="http://blog.jverkamp.com/2015/04/28/year-zero" /><id>urn:uuid:a0507ac6-d1ec-9e91-ff33-5842a395cbb6</id><updated>2015-04-28T00:00:00Z</updated><summary type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/12953520-year-zero"><img src="http://blog.jverkamp.com/2015/04/28/year-zero/year-zero.jpg" /></a></p>
<p>Confession time: I didn't particularly like <a href="https://www.goodreads.com/book/show/11.The_Hitchhiker_s_Guide_to_the_Galaxy">The Hitchhiker's Guide to the Galaxy</a>. It seems a bit of blasphemy for a self professed 'geek', but I just don't particularly care for this style of humorous science fiction. A novel with a large helping of humor? Good. Example: <a href="http://blog.jverkamp.com/2015/02/20/the-iron-druid-chronicles">The Iron Druid Chronicles</a>. But when that humor is pushed to the level of world building, that's a bit of a problem.</p>
]]></summary><content type="html"><![CDATA[<p><a href="https://www.goodreads.com/book/show/12953520-year-zero"><img src="http://blog.jverkamp.com/2015/04/28/year-zero/year-zero.jpg" /></a></p>
<p>Confession time: I didn't particularly like <a href="https://www.goodreads.com/book/show/11.The_Hitchhiker_s_Guide_to_the_Galaxy">The Hitchhiker's Guide to the Galaxy</a>. It seems a bit of blasphemy for a self professed 'geek', but I just don't particularly care for this style of humorous science fiction. A novel with a large helping of humor? Good. Example: <a href="http://blog.jverkamp.com/2015/02/20/the-iron-druid-chronicles">The Iron Druid Chronicles</a>. But when that humor is pushed to the level of world building, that's a bit of a problem.</p>
<!--more-->
<p>Specifically, Year Zero starts with an interesting premise: Since the 1970s, aliens have been listening to our music--and they love it. But alien society at large also has a problem: art created by a 'primitive' species is bound by the laws of that species. In this particular case, copyright law. The end result: humanity is now due all of the universe's wealth (for better and for worse). Neat concept, yes?</p>
<p>The problem is that it starts to fall apart almost immediately. The basic conceit is that art is at the core of universal culture. That part seems fine. But in all the millions of species, we are the best at music--by a large margin. A step forward and our music seems universally loved. How that's possible in such a large universe? It's hard to swallow.</p>
<p>On the other hand I did like is the idea that in such a huge universe, just about every sort of alien life is possible. Life that looks like parrots... vacuum cleaners... and life that looks <em>almost</em> exactly like us. That's not a problem though, with that many species, chances are pretty good that one or more would end up just like us.</p>
<p>An interesting note is that the author of the book--<a href="https://www.goodreads.com/author/show/6423803.Rob_Reid?ref=ru_lihp_nsup_as.6423803_0_mclk">Rob Reid</a> founded the company that developed Rhapsody. So a novel heavily invested with copyright law works well with the idea to 'write what you know'. It shows, with more details about copyright law and musical pop culture references than I personally cared for. I'm not convinced that this is a novel that is going to age well--although I guess that isn't the end of the world.</p>
<p>Otherwise, the characters are a little rough, closer to caricatures at times<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>. The plot is a little uneven, taking a while to get moving, then each conclusion in turn--including the finale--comes too suddenly.  When I first started Year Zero, I wasn't sure that I was even going to finish it. Around 20% in, something clicked and suddenly it was a few hours later and I'd finished it. If you liked the Hitchhiker's Guide, you'll probably like this book.</p>
<p>Counting my side trip into the <a href="http://blog.jverkamp.com/2015/04/25/the-ender-quintet">Enderverse</a>, that puts me at 39 books just shy of the first 4 months. 100 books sounded mad at first, but I'm really enjoying it. It's nice to be reading again. Next up, <a href="https://www.goodreads.com/book/show/12988074-the-unnaturalists">The Unnaturalists</a> by <a href="https://www.goodreads.com/author/show/345572.Tiffany_Trent">Tiffany Trent</a>.</p>]]></content></entry></feed>