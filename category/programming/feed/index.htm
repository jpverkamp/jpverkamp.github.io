<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jverkamp.com</title><link href="//blog.jverkamp.com" /><link rel="self" href="//blog.jverkamp.com/feed/" /><updated>2016-07-14T00:00:00Z</updated><author><name>JP Verkamp</name></author><id>urn:uuid:e246205b-1f33-c07a-2aa5-10021f3fe725</id><entry><title>Solving Loop Puzzles</title><link href="//blog.jverkamp.com/2016/07/14/solving-loop-puzzles" /><id>urn:uuid:0f0f5549-dedc-0695-9d2a-c54fdff8ec54</id><updated>2016-07-14T00:00:00Z</updated><summary type="html"><![CDATA[<p>A quick puzzle from Daily Programmer:</p>
<blockquote>
    ∞ Loop is a mobile game that consists of n*m tiles, placed in a n*m grid. There are 16 different tiles:

    <code>┃, ━, ┏, ┓, ┛, ┗, ┣, ┳, ┫, ┻, ╋, ╹, ╺, ╻, ╸, ' '.</code>

    The objective is to create a closed loop: every pipe must have another tile facing it in the adjacent tile <code>—</code> for example if some tile has a pipe going right, its adjacent tile to the right must have a pipe going left.
</blockquote>
<p>The most straightforward solution is a hybrid combination of constraints and backtracking, similar to what I did when solving <a href="//blog.jverkamp.com/2015/10/29/takuzu-solver">Takuzu</a> and <a href="//blog.jverkamp.com/2014/10/28/tile-puzzle">tile puzzles</a>.</p>
]]></summary><content type="html"><![CDATA[<p>A quick puzzle from Daily Programmer:</p>
<blockquote>
    ∞ Loop is a mobile game that consists of n*m tiles, placed in a n*m grid. There are 16 different tiles:

    <code>┃, ━, ┏, ┓, ┛, ┗, ┣, ┳, ┫, ┻, ╋, ╹, ╺, ╻, ╸, ' '.</code>

    The objective is to create a closed loop: every pipe must have another tile facing it in the adjacent tile <code>—</code> for example if some tile has a pipe going right, its adjacent tile to the right must have a pipe going left.
</blockquote>
<p>The most straightforward solution is a hybrid combination of constraints and backtracking, similar to what I did when solving <a href="//blog.jverkamp.com/2015/10/29/takuzu-solver">Takuzu</a> and <a href="//blog.jverkamp.com/2014/10/28/tile-puzzle">tile puzzles</a>.</p>
<!--more-->
<p>First, we'll create two classes, one for individual characters and one for puzzles. Think what you may about <a href="https://en.wikipedia.org/wiki/object_oriented programming">object oriented programming</a>, but I think it fits fairly well with this problem.</p>
<p>First, characters. We want something that will be able to represent characters with with their character form (the <a href="https://en.wikipedia.org/wiki/box_drawing characters">box drawing characters</a> above) or as a collection of edges (if the top / right / bottom / left pipe is included). This could be represented as a 4-bit integer, but instead I'll use a 4-tuple of bools. It's just a bit easier to read by default.</p>
<p>On top of that, we want functions that can rotate pieces, test if two characters are actually the same, and to test if two neighboring pieces can border each other or not. The last is true if they either both have a pipe pointing inwards or neither does.</p>
<pre class="python"><code>class Character(object):
    '''A box drawing character or empty space ( ╸╻┓╺━┏┳╹┛┃┫┗┻┣╋).'''

    order = ' ╸╻┓╺━┏┳╹┛┃┫┗┻┣╋'
    sides = {'top': (0, 2), 'right': (1, 3), 'bottom': (2, 0), 'left': (3, 1)}

    def __init__(self, symbol_or_bits):
        '''
        Create a new character from either the symbol (must be a valid symbol)
        or a 4-tuple of booleans representing the sides (top, right, bottom,
        left).
        '''

        if isinstance(symbol_or_bits, str):
            self.symbol = symbol_or_bits

            bits = bin(Character.order.find(symbol_or_bits))[2:]
            bits = '0' * (4 - len(bits)) + bits

            self.bits = tuple(bit == '1' for bit in bits)
        else:
            self.bits = symbol_or_bits
            self.symbol = Character.order[int(''.join('1' if bit else '0' for bit in symbol_or_bits), 2)]

    def rotate(self):
        '''Return the next rotation for this character.'''

        return Character(tuple(self.bits[i] for i in range(-1, 3)))

    def rotations(self):
        '''Generate all four of the rotations this character could have.'''

        c = self
        for i in range(4):
            yield c
            c = c.rotate()

    def can_neighbor(self, other, side):
        '''
        Test if this character can neighbor a given other on a given side.

        Two characters can be neighbors if they either both have a line on that
        side or neither does. If other is not set, that is assumed to be a
        outside of the puzzle and thus not have a line.
        '''

        my_bit, their_bit = Character.sides[side]

        # print(side, self, other, my_bit, their_bit, self.bits, other.bits) # DEBUG

        if other:
            return self.bits[my_bit] == other.bits[their_bit]
        else:
            return not self.bits[my_bit]

    def __hash__(self):
        '''Use the symbol as a hash. This is so we can put characters in sets.'''

        return hash(self.symbol)

    def __eq__(self, other):
        '''Characters are equal if they have the same symbol.'''

        return self.symbol == other.symbol

    def __repr__(self):
        '''Print which character this is.'''

        return self.symbol</code></pre>
<p>After that, the next step will be to create a <code>Puzzle</code>. This is the grid of characters, but we'll actually go a step larger. Each cell in the <code>Puzzle</code> will actually be a set of rotations that are still possible. This means that as long as any cell has more than 1 possibility, it's not solved. If any has managed to reach 0, no solution is possible.</p>
<p>In addition, we'll put the constraining function here. This will loop through every single cell in the puzzle: for each, it will match each rotation remaining against each rotation of all four neighbors. If a given rotation cannot possibly match any one of the neighbors, remove it from the set. Imagine:</p>
<pre class="test"><code>┛╸╸
╺┓╻
┗ ┣</code></pre>
<p>The middle character can originally be any of <code>{┏, ┓, ┛, ┗}</code>; however, the bottom center is an empty space, so we should not include any downward facing options. Thus, with a single round of constraint, we've reduced the center tile to <code>{┛, ┗}</code>. Even better, this will further constrain the top center piece. At first it was <code>{╹, ╺, ╻, ╸}</code>, but the center has to have an upward pointing point, forcing the top center to be <code>{╻}</code>. Each round of constraints only sets each tile once and won't work recursively, but it's easy enough to call it more than once. Especially since the function will return <code>True</code> until the puzzle reaches a steady state.</p>
<pre class="python"><code>class Puzzle(object):
    '''Represent a grid of possible characters.'''

    border = {Character(' ')}

    def __init__(self, data):
        '''Initialize from a string containing characters.'''

        self.data = [
            [set(Character(c).rotations()) for c in line]
            for line in data.strip().split('\n')
        ]
        self.rows = len(self.data)
        self.cols = len(self.data[0])

    def possibilities(self):
        '''
        Return the number of possibilities in the form (unsolved squares, total
        possibilities). A solved puzzle will return (0, rows * cols).
        '''

        return (
            sum(0 if len(el) == 1 else 1 for row in self.data for el in row),
            sum(len(el) for row in self.data for el in row)
        )

    def is_solvable(self):
        '''Test if the puzzle is still solvable (no empty possibilities.)'''

        return not any(
            len(el) == 0
            for row in self.data
            for el in row
        )

    def is_solved(self):
        '''Test if this puzzle is currently solved.'''

        return all(
            len(el) == 1
            for row in self.data
            for el in row
        )

    def constrain(self):
        '''
        Constrain this puzzle by removing any rotations that could not possibly
        be used (there's no possibility in the neighbor to match them).

        Only make one pass, call this function multiple times in case one
        constraint cascades.

        Return if anything changed.
        '''

        logging.debug('Applying constraints, possiblities: {}'.format(self.possibilities()))

        offsets = [
            ('top', -1, 0),
            ('right', 0, 1),
            ('bottom', 1, 0),
            ('left', 0, -1),
        ]

        something_changed = False

        for row in range(self.rows):
            for col in range(self.cols):
                invalid = set()
                for first_point in self[row, col]:
                    if not all(
                        any(
                            first_point.can_neighbor(second_point, direction)
                            for second_point in self[row + row_offset, col + col_offset]
                        ) for direction, row_offset, col_offset in offsets
                    ):
                        invalid.add(first_point)

                for impossibility in invalid:
                    something_changed = True
                    self[row, col].remove(impossibility)

        return something_changed

    def __getitem__(self, pt):
        '''
        Fetch the current possibility set from a given row and column.

        If the index is out of bounds, instead return a 'border character' with
        no edges to help guarantee that no pieces point outwards.
        '''

        row, col = pt
        if 0 &lt;= row &lt; self.rows and 0 &lt;= col &lt; self.cols:
            return self.data[row][col]
        else:
            return Puzzle.border

    def __repr__(self):
        '''If solved, print the puzzle; if not, print remaining possibilities.'''

        if self.is_solved():
            return '\n'.join(
                ''.join(str(list(el)[0]) for el in row)
                for row in self.data
            )

        else:
            def pad_set(el):
                return ''.join(str(each) for each in el) + ' ' * (4 - len(el))

            line_seperator = '\n' + ('┈' * (7 * self.cols - 3)) + '\n'

            return line_seperator.join(
                ' ┆ '.join(pad_set(el) for el in row)
                for row in self.data
            )
            return repr(self.data)</code></pre>
<p>That's actually enough by itself to solve some puzzles. But sometimes, particularly in larger puzzles, you'll reach states where two arrangements are still possible. In those cases, we want to take a <a href="https://en.wikipedia.org/wiki/backtracking">backtracking</a> step: choose each of the possible states in turn and assume it is correct, switching back to the constraint solver until the next block. If a solution is found in that branch, just return. If not, try the next branch from that position.</p>
<pre class="python"><code>def solve(puzzle):
    '''
    Use a hybrid constraint / backtracking solver to solve the puzzle.

    while not solved:
        apply constraint solver until it doesn't work any more
        find the first mismatched point and try each possibility
    '''

    queue = [puzzle]
    while queue:
        puzzle = queue.pop()
        logging.info('Running backtracker, states: {}, possiblities in current state: {}'.format(len(queue), puzzle.possibilities()))
        logging.debug(puzzle)

        # Apply constraint until the constrain function returns false
        while puzzle.constrain(): pass
        logging.debug(puzzle)

        if not puzzle.is_solvable():
            logging.info('Unsolveable state found, removing it')
            continue

        if puzzle.is_solved():
            logging.info('Solved state found, returning it')
            return puzzle

        # Split to backtracking
        def first_unclear_point():
            for row in range(puzzle.rows):
                for col in range(puzzle.cols):
                    if len(puzzle[row, col]) &gt; 1:
                        return row, col, puzzle[row, col]

        row, col, possibilities = first_unclear_point()
        for possibility in possibilities:
            copied_puzzle = copy.deepcopy(puzzle)
            copied_puzzle[row, col].clear()
            copied_puzzle[row, col].add(possibility)

            queue.append(copied_puzzle)

    # If we made it out of the loop, there is no solution to the puzzle
    return None</code></pre>
<p>And that's it. We can solve puzzles from <code>stdin</code>:</p>
<pre class="python"><code>import sys
puzzle = Puzzle(sys.stdin.read())
solution = solve(puzzle)
print(solution)</code></pre>
<p>Example running:</p>
<pre class="bash"><code>$ cat 10x10.loops

┗┣┃┃┗┏┳┓┛┏
┗┛┛━┳┫┃┃━━
┛┛━┓┳╋┫━┣┏
┫╋┻┛┛┻━┳╋┗
┛┳┃┳┃╋┫┃┳┗
┓━┓━┏╋┏┻╋┓
┛┛━┃┻┗┓┓┳┓
┏╋╋┏┏┳┣┗┗┗
┣╋╋┏┏┻┓┓┏┫
┏┏┗┫┣┳┳━┫┗

$ cat 10x10.loops | python3 loop-solver.py

┏┳━━┓┏┳┓┏┓
┗┛┏━┻┫┃┃┃┃
┏┓┃┏┳╋┫┃┣┛
┣╋┻┛┗┫┃┣╋┓
┗┻━┳━╋┫┃┣┛
┏━┓┃┏╋┛┣╋┓
┗┓┃┃┣┛┏┛┣┛
┏╋╋┛┗┳┻┓┗┓
┣╋╋┓┏┫┏┛┏┫
┗┛┗┻┻┻┻━┻┛</code></pre>
<p>Cool. Looking at this and several other puzzles, it seems like it would be a good generic framework to work out. Given a definition for a puzzle with an <code>is_valid</code> function (<code>can_neighbor</code> here), a <code>constrain</code> function, and the backtracking code above, it should be able to solve a large class of puzzles. <a href="https://en.wikipedia.org/wiki/Sudoku">Sudoku</a>, for example, or <a href="https://en.wikipedia.org/wiki/Hashi">Hashi</a>. Both puzzles I've been working on solvers for. Even better, once you have a solver you can use it to generate puzzles with a difficulty gradient. Just solve each puzzle, keeping track of how many times you had to backtrack and how many were solved with the constraints.</p>
<p>And that's it. A fun little puzzle.</p>]]></content></entry><entry><title>Mirror iTunes playlists to Spotify</title><link href="//blog.jverkamp.com/2016/06/22/mirror-itunes-playlists-to-spotify" /><id>urn:uuid:728d449b-f26f-3dc7-9a72-a5e203174850</id><updated>2016-06-22T00:00:00Z</updated><summary type="html"><![CDATA[<p>At the moment, I have an Apple Music subscription. It's great to be able to listen to more or less whatever music I want to. I switched from Spotify because they were missing a few artists that I actually did want to listen to. Unfortunately, there are a few things that Apple Music doesn't do that I would like to have--chief among them the ability to play on a Roku.</p>
<p>One nice thing that Spotify does have though is a fairly powerful API: <a href="https://developer.spotify.com/web-api/">Spotify Web API</a>. Inspired by a post on <a href="http://aguo.us/writings/spotify-billboard.html">Spotify and billboard.py</a> which automatically creates Spotify playlists from the Billboard music ranking charts, I decided to write up a script that can sync my playlists from iTunes to Spotify.</p>
]]></summary><content type="html"><![CDATA[<p>At the moment, I have an Apple Music subscription. It's great to be able to listen to more or less whatever music I want to. I switched from Spotify because they were missing a few artists that I actually did want to listen to. Unfortunately, there are a few things that Apple Music doesn't do that I would like to have--chief among them the ability to play on a Roku.</p>
<p>One nice thing that Spotify does have though is a fairly powerful API: <a href="https://developer.spotify.com/web-api/">Spotify Web API</a>. Inspired by a post on <a href="http://aguo.us/writings/spotify-billboard.html">Spotify and billboard.py</a> which automatically creates Spotify playlists from the Billboard music ranking charts, I decided to write up a script that can sync my playlists from iTunes to Spotify.</p>
<!--more-->
<p>First, let's write a method that uses the Spotify web API to search for tracks (or actually any <code>type</code>, such as an artist):</p>
<pre class="python"><code>@memory.cache
def spotify_search(type, retries = 3, **params):
    '''Search for an item on the spotify API.'''

    logging.debug('spotify_search({}, {})'.format(type, params))

    url = 'https://api.spotify.com/v1/search'
    query = ' '.join(
        '{key}:{value}'.format(key = key, value = params[key])
        for key in params
    )

    response = requests.get(url, {'type': type, 'q': query})

    if response.status_code == 419:
        timeout = int(response.headers['Retry-After'])
        sys.stderr.write('Rate limited, waiting {} seconds...\n'.format(timeout))
        time.sleep(timeout)
        return spotify_search(type, retries = 3, **params)

    if response.status_code != 200:
        if retries:
            logging.warning('Non-200 status code for {}, retrying in 1 second...\n'.format(query))
            time.sleep(1)
            return spotify_search(type, retries = retries - 1, **params)
        else:
            logging.critical('Non-200 status code for {}, no more retries'.format(query))
            raise Exception('Error in spotify api for {}'.format(query))

    type_plural = type + 's'

    if response.json()[type_plural]['total'] &gt; 0:
        return response.json()[type_plural]['items'][0]
    else:
        return None</code></pre>
<p>Essentially, it's just a call to the API endpoint <code>/v1/search</code>. The only two odd parts are how the query string is formatted (it looks something like this: <code>Artist:Arist Name Song:Song Name</code>) and the <code>memory.cache</code> decorator.</p>
<p>The decorator comes from <a href="https://pypi.python.org/pypi/joblib">joblib</a> and is basically an easy way to make sure that I don't fetch this information more than once per song no matter how many times I call this method. It will save the results and return them directly for any future calls. To initialize it, all I have to do is run <code>memory = joblib.Memory(cachedir = 'cache', verbose = 0)</code> at the top of my code.</p>
<p>Now that we have a way of looking up songs, lets write a few more helper methods to read from the iTunes library. The first thing that you have to do is check the Advanced setting to 'Share iTunes Library XML with other applications':</p>
<p><a href="//blog.jverkamp.com/2016/06/22/mirror-itunes-playlists-to-spotify/itunes-settings.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/06/22/mirror-itunes-playlists-to-spotify/itunes-settings.png" /></a></p>
<p>This will make the file <code>iTunes Library.xml</code> / <code>iTunes Music Library.xml</code> (it changed between Yosemite and El Capitan) available in your iTunes folder. This is a <a href="https://en.wikipedia.org/wiki/plist">plist</a> file which means the built in <a href="https://docs.python.org/2/library/plistlib.html">plistlib</a> can read it directly:</p>
<pre class="python"><code>path = os.path.expanduser('~/Music/iTunes/iTunes Music Library.xml')
with open(path, 'rb') as fin:
    ITUNES_LIBRARY = plistlib.load(fin)</code></pre>
<p>We can then use this directly to read in information about any given track that we have in our library.</p>
<pre class="python"><code>@memory.cache
def get_track(track_id):
    '''Get a track by ID.'''

    logging.debug('get_track({})'.format(track_id))

    track = ITUNES_LIBRARY['Tracks'].get(str(track_id), None)
    if not track:
        return None

    def remove_parentheticals(s):
        return re.sub(r'\s+[\(\[].*[\)\]]', '', s)

    spotify_data = spotify_search('track',
        artist = remove_parentheticals(track['Artist']),
        track = remove_parentheticals(track['Name']),
    )

    if spotify_data:
        track.update(spotify_data)

    return track</code></pre>
<p>Essentially, we pull the <code>Tracks</code> object out of the iTunes library which is indexed by a <code>track_id</code>. There's one kind of weird part here in that the <code>Tracks</code> object uses numeric strings as keys while the <code>Playlists</code> tracks (see below) are returned as <code>int</code>s. Thus the cast. We take the information from iTunes and then try to look up the song in Spotify. If the search returns, we shove the two objects together. If not, we return just the iTunes information and deal with that later.</p>
<p>Next, we want to look up playlists:</p>
<pre class="python"><code>def get_playlists():
    '''
    Return all playlists for the current user.

    Each will be of the form:
    {'name': '{playlist_name}', 'tracks': [...]}
    '''

    for playlist in ITUNES_LIBRARY['Playlists']:
        if any(key in playlist and playlist[key] for key in ['Master', 'Movies', 'TV Shows', 'Podcasts', 'iTunesU', 'Audiobooks']):
            continue

        yield {
            'name': playlist['Name'],
            'tracks': [
                get_track(track['Track ID'])
                for track in playlist['Playlist Items']
                if get_track(track['Track ID'])
            ]
        }</code></pre>
<p>This is a bit odd, since there are many different kinds of playlists in the iTunes library, not all of which have the same keys. With a bit of experimentation, I found that the list of keys above are the ones we want to avoid. Other than that, we will <code>yield</code> each playlist along with a list of track objects from <code>get_track</code>. This is why I cached those results, since a track can (and often will be) in multiple playlists and we don't want to re-fetch the track information if that's the case.</p>
<p>That's actually the lion's share of what I need. All that's left is the code to create / find Spotify playlists and then add the songs to them. For that, I'm going to use the <a href="https://github.com/plamere/spotipy">spotipy</a> library rather than directly dealing with the endpoints. For the most part, it really helps with the OAuth tokens. All we have to do to create a Spotipy client is this:</p>
<pre class="python"><code>token = spotipy.util.prompt_for_user_token(
    os.env['SPOTIFY_USERNAME'],
    client_id = os.env['SPOTIFY_CLIENT_ID'],
    client_secret = os.env['SPOTIFY_CLIENT_SECRET'],
    redirect_uri = os.env['SPOTIFY_REDIRECT_URI'],
    scope = os.env['SPOTIFY_SCOPE'],
)

sp = spotipy.Spotify(auth = token)</code></pre>
<p>You have to <a href="https://developer.spotify.com/my-applications/#!/applications">create a Spotify App</a>, but that's straight forward enough and free. The first time this is run, you will have to okay the permissions in your web browser, but after that it will keep track of your Spotify API token and will run transparently.</p>
<p>I'm going to use that to write one more helper method:</p>
<pre class="python"><code>def get_spotify_playlist(title):
    '''Get either an existing or new playlist by title.'''

    playlists = sp.user_playlists(sp.me()['id'])['items']
    for playlist in playlists:
        if title == playlist['name']:
            return playlist

    return sp.user_playlist_create(sp.me()['id'], title)</code></pre>
<p><a href="http://aguo.us/writings/spotify-billboard.html">The article</a> that inspired this code only used the <code>user_playlist_create</code> method, but that will create a new playlist on each run. Instead, we want to check if there's already a playlist matching the name that we're trying to create. If so, return that playlist. If not, create a new one to return.</p>
<p>Now we have everything we need. We can write a script that will loop through any iTunes playlists specified on the command line (or all of them if none are specified) and sync them to Spotify:</p>
<pre class="python"><code>for playlist in get_playlists():
    if len(sys.argv) &gt; 1 and playlist['name'] not in sys.argv:
        continue

    spotify_playlist = get_spotify_playlist('iTunes - {}'.format(playlist['name']))

    uris = [
        track['uri'] for
        track in playlist['tracks']
        if 'uri' in track
    ]

    def chunks(items, size):
        for start in range(0, len(items), size):
            yield items[start : start + size]

    for uri_chunk in chunks(uris, 100):
        sp.user_playlist_add_tracks(sp.me()['id'], spotify_playlist['id'], uri_chunk)</code></pre>
<p>I did hit one interesting temporary roadblock in that the Spotify API cannot accept more than 100 URIs at a time, but the <code>chunk</code> method took care of that. One thing that is nice is that the list of songs in a playlist form a set. So it doesn't matter if we add the same song to a playlist more than once, it will still only exist a single time. That's pretty cool!</p>
<p>And that's it. A quick run (it took a few minutes to get all of the information for the 500 songs I have in my iTunes library) and I now have a Spotify playlist for each of my iTunes ones. It's not perfect. There are still a few artists that are on Apple Music but not Spotify. But for a stopgap and when I'm on computers that don't have my iTunes library, it works pretty well. I'll probably set this up to run periodically, just so I always have my playlists relatively up to date.</p>]]></content></entry><entry><title>Parsing Motorola Surfboard stats</title><link href="//blog.jverkamp.com/2016/06/04/parsing-motorola-surfboard-stats" /><id>urn:uuid:91b517e2-ff8e-5c7a-e9f5-67526c7c4209</id><updated>2016-06-04T00:00:00Z</updated><summary type="html"><![CDATA[<p>A few weeks ago, I was having some pretty bad problems with my internet randomly hanging. Given that I'm now working from home, that wasn't exactly the most optimal of situations to find myself in, so I decided to dig a bit deeper. After a bit of looking, I found myself at my cable modem's built in web page:</p>
<p><a href="//blog.jverkamp.com/2016/06/04/parsing-motorola-surfboard-stats/downstream.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/06/04/parsing-motorola-surfboard-stats/downstream.png" /></a></p>
<p>(This is after I fixed my problem. The values aren't perfect but they're much better.)</p>
]]></summary><content type="html"><![CDATA[<p>A few weeks ago, I was having some pretty bad problems with my internet randomly hanging. Given that I'm now working from home, that wasn't exactly the most optimal of situations to find myself in, so I decided to dig a bit deeper. After a bit of looking, I found myself at my cable modem's built in web page:</p>
<p><a href="//blog.jverkamp.com/2016/06/04/parsing-motorola-surfboard-stats/downstream.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/06/04/parsing-motorola-surfboard-stats/downstream.png" /></a></p>
<p>(This is after I fixed my problem. The values aren't perfect but they're much better.)</p>
<!--more-->
<p>There are three numbers here that are particularly interesting:</p>
<ul>
    <li><code>Signal to Noise Ratio</code> - >30 dB, although theoretically it can work as low as 25 dB at times; this one is fine</li>
    <li><code>Downstream Power Level</code> - ±15 dbmV is supposed to be acceptable, but you really want no more than ±8 dbmV (that's why I said it's not great at the moment); I was getting -15 dbmV or worse consistently</li>
    <li><code>Upstream Power Level</code> (not shown) - 37-55 dbmV, lower is generally better; I'm getting 47 dbmV, so once again fine</li>
</ul>
<p>The nice thing about all of these numbers is that they are relatively easy to parse. All of the pages are a series of HTML tables, so I should be able to parse them relatively quickly with a combination of <a href="http://docs.python-requests.org/en/master/">Requests</a> to pull down the pages and <a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a> to parse them.</p>
<p>First, let's write a helper that can parse an table into a Python list of lists:</p>
<pre class="python"><code>def parse_table(table):
    '''Given soup &lt;table&gt;, extract the rows'''

    rows = []

    for tr in table.find_all('tr'):
        if not tr.find_all('td'):
            continue

        rows.append([
            td.text.strip()
            for td in tr.find_all('td')
            if td.text.strip()
        ])

    return rows</code></pre>
<p>Then furthermore, let's assume the first row is a header row and turn them into a list of dictionaries:</p>
<pre class="python"><code>def lol_to_lod(table, transpose = False):
    '''Convert a list of lists with headers into a list of dicts.'''

    if transpose:
        table = list(zip(*table))

    headers = table[0]

    return [
        dict(zip(headers, row))
        for row in table[1:]
    ]</code></pre>
<p>There's some magic going on there, <code>zip</code>ping the <code>headers</code> and <code>row</code> together to make a <code>dict</code> and transposing arrays via <code>list(zip(*table))</code>. It's perhaps not the most readable code ever, but it's amusing and compact.</p>
<p>After that, it's just a matter of downloading each of the pages and doing a little bit of massaging the data to get it into a consistent form:</p>
<pre class="python"><code>def tables_for(endpoint):
    response = requests.get('http://192.168.100.1' + endpoint)
    soup = bs4.BeautifulSoup(response.text, 'lxml')
    return [parse_table(table) for table in soup.find_all('table')]

def status_page():
    tables = tables_for('/indexData.htm')

    result = {}
    result.update(lol_to_lod(tables[0], transpose = True)[0])
    result.update(lol_to_lod(tables[1], transpose = True)[0])
    return result

def signal_page():
    tables = tables_for('/cmSignalData.htm')
    tables[0][4][0] = 'Power Level'
    del tables[0][-1]
    del tables[0][-1][1]

    return {
        'downstream': lol_to_lod(tables[0], transpose = True),
        'upstream': lol_to_lod(tables[2], transpose = True),
        'codewords': lol_to_lod(tables[3], transpose = True),
    }

def addresses_page():
    tables = tables_for('/cmAddressData.htm')
    tables[1].insert(0, ['Index', 'MAC Address', 'Status'])

    result = lol_to_lod(tables[0], transpose = True)[0]
    result['clients'] = lol_to_lod(tables[1])

    return result

def configuration_page():
    tables = tables_for('/cmConfigData.htm')
    return lol_to_lod(tables[0][:-1], transpose = True)

def logs_page():
    tables = tables_for('/cmLogsData.htm')
    tables[0].insert(0, ['Time', 'Priority', 'Code', 'Message'])
    return lol_to_lod(tables[0])</code></pre>
<p>It's a bit odd since each of the pages is actually one page containing another as an <code>iframe</code>, but a quick look into the source gets me all of the names. It's far more data than you probably actually need (and a good bit of it never changes), but you can always filter it after or compress the heck out of it (lines of mostly the same JSON compress very well; 90%+)</p>
<p>Combine everything into one more layer of Python <code>dict</code> and dump the whole thing as a JSON object.</p>
<pre class="python"><code>results = {
    'status': status_page(),
    'signal': signal_page(),
    'addresses': addresses_page(),
    'configuration': configuration_page(),
    'logs': logs_page(),
}

print(json.dumps(results))</code></pre>
<p>Combined with the excellent <a href="https://stedolan.github.io/jq/">jq</a> to make it pretty:</p>
<pre class="bash"><code>$ modem-stats | jq '.'

{
  "signal": {
    "upstream": [
      {
        "Upstream Modulation": "[3] QPSK\n[3] 64QAM",
        "Ranging Status": "Success",
        "Channel ID": "79",
        "Symbol Rate": "5.120 Msym/sec",
        "Frequency": "21000000 Hz",
        "Ranging Service ID": "15160",
        "Power Level": "47 dBmV"
      },
      ...
    ],
    "codewords": [
      {
        "Total Unerrored Codewords": "9570874877",
        "Channel ID": "10",
        "Total Uncorrectable Codewords": "19826",
        "Total Correctable Codewords": "4667"
      },
      ...
    ],
    "downstream": [
      {
        "Signal to Noise Ratio": "36 dB",
        "Downstream Modulation": "QAM256",
        "Frequency": "663000000 Hz",
        "Power Level": "-9 dBmV",
        "Channel ID": "10"
      },
      ...
    ]
  },
  "addresses": {
    "Serial Number": "{redacted}",
    "clients": [
      {
        "Index": "1",
        "MAC Address": "{redacted}",
        "Status": "Dynamic"
      }
    ],
    "Ethernet MAC Address": "{redacted}",
    "HFC MAC Address": "{redacted}",
    "Ethernet IP Address": "192.168.100.1"
  },
  "status": {
    "Current Time and Date": "Jun 03 2016 23:25:32",
    "System Up Time": "2 days 10h:30m:54s",
    "DOCSIS Downstream Channel Acquisition": "Done",
    "Establish IP Connectivity using DHCP": "Done",
    "Initialize Baseline Privacy": "Done",
    "DOCSIS Ranging": "Done",
    "Register Connection": "Done",
    "Establish Time Of Day": "Done",
    "Transfer Operational Parameters through TFTP": "Done",
    "Cable Modem Status": "Operational"
  },
  "configuration": [
    {
      "Frequency Plan:": "North American Standard/HRC/IRC",
      "Upstream Channel ID:": "79",
      "Favorite Frequency (Hz)": "663000000",
      "Modem's IP Mode": "IPv6 Only",
      "Custom Frequency Ordering:": "Default",
      "DOCSIS MIMO": "Honor MDD IP Mode"
    }
  ],
  "logs": [
    ...
  ]
}</code></pre>
<p>You can also use a bit of shell-fu to combine everything to get an average downstream power level at any given point in time:</p>
<pre class="bash"><code>$ modem-stats \
    | jq '.signal.downstream[]."Power Level"' \
    | tr -d '"' \
    | awk '{ sum += $1; count += 1 } END { print sum/count }'

-8.25</code></pre>
<p>Combine that with a minutely cronjob and you can even detect when certain stats get particularly bad.</p>
<p>In the end, it was mostly a hardware issue. The coaxial cable I was using between the wall and my modem had a few kinks in it. I replaced with a newer, slightly shorter cable and all was well.</p>
<p>But still, it's interesting to have such statistics.</p>
<p>If you'd like to download the entire script, it's in my <a href="https://github.com/jpverkamp/dotfiles/">dotfiles</a>: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/modem-stats">modem-stats</a>.</p>]]></content></entry><entry><title>Automatically uploading files</title><link href="//blog.jverkamp.com/2016/06/03/automatically-uploading-files" /><id>urn:uuid:90df3103-501b-d352-df53-c06dfd486fbd</id><updated>2016-06-03T00:00:00Z</updated><summary type="html"><![CDATA[<p>Quick post today. I was working on a website where I have a live server running the code on another machine. I wanted to write a quick script that would copy any files I changed to the remote machine. This is something you can do automatically in most IDEs, but I wanted something both a bit lighter weight and to have the excuse to write something myself.</p>
]]></summary><content type="html"><![CDATA[<p>Quick post today. I was working on a website where I have a live server running the code on another machine. I wanted to write a quick script that would copy any files I changed to the remote machine. This is something you can do automatically in most IDEs, but I wanted something both a bit lighter weight and to have the excuse to write something myself.</p>
<!--more-->
<p>Basically, I'm going to wrap <a href="https://fsnotify.org/">fsnotify</a> with a quick queue that can keep track of files as they're changed and upload them in order.</p>
<p>First, the functionality that can run an arbitrary command (at least one that returns a list of filenames) and put any files found into a queue (we'll see why in a moment):</p>
<pre class="python"><code>sync_queue = queue.Queue()

def sync_command(command):
    process = subprocess.Popen(command, shell = True, stdout = subprocess.PIPE)
    for line in process.stdout:
        for file in line.decode().strip().split():
            sync_queue.put(file)</code></pre>
<p>And then the other half--a thread that can take those files off the queue and automatically upload them to a remote server:</p>
<pre class="python"><code>def do_sync():
    while True:
        path = sync_queue.get()
        local_path = path.replace(local_directory, '').lstrip('/')
        remote_path = remote_directory.rstrip('/') + '/' + local_path

        print('[{} remaining] {} ... '.format(sync_queue.qsize(), local_path), end = '')
        sys.stdout.flush()

        subprocess.check_call('scp "{local_path}" "{remote_host}:{remote_path}"'.format(
            local_path = local_path,
            remote_host = remote_host,
            remote_path = remote_path
        ), shell = True, stdout = subprocess.PIPE, stderr = subprocess.STDOUT)

        print('done')

# Start up the sync thread
sync_thread = threading.Thread(target = do_sync)
sync_thread.daemon = True
sync_thread.start()</code></pre>
<p>And that's all we need. We can run a trio of commands to automatically sync any changes that we've made on a <code>git</code> branch plus any we make going forward:</p>
<pre class="python"><code># Sync any differences on the current branch (first changed, then new files)
sync_command('git diff --name-only master')
sync_command('git ls-files --others --exclude-standard')

# Sync any changes to files as they happen
sync_command('fswatch -r -e ".git" .')</code></pre>
<p>And that's it. <code>fswatch</code> really does most of the work, but it's a nice wrapper that will continually sync files until you tell it to quit.</p>
<p>It's useful enough that I already put it in my <code>dotfiles</code> repo: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/sync">sync</a>.</p>]]></content></entry><entry><title>Ensuring docker-machine is running</title><link href="//blog.jverkamp.com/2016/04/19/ensuring-docker-machine-is-running" /><id>urn:uuid:0e62eb30-f56c-7441-a014-2f509ef5d9d5</id><updated>2016-04-19T00:00:00Z</updated><summary type="html"><![CDATA[<p>When developing using <a href="https://www.docker.com/">docker</a> on OS X, you'll currently<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> have to use <a href="https://docs.docker.com/machine/">docker-machine</a> to spin up a virtual machine that is actually running the docker containers. Running a virtual machine takes up a bit more in the way of resources than just the docker containers, so if you're not actually developing at the moment, it's helpful to be able to start up the virtual machine only when you need it.</p>
<p>The current way I have to do that:</p>
<pre class="bash"><code>$ docker-machine start default
$ eval $(docker-machine env default)</code></pre>
<p>What's worse, the latter command has to be run for every shell that you start up. It's by no means a hard pair of commands and you could easily wrap them in an alias or put them in your <code>.profile</code> equivalent (which is what I used to do). But unfortunately, I found a completely unrelated bug in <a href="https://github.com/tony/tmuxp"><code>tmuxp</code></a>: if the shell takes too long to start up, <code>tmuxp</code> essentially won't work. The above <code>eval</code> command took long enough to hit this limit.</p>
]]></summary><content type="html"><![CDATA[<p>When developing using <a href="https://www.docker.com/">docker</a> on OS X, you'll currently<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span> have to use <a href="https://docs.docker.com/machine/">docker-machine</a> to spin up a virtual machine that is actually running the docker containers. Running a virtual machine takes up a bit more in the way of resources than just the docker containers, so if you're not actually developing at the moment, it's helpful to be able to start up the virtual machine only when you need it.</p>
<p>The current way I have to do that:</p>
<pre class="bash"><code>$ docker-machine start default
$ eval $(docker-machine env default)</code></pre>
<p>What's worse, the latter command has to be run for every shell that you start up. It's by no means a hard pair of commands and you could easily wrap them in an alias or put them in your <code>.profile</code> equivalent (which is what I used to do). But unfortunately, I found a completely unrelated bug in <a href="https://github.com/tony/tmuxp"><code>tmuxp</code></a>: if the shell takes too long to start up, <code>tmuxp</code> essentially won't work. The above <code>eval</code> command took long enough to hit this limit.</p>
<!--more-->
<p>So how do we fix it? Essentially (using <a href="http://www.zsh.org/">zsh</a>, my current shell of choice, although others should be similar):</p>
<pre class="zsh"><code>assert-docker() {
    command docker ps 2&gt; /dev/null &gt; /dev/null
    if [ $? -ne 0 ]; then
        echo "Starting docker..."
        docker-machine start default
        eval $(docker-machine env default)
        echo
    fi
}

docker () { assert-docker && command docker $@ }
docker-compose () { assert-docker && command docker-compose $@ }</code></pre>
<p>The basic idea is that <code>assert-docker</code> first checks if <code>docker</code> is running by trying to run <code>docker ps</code>. <code>$?</code> contains the status code, which will be non-zero if <code>docker ps</code> failed, so check that. If that's the case, assume <code>docker ps</code> failed because <code>docker-machine</code> wasn't running, so start it up. This will run <code>docker-machine start default</code> more often than needed, but it turns out it's a <code><a href="https://en.wikipedia.org/wiki/NOP">NOP</a></code> if it's already running.</p>
<p>The only interesting part here is the use of the keyword <code>command</code> that prefixes <code>docker</code> or <code>docker-machine</code> within the functions. Basically, this tells ZSH to use the system version of <code>docker</code> or <code>docker-compose</code> rather than the one that I defined, thus preventing an infinite loop. Whee!</p>
<p>How's it work?</p>
<pre class="bash"><code>$ docker ps

Starting docker...
(dev) OUT | Starting VM...
Started machines may have new IP addresses. You may need to re-run the &lt;code&gt;docker-machine env&lt;/code&gt; command.

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

$ docker ps

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</code></pre>
<p>Switching to another terminal:</p>
<pre class="bash"><code>$ docker ps

Starting docker...
Machine "default" is already running.

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES

$ docker ps

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</code></pre>
<p>Neat. That should <a href="https://xkcd.com/1205/">eventually save me a fraction of the time</a> it took to get it right. :)</p>]]></content></entry><entry><title>Audiobooks to Podcasts</title><link href="//blog.jverkamp.com/2016/02/26/audiobooks-to-podcasts" /><id>urn:uuid:cfe78150-139b-aa1d-01bd-c73e7e91fd17</id><updated>2016-02-26T00:05:00Z</updated><summary type="html"><![CDATA[<p>I've recently started to listen to audiobooks again (<a href="//blog.jverkamp.com/2016/02/10/the-aeronauts-windlass">The Aeronaut's Windlass</a>). If you buy books through Audible or some other setup that has their own app, it's a straight forward enough process. On the other hand, if you have them on CD and want to play them on a mobile device... It's a little more interesting.</p>
<p>I tried a few different apps that purport to do exactly what I wanted: import an audiobook as a folder full of MP3s and play them, but none that quite meet what I wanted. Since I also listen to a lot of podcasts and have more than one podcast app that I really like (I've used and liked both <a href="http://www.downcastapp.com/">Downcast</a> and <a href="http://www.shiftyjelly.com/pocketcasts">Pocket Casts</a>), I decided to see if I couldn't use one of those as an audiobook player.</p>
]]></summary><content type="html"><![CDATA[<p>I've recently started to listen to audiobooks again (<a href="//blog.jverkamp.com/2016/02/10/the-aeronauts-windlass">The Aeronaut's Windlass</a>). If you buy books through Audible or some other setup that has their own app, it's a straight forward enough process. On the other hand, if you have them on CD and want to play them on a mobile device... It's a little more interesting.</p>
<p>I tried a few different apps that purport to do exactly what I wanted: import an audiobook as a folder full of MP3s and play them, but none that quite meet what I wanted. Since I also listen to a lot of podcasts and have more than one podcast app that I really like (I've used and liked both <a href="http://www.downcastapp.com/">Downcast</a> and <a href="http://www.shiftyjelly.com/pocketcasts">Pocket Casts</a>), I decided to see if I couldn't use one of those as an audiobook player.</p>
<!--more-->
<p>My basic set up is one that I've used before. I'll use <a href="https://docs.docker.com/compose/">docker-compose</a> to run a web server running <a href="http://flask.pocoo.org/">flask</a> behind an <a href="https://www.nginx.com/resources/wiki/">nginx reverse proxy</a> (for performance reasons and to serve static files).</p>
<p>Basically, I want a server that when I hit it will give a list of all books in a folder. If I click any of those, it will generate an RSS feed that I can then give to my podcasting application. That in turn can make requests for any of the MP3 files that make up the book, which should be served back to the app. Simple as pie, no? Well, mostly.</p>
<p>Creating a list of books is easy:</p>
<pre class="python"><code>@app.route('/')
def index():
    result = '&lt;ul&gt;'

    for path in sorted(os.listdir('books')):
        config_path = os.path.join('books', path, 'book.yml')
        print(config_path)

        if not os.path.exists(config_path):
            continue

        with open(config_path, 'r') as fin:
            config = yaml.load(fin)

        result += '&lt;li&gt;&lt;a href="feed/{path}.xml"&gt;{title} by {author}&lt;/a&gt;&lt;/li&gt;'.format(
            path = path,
            title = config['title'],
            author = config['author']
        )

    result += '&lt;/ul&gt;'
    return result</code></pre>
<p>Note: Each book is a subdirectory of the folder <code>books</code>. Each book must also contain at least one file named <code>book.yml</code> which defines the <code>title</code> and <code>author</code> of the book, along with any number of MP3 files (we'll see that in a moment).</p>
<p>All this script does is generate an HTML unordered list (<code>ul</code>) of links to individual RSS feeds. We generate those in turn with:</p>
<pre class="python"><code>@app.route('/feed/&lt;feed&gt;.xml')
def get_feed(feed):
    config_path = os.path.join('books', feed, 'book.yml')

    with open(config_path, 'r') as fin:
        config = yaml.load(fin)

    fg = feedgen.feed.FeedGenerator()
    fg.load_extension('podcast')

    host_url = flask.request.scheme + '://' + flask.request.host

    feed_link = host_url + '/feed/{feed}.xml'.format(feed = feed)

    fg.id = feed_link
    fg.title(config['title'])
    fg.description('{title} by {author}'.format(title = config['title'], author = config['author']))
    fg.author(name = config['author'])
    fg.link(href = feed_link, rel = 'alternate')

    fg.podcast.itunes_category('Arts')

    for file in sorted(os.listdir(os.path.join('books', feed))):
        if not file.endswith('.mp3'):
            continue

        name = file.rsplit('.', 1)[0]

        feed_entry_link = host_url + '/feed/{feed}/{file}'.format(feed = feed, file = file)

        fe = fg.add_entry()

        fe.id(feed_entry_link)
        fe.title(name)
        fe.description('{title} by {author} - {chapter}'.format(
            title = config['title'],
            author = config['author'],
            chapter = name,
        ))
        fe.enclosure(feed_entry_link, 0, 'audio/mpeg')

    return fg.rss_str(pretty = True)</code></pre>
<p>Here, I basically just read in the <code>book.yml</code> file and any MP3s in the directory and generate a feed. As I did previously in my post on <a href="//blog.jverkamp.com/2015/05/11/generating-youtube-user-rss-feeds">Generating YouTube user RSS feeds</a>, I'm using the <a href="https://lkiesow.github.io/python-feedgen/">feedgen</a> package to generate the RSS feeds. This time I'm using their built in <code>podcast</code> extension. Nice.</p>
<p>After that, we just need to serve the MP3s. Originally I was going to serve this with flask as well, but since I'm already going to use nginx as a performance / caching layer, we can use that to serve static files. Something like this for an nginx configuration:</p>
<pre class="nginx"><code>server {
    root /var/www/;

    location / {
        try_files $uri @server;
    }

    location @server {
        proxy_set_header Host $host;
        proxy_pass http://server:5000;
    }
}</code></pre>
<p>Essentially, it will <code>try_files</code> to see if there's a static file at the path requested first. If that fails, it will fall back to the <code>@server</code> reverse proxy, which just feeds traffic to the flask server.</p>
<p>To get everything working together, we'll use docker-compose:</p>
<pre class="yaml"><code>server:
    build: server
    # environment: {DEBUG: True}
    ports:
        - 5000
    volumes:
        - ./books:/app/books

nginx:
    image: nginx
    links:
        - server
    ports:
        - 80:80
    volumes:
        - ./books:/var/www/feed/
        - ./nginx:/etc/nginx/conf.d/</code></pre>
<p>Since I'm mounting the <code>./books</code> directory as a volume into both containers, the <code>nginx</code> container can use it to server static files while the <code>server</code> container can use it to list files.</p>
<p>And that's about it. I have mine running with <a href="http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html">nginx HTTP authentication </a>, which means that I have to use <a href="http://www.downcastapp.com/">Downcast</a> (it's the only one I've used that seems to support it), but other than that it works great. It does require that you have your own server running to initially get the files onto the podcast app, but if you download them, almost all of the apps will let you turn off the server.</p>
<p>The combination of flask and docker is nice. Flask let's you quickly and easily write simple web applications. Docker makes deployment and dependency management a snap.</p>
<p>If you'd like to see the entire codebase, it's on GitHub: <a href="https://github.com/jpverkamp/podbook">podbook</a>. There are a few bits that I didn't include in the writeup above.</p>
<p>Any questions? Let me know below.</p>]]></content></entry><entry><title>Duplicating AeroSnap on OSX with Hammerspoon</title><link href="//blog.jverkamp.com/2016/02/08/duplicating-aerosnap-on-osx-with-hammerspoon" /><id>urn:uuid:09374126-32e6-69a9-1a73-8141f97dec1a</id><updated>2016-02-08T00:00:00Z</updated><summary type="html"><![CDATA[<p>Relatively recently, I switched my last Windows machine over to OSX. For the most part, it's been great. One bit of functionality that I've been missing though is AeroSnap. Specifically the ability to use a keyboard shortcut to move windows to the left/right half of a monitor.</p>
]]></summary><content type="html"><![CDATA[<p>Relatively recently, I switched my last Windows machine over to OSX. For the most part, it's been great. One bit of functionality that I've been missing though is AeroSnap. Specifically the ability to use a keyboard shortcut to move windows to the left/right half of a monitor.</p>
<!--more-->
<p>For a while, <a href="https://www.boastr.net/">BetterTouchTool</a> provided that functionality for me, among it's many (many) other options. Unfortunately (for me, it's a good move for them), the author(s) of BetterTouchTool are now moving to a paid model. Since I use only a tiny fraction of the functionality, I decided to see if there were other options.</p>
<p>The first thing that I stumbled across was <a href="https://github.com/fikovnik/ShiftIt">ShiftIt</a>. It actually has exactly the functionality that I wanted and was configurable enough that I could tweak the keybindings to what my fingers already expected them to be. If you don't particularly want to tweak the functionality and just want AeroSnapesqe functionality, this is probably a good enough option.</p>
<p>Me though? I love to tweak things.</p>
<p>With unusually precient timing, Lifehacker posted an article about <a href="http://www.hammerspoon.org/">Hammerspoon</a>: <a href="http://lifehacker.com/hammerspoon-is-powerful-free-automation-tool-for-os-x-1757351485">Hammerspoon Is Powerful, Free Automation Tool for OS X</a></p>
<p>Interesting.</p>
<p>After a bit of digging, I found that their <a href="http://www.hammerspoon.org/go/">Getting Started</a> document actually has an example that does exactly what I want to do: <a href="http://www.hammerspoon.org/go/#winresize">Window sizing</a> Shiny!</p>
<p>A bit of tweaking and this is what I ended up with:</p>
<h3><code>.hammerspoon/init.lua</code></h3>
<p>Base code, handles reloading, locking, and loading modules</p>
<pre class="lua"><code>-- Reload hammerspoon configs
hs.hotkey.bind({"cmd", "ctrl"}, "R", function()
    hs.reload()
end)
hs.alert.show("Config loaded")

-- Lock
hs.hotkey.bind({"cmd", "ctrl"}, 'L', function()
    os.execute("open '/System/Library/Frameworks/ScreenSaver.framework/Versions/A/Resources/ScreenSaverEngine.app'")
end)

require('aerosnap')</code></pre>
<p>The first is another example from their documentation of bind a keyboard shortcut to reloading the Hammerspoon documentation. The second is another keyboard shortcut I missed from Windows: the ability to lock the screen without logging out (the normal lock functionality disables networking and thus things like remote login).</p>
<h3><code>.hammerspoon/aerosnap/init.lua</code></h3>
<pre class="lua"><code>-- Aerosnap helper functions to get and set current window parameters
function aerosnap_get_parameters()
    local window = hs.window.focusedWindow()
    local frame = window:frame()
    local screen = window:screen()
    local bounds = screen:frame()

    return window, frame, bounds
end

-- Aerosnap help to move a window to a specified position
function aerosnap_move_window(x, y, w, h)
    local window, frame, bounds = aerosnap_get_parameters()

    frame.x = x
    frame.y = y
    frame.w = w
    frame.h = h

    window:setFrame(frame)
end

-- Save the current window's position so we can restore it
function aerosnap_save_window()
    local window, frame, bounds = aerosnap_get_parameters()
    saved_window_sizes = saved_window_sizes or {}
    saved_window_sizes[window:id()] = {x = frame.x, y = frame.y, w = frame.w, h = frame.h}
end

-- Aerosnap move window to the left half
hs.hotkey.bind({"cmd", "ctrl"}, "Left", function()
    local window, frame, bounds = aerosnap_get_parameters()
    aerosnap_save_window()
    aerosnap_move_window(bounds.x, bounds.y, bounds.w / 2, bounds.h)
end)

-- Aerosnap move window to the right half
hs.hotkey.bind({"cmd", "ctrl"}, "Right", function()
    local window, frame, bounds = aerosnap_get_parameters()
    aerosnap_save_window()
    aerosnap_move_window(bounds.x + bounds.w / 2, bounds.y, bounds.w / 2, bounds.h)
end)

-- Aerosnap maximize current window, saving size to restore
hs.hotkey.bind({"cmd", "ctrl"}, "Up", function()
    local window, frame, bounds = aerosnap_get_parameters()
    aerosnap_save_window()
    aerosnap_move_window(bounds.x, bounds.y, bounds.w, bounds.h)
end)

-- Restore the last saved window configuration for a window (basically, a one level undo)
hs.hotkey.bind({"cmd", "ctrl"}, "Down", function()
    local window, frame, bounds = aerosnap_get_parameters()

    old_bounds = saved_window_sizes[window:id()]
    if old_bounds ~= nil then
        aerosnap_move_window(old_bounds.x, old_bounds.y, old_bounds.w, old_bounds.h)
        saved_window_sizes[window:id()] = nil
    end
end)</code></pre>
<p>Basically, I took the same functionality that they had in the demo and factored out the functionality that gets the current window / sets the new sizes. The other interesting bit is the <code>aerosnap_save_window</code> function, which allows you to restore the size of a window you had just maximized. This does have something of a memory leak (in that it never clears up closed windows), but the amount should be small enough that it doesn't overly matter.</p>
<p>And that's it. My full configs are available in my dotfiles (if I make any further tweaks or add more functionality): <a href="https://github.com/jpverkamp/dotfiles/tree/master/hammerspoon">hammerspoon configs</a></p>
<p>I'm looking forward to seeing what else I can do with Hammerspoon. You can get fairly extensive: <a href="https://github.com/tstirrat/hammerspoon-config">example Hammerspoon config</a>.</p>
<p>Also, if you want an alternative to Hammerspoon with what looks like a more modular approach, check out <a href="https://github.com/sdegutis/mjolnir">Mjolnir</a>. It appears that Hammerspoon is a fork of Mjolnir, so their configs are rather similar.</p>]]></content></entry><entry><title>Command line unicode search</title><link href="//blog.jverkamp.com/2016/01/06/command-line-unicode-search" /><id>urn:uuid:842e94d5-f91e-d1f9-c793-73043fa69212</id><updated>2016-01-06T00:00:00Z</updated><summary type="html"><![CDATA[<p>Similar to Monday's post about <a href="//blog.jverkamp.com/2016/01/04/command-line-emoji-search">command line emoji search</a>, I often find myself wanting to look up Unicode characters. I have a custom search engine / bookmark set up in Chrome / Firefox (<code>uni %s</code> maps to <code>http://unicode-search.net/unicode-namesearch.pl?term=%s&.submit=Submit&subs=1</code>). That actually works great, but given how relatively much of my day I spend on the command line, I thought it would be interesting to do something there:</p>
<pre class="bash"><code>$ uni delta
⍋	apl functional symbol delta stile
⍙	apl functional symbol delta underbar
⍍	apl functional symbol quad delta
≜	delta equal to
Δ	greek capital letter delta
δ	greek small letter delta
ẟ	latin small letter delta
ƍ	latin small letter turned delta
𝚫	mathematical bold capital delta
𝜟	mathematical bold italic capital delta
𝜹	mathematical bold italic small delta
𝛅	mathematical bold small delta
𝛥	mathematical italic capital delta
𝛿	mathematical italic small delta
𝝙	mathematical sans-serif bold capital delta
𝞓	mathematical sans-serif bold italic capital delta
𝞭	mathematical sans-serif bold italic small delta
𝝳	mathematical sans-serif bold small delta
ᵟ	modifier letter small delta</code></pre>
]]></summary><content type="html"><![CDATA[<p>Similar to Monday's post about <a href="//blog.jverkamp.com/2016/01/04/command-line-emoji-search">command line emoji search</a>, I often find myself wanting to look up Unicode characters. I have a custom search engine / bookmark set up in Chrome / Firefox (<code>uni %s</code> maps to <code>http://unicode-search.net/unicode-namesearch.pl?term=%s&.submit=Submit&subs=1</code>). That actually works great, but given how relatively much of my day I spend on the command line, I thought it would be interesting to do something there:</p>
<pre class="bash"><code>$ uni delta
⍋	apl functional symbol delta stile
⍙	apl functional symbol delta underbar
⍍	apl functional symbol quad delta
≜	delta equal to
Δ	greek capital letter delta
δ	greek small letter delta
ẟ	latin small letter delta
ƍ	latin small letter turned delta
𝚫	mathematical bold capital delta
𝜟	mathematical bold italic capital delta
𝜹	mathematical bold italic small delta
𝛅	mathematical bold small delta
𝛥	mathematical italic capital delta
𝛿	mathematical italic small delta
𝝙	mathematical sans-serif bold capital delta
𝞓	mathematical sans-serif bold italic capital delta
𝞭	mathematical sans-serif bold italic small delta
𝝳	mathematical sans-serif bold small delta
ᵟ	modifier letter small delta</code></pre>
<!--more-->
<p>The basic idea is to take Python's <code>unicodedata</code> module and use that to get the names of characters, then to find those that best match user input. Of course one problem with that is that as of version 8 of the Unicode specification there are up to 263,994 characters defined in 262 different blocks. That's a bit much.</p>
<p>So instead, I'm going to select a handpicked list of blocks that I think might be vaguely interesting (see <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/uni#L284">here</a>) as a default and add the ability to select any other block as a command line switch:</p>
<pre class="bash"><code>$ uni --block currency euro
€	euro sign
₠	euro-currency sign</code></pre>
<p>So, how do I do it? First, let's assume I have a list of unicode blocks defined as such (available from the Unicode Consortium: <a href="ftp://ftp.unicode.org/Public/8.0.0/ucd/Blocks.txt">Blocks.txt</a>):</p>
<pre class="text"><code>0000..007F; Basic Latin
0080..00FF; Latin-1 Supplement
0100..017F; Latin Extended-A
0180..024F; Latin Extended-B
0250..02AF; IPA Extensions
...</code></pre>
<p>First, we'll want to either determine which block(s) we'll be looking at:</p>
<pre class="python"><code># Determine which unicode blocks we'll be searching through
blocks = []

if args.block:
    for line in all_blocks.split('\n'):
        if fuzz.token_set_ratio(args.block, line.split('; ')[-1]) &gt; 100 * args.block_threshold:
            blocks.append(line)
else:
    blocks = default_blocks.split('\n')

if not blocks:
    sys.stderr.write('No blocks found\n')
    sys.exit(-1)</code></pre>
<p><code>args</code> contains the parsed command line parameters, I'll get to that later. <code>fuzz</code> is from the <a href="https://github.com/seatgeek/fuzzywuzzy">fuzzywuzzy</a> Python library for fuzzy string matching. Basically, if the <code>--block</code> parameter was specified, we'll search for any that match closely enough, otherwise we'll use the default blocks.</p>
<p>Next, we'll look through and build a list of all possible matching characters within those blocks. Given the formats above, we can get the lower and upper bounds with <code>int</code>, specifying base 16 and then use <code>unicodedata</code> to get the character name. Again, we'll apply a fuzzy match to the character names.</p>
<pre class="python"><code># Search through all of those blocks, whee
results = []

for block in blocks:
    bounds, name = block.split('; ')
    lower_bound, upper_bound = bounds.split('..')

    lower_bound = int(lower_bound, 16)
    upper_bound = int(upper_bound, 16)

    for codepoint in range(lower_bound, upper_bound + 1):
        try:
            character = chr(codepoint)
            name = unicodedata.name(character, None).lower()
            score = fuzz.token_set_ratio(args.name, name)

            if score &gt; 100 * args.name_threshold:
                results.append((score, name, character))
        except:
            pass

if not results:
    sys.stderr.write('No characters found\n')
    sys.exit(-1)</code></pre>
<p>And after that, we have a few tweaks for output. We can print all of the results (default) or just a limited number and we can print just the character or also the name:</p>
<pre class="python"><code># Only print out the requested number of results
for count, (score, name, character) in enumerate(sorted(results)):
    if args.count and count &gt;= args.count:
        break

    if args.quiet:
        print(character)
    else:
        print(character, name, sep = '\t')</code></pre>
<p>I guess now would be a good time to go back to how we got the <code>args</code> object in the first place:</p>
<pre class="python"><code>parser = argparse.ArgumentParser('Search unicode characters')
parser.add_argument('name', nargs = '+', help = ...)
parser.add_argument('--block', '-b', help = ...)
parser.add_argument('--block-threshold', default = 0.9, help = ...)
parser.add_argument('--name-threshold', default = 0.9, help = ...)
parser.add_argument('--count', default = 0, type = int, help = ...)
parser.add_argument('--quiet', '-q', default = False, action = 'store_true', help = ...)
args = parser.parse_args()</code></pre>
<p><code>argparse</code> is a most excellent library. It allows you to declaratively specify what your command line parameters will be and then will parse it into an object with one field for each variable (fixing the names so that <code>--block-threshold</code> becomes <code>args.block_threshold</code>).</p>
<p>And that's it. You can use it to look up all sorts of interesting things:</p>
<pre class="python"><code>uni --count 10 --block runic runic

ᛮ	runic arlaug symbol
ᛰ	runic belgthor symbol
᛭	runic cross punctuation
ᚪ	runic letter ac a
ᚫ	runic letter aesc
ᛉ	runic letter algiz eolhx
ᚨ	runic letter ansuz a
ᛒ	runic letter berkanan beorc bjarkan b
ᛍ	runic letter c
ᛣ	runic letter calc</code></pre>
<p>(That will display better if you're using a font that includes Unicode range <code>16A0..16FF; Runic</code>.)</p>
<p>For the most part, I'll use it in this mode and then select characters to copy and paste. But you could also combine it with <a href="https://github.com/garybernhardt/selecta">selecta</a> and <code>pbcopy</code> (on OSX) to get something entirely more interesting:</p>
<pre class="bash"><code>$ uni --block runic runic | selecta | cut -f 1 | tr -d '\n' | pbcopy</code></pre>
<p><code>uni</code> will display a list of characters, <code>selecta</code> will let you search for one, <code>cut</code> will get just the character, <code>tr</code> will remove the newline, and <code>pbcopy</code> will send it to the clipboard. You could even shove it into a Bash/ZSH alias:</p>
<pre class="bash"><code>pbuni() {
    uni $@ | selecta | cut -f 1 | tr -d '\n' | pbcopy
}</code></pre>
<p>Very cool.</p>
<p>This is in my dotfiles, so you can find the full source here: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/uni">uni</a>. Enjoy!</p>]]></content></entry><entry><title>Command line emoji search</title><link href="//blog.jverkamp.com/2016/01/04/command-line-emoji-search" /><id>urn:uuid:97c23a50-ef50-9386-e54b-947be0817eeb</id><updated>2016-01-04T00:00:00Z</updated><summary type="html"><![CDATA[<p>Sometimes, I find myself wanting to communicate in <a href="https://en.wikipedia.org/wiki/emoji">emoji</a>.</p>
<p><img alt="chicken" class="emoji" src="/emoji/chicken.svg" /></p>
<p>How about this:</p>
<pre class="bash"><code>$ emoji chicken
🐔

$ emoji "which came first, the @emoji{:chicken:} or the :egg:"
which came first, the 🐔 or the 🍳</code></pre>
]]></summary><content type="html"><![CDATA[<p>Sometimes, I find myself wanting to communicate in <a href="https://en.wikipedia.org/wiki/emoji">emoji</a>.</p>
<p><img alt="chicken" class="emoji" src="/emoji/chicken.svg" /></p>
<p>How about this:</p>
<pre class="bash"><code>$ emoji chicken
🐔

$ emoji "which came first, the @emoji{:chicken:} or the :egg:"
which came first, the 🐔 or the 🍳</code></pre>
<!--more-->
<p>To start off, I'm going to use the data from muan's emojilib on GitHub: <a href="https://github.com/muan/emojilib/">github:muan/emojilib</a>. Specifically, their list of keywords that relate to any given emoji: <a href="https://raw.githubusercontent.com/muan/emojilib/master/emojis.json">emojis.json</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span></p>
<p>We'll fetch that file if we haven't before and otherwise use a locally cached version:</p>
<pre class="python"><code>cache_path = os.path.expanduser('~/.emoji.json')
remote_url = 'https://raw.githubusercontent.com/muan/emojilib/master/emojis.json'

if not os.path.exists(cache_path):
    with open(cache_path, 'w') as fout:
        response = requests.get(remote_url)
        fout.write(response.text)

with open(cache_path, 'r') as fin:
    emoji = json.load(fin)</code></pre>
<p>After that, there are two different ways that we can look up Emoji. We can either look them up by a semi official name or by keyword. This function will search through the both, matching on names first and then falling back to the first which matches the given keyword (this script isn't designed to return choices for emoji, but rather just choose the first one that fits; because a Python <code>dict</code> isn't ordered, this is actually non-deterministic):</p>
<pre class="python"><code>def emoji_by_keyword(keyword):
    if keyword in emoji:
        return emoji[keyword]['char']

    for name in emoji:
        if name == 'keys':
            continue

        if keyword in emoji[name]['keywords']:
            return emoji[name]['char']

    return keyword</code></pre>
<p>Following that, we can use regular expressions (the <code>re</code> module) to replace emoji in a string--if they're set off <code>:emoji:</code> style (a la GitHub):</p>
<pre class="python"><code>def emojify(string):
    return re.sub(
        r'\:(\w+)\:',
        lambda m : emoji_by_keyword(m.group(1)),
        string
    )</code></pre>
<p>That's a neat trick that I use from time to time: the second argument to <code>re.sub</code> can be either a literal string or a function. If it's the latter, it's given the match object for each replacement, which we can then pass along to <code>emoji_by_keyword</code>.</p>
<p>And finally, let's mess with some command line arguments:</p>
<pre class="python"><code># Run replacement mode on stdin if no parameters
if len(sys.argv) == 1:
    for line in sys.stdin:
        print(emojify(line[:-1]))

# Othwise, run through the list
else:
    for arg in sys.argv[1:]:
        if ':' in arg:
            print(emojify(arg), end = ' ')
        else:
            print(emoji_by_keyword(arg), end = ' ')</code></pre>
<p>There are three modes we can be operating in:</p>
<ul>
    <li><code>stdin</code> mode, where we will read text from <code>stdin</code> and replace any <code>:emoji:</code> blocks with the corresponding emoji</li>
    <li>String mode, where we find any <code>:emoji:</code> in each argument in each input and replace them</li>
    <li>Single lookup mode, where we look up each argument as an individual emoji keyword, without the need for <code>:</code></li>
</ul>
<p>And, that's it.</p>
<pre class="bash"><code>$ emoji fireworks fireworks fireworks
🎆🎆🎆</code></pre>
<p>Since this is now one of my <a href="//blog.jverkamp.com/category/programming/by-topic/dotfiles">dotfiles</a>, you can find the entire source here: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/emoji">emoji</a></p>]]></content></entry><entry><title>Inlining plaintext attachments in Gmail</title><link href="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail" /><id>urn:uuid:c7dbc6ed-89ac-4c30-fa24-92e8614e530d</id><updated>2016-01-02T00:00:00Z</updated><summary type="html"><![CDATA[<p>When you send a text message to a Gmail email address (at least from an iPhone using AT&T), you get something like this:</p>
<p><a href="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-before.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-before.png" /></a></p>
<p>It's vaguely annoying to have to click through every single time just to see what the message is, especially when various extensions (such as <a href="https://github.com/gorhill/uMatrix">uMatrix</a>) break overlay rendering or when you have multiple attachments.</p>
<p>Much better would be to just display the plaintext attachments inline:</p>
<p><a href="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-after.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-after.png" /></a></p>
]]></summary><content type="html"><![CDATA[<p>When you send a text message to a Gmail email address (at least from an iPhone using AT&T), you get something like this:</p>
<p><a href="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-before.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-before.png" /></a></p>
<p>It's vaguely annoying to have to click through every single time just to see what the message is, especially when various extensions (such as <a href="https://github.com/gorhill/uMatrix">uMatrix</a>) break overlay rendering or when you have multiple attachments.</p>
<p>Much better would be to just display the plaintext attachments inline:</p>
<p><a href="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-after.png" data-toggle="lightbox"><img src="//blog.jverkamp.com/2016/01/02/inlining-plaintext-attachments-in-gmail/gpti-after.png" /></a></p>
<!--more-->
<p>Let's do it!</p>
<p>Essentially, I'm going to write a Javascript userscript, compatible with <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> or <a href="https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo?hl=en">Tampermonkey</a> for Chrome. Either allows you to insert small bits of Javascript into web pages to modify their behavior.</p>
<p>After digging around a bit in the structure of Gmail's message pages, here's roughly what I ended up with:</p>
<pre class="javascript"><code>var checkForPlaintexts = function(evt) {
    jQuery('span[download_url]').each(function(i, el) {
        var parts = el.getAttribute('download_url').split(':');
        if (!parts || parts[0] != 'text/plain') return;
        var url = parts[3];

        var newElement = jQuery('&lt;pre id="GPTI_' + i + '"&gt;&lt;/pre&gt;');
        newElement.text('Loading: ' + url);

        jQuery(el).replaceWith(newElement);
        jQuery.ajax({
            url: url,
            success: function(data) {
                newElement.text(data);
            }
        });
    });
};</code></pre>
<p>Basically, we're going to look for a <code>span</code> containing a <code>download_url</code> attribute. For the moment at least, that's always present with attachments and not otherwise. If you take that <code>download_url</code> element, you get something like this:</p>
<p><code>text/plain:text_0.txt:https://mail.google.com/mail/u/0/?ui=...</code>`</p>
<p>The first part is a <a href="https://en.wikipedia.org/wiki/MIME_type">MIME type</a>--of which, we're only interested in plaintext. The last section is a URL under gmail which, when visited, contains the contents of the attachment.</p>
<p>Now that I have that (via jQuery<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span><span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>), I build a new <code>pre</code> element with the text content and shove it in place.</p>
<p>Voila.</p>
<p>All I have to do next is make sure that it's called when I either load the page or when I navigate from the Inbox (et al) to a message:</p>
<pre class="javascript"><code>jQuery(window).bind('hashchange', checkForPlaintexts);
jQuery(checkForPlaintexts);</code></pre>
<p>Unfortunately, this has some issues as well. It works if the message has already been viewed once, but not on the first load. Basically, I'm running into timing issues.</p>
<p>My original solution to this was to put in a quick delay and call it a day. Unfortunately, when using satellite internet... even that didn't work. So instead, I built a system that will delay the initial call and then--if it fails--try a few more times with increasing timeouts between then.</p>
<p>Something like this:</p>
<pre class="javascript"><code>var delayedEvent = function(f, timeout, retries) {
    timeout = timeout || 0;
    retries = retries || 0;

    return function(evt) {
        setTimeout(f, timeout, evt, retries, timeout * 2);
    }
};

var checkForPlaintexts = function(evt, retries, delay) {
    retries = retries || 0;
    var foundOne = false;

    jQuery('span[download_url]').each(function(i, el) {
        foundOne = true;

        ...
    });

    if (!foundOne && retries) {
        setTimeout(checkForPlaintexts, delay, evt, retries - 1, delay * 2);
    }
};

jQuery(window).bind('hashchange', delayedEvent(checkForPlaintexts, 125, 3));
jQuery(delayedEvent(checkForPlaintexts, 125, 3));</code></pre>
<p>So far, this has worked perfectly. Sometimes it takes a bit to fetch the ajax call in the background. That's why I put in the <code>Loading...</code> notification to tell the user it was working.</p>
<p>It's been a little while since I last wrote a userscript (pre-Chrome, to give you an idea). I forgot how much fun it can be to mess with websites a bit like that. I may write up a few more.</p>
<p>If you'd like to see the entire source (includes some debug messaging and the userscript header comments), you can do so on GitHub: <a href="https://github.com/jpverkamp/userscripts/blob/master/gmail-plaintext-inline.user.js">gmail-plaintext-inline.user.js</a></p>
<p>If you want to install it directly (and have Greasemonkey/Tampermonkey installed), you can directly from GitHub as well: <a href="https://github.com/jpverkamp/userscripts/raw/master/gmail-plaintext-inline.user.js">install gmail-plaintext-inline.user.js</a>.</p>
<p>As a side note, 'optional' parameters in Javascript are weird...</p>]]></content></entry></feed>