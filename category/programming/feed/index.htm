<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jverkamp.com</title><link href="http://blog.jverkamp.com" /><link rel="self" href="http://blog.jverkamp.com/feed/" /><updated>2015-07-02T00:00:00Z</updated><author><name>JP Verkamp</name></author><id>urn:uuid:bdbdd0f8-f9c2-fda3-168c-52092e959085</id><entry><title>Scraping Kindle Highlights</title><link href="http://blog.jverkamp.com/2015/07/02/scraping-kindle-highlights" /><id>urn:uuid:607a86a7-2b7b-24ef-d68a-fed6db77517e</id><updated>2015-07-02T00:00:00Z</updated><summary type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
]]></summary><content type="html"><![CDATA[<p>As part of an ongoing effort to <a href="http://blog.jverkamp.com/category/programming/by-topic/backups">backup all the things</a>, combined with a rather agressive <a href="http://blog.jverkamp.com/2015/01/01/2015-reading-list">2015 Reading List</a>, I wanted to the ability to back up any sections that I've highlighted on my Kindle. Unfortunately, Amazon doesn't seem to have an API to do that, but why should that stop me?</p>
<p>Using a combination of <a href="http://blog.jverkamp.com/category/programming/by-language/python">Python</a> and the Python libraries <a href="http://docs.python-requests.org/en/latest/">Requests</a> and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a><span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>, it's entirely possible to write a Python script that will log into Amazon, get a list of all of the books on your account, and download the highlights for each.</p>
<p>Let's do it!</p>
<!--more-->
<p>First, we are going to be using a Requests <code>session</code>. This will keep track of any cookies that Amazon decides to send us so that we know that we're logged in.</p>
<pre class="python"><code>session = requests.Session()</code></pre>
<p>After that, the next thing we need to do is to use requests to log into Amazon. Loading up the login page (<code>https://kindle.amazon.com/login</code>), we see that the <code>form</code> target is a <code>POST</code> request to <code>https://www.amazon.com/ap/signin</code>, specifying the fields <code>email</code> and <code>password</code>. Something like this:</p>
<pre class="python"><code>signin_data = {}

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)</code></pre>
<p>I'm reading my Amazon username and password from the environment. In general, that means I can have a simple file like this:</p>
<pre class="bash"><code>export AMAZON_USERNAME="me@example.com"
export AMAZON_PASSWORD="correct horse battery staple"</code></pre>
<p>Then I can source that script before running my program:</p>
<pre class="bash"><code>. ./env.conf && python3 kindle-highlights-backups.py</code></pre>
<p>That should work, but unfortunately it doesn't. It looks like Amazon is sending a small pile of hidden fields. Theoretically, I could look at the page and hard code them, but where's the fun in that? Instead, let's use Requests to grab the login page and BeautifulSoup to parse out all of the fiels we're going to send:</p>
<pre class="python"><code># Log in to Amazon, we have to get the real login page to bypass CSRF
print('Logging in...')
response = session.get('https://kindle.amazon.com/login')
soup = bs4.BeautifulSoup(response.text)

signin_data = {}
signin_form = soup.find('form', {'name': 'signIn'})
for field in signin_form.find_all('input'):
    try:
        signin_data[field['name']] = field['value']
    except:
        pass

signin_data[u'email'] = os.environ['AMAZON_USERNAME']
signin_data[u'password'] = os.environ['AMAZON_PASSWORD']

response = session.post('https://www.amazon.com/ap/signin', data = signin_data)
if response.status_code != 200:
    print('Failed to login: {0} {1}'.format(response.status_code, response.reason))
    sys.exit(0)</code></pre>
<p>... Still doesn't work. I'm getting a page back that says I need to enable cookies, which I most definitely have enabled (that's why I created the <code>session</code>). A bit of Google-fu later, and I find out that Amazon will only allow connections from semi-reasonable <a href="https://en.wikipedia.org/wiki/User_Agents">User Agents</a>. Let's set it to a recent Chrome build on Windows 8.1:</p>
<pre class="python"><code>session = requests.Session()
session.headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.61 Safari/537.36'
}</code></pre>
<p>Ah ha! That works. Finally logged in. Next, we know that we can get a list of your current books by going to <code>https://kindle.amazon.com/your_reading/0/0/0</code>. The last three numbers are:</p>
<ul>
    <li>mode (all, read, reading)</li>
    <li>starting index / page (increments in 25)</li>
    <li>all books (0) versus kindle only (1)</li>
</ul>
<p>So let's write a loop to keep fetching pages of these books, 25 at a time:</p>
<pre class="python"><code># Iterate through pages of books, 25 at a time
# Note: The last three parts of the URL are:
#   - mode (all, read, reading)
#   - starting index / page (increments in 25)
#   - all books (0) versus kindle only (1)
print('Getting books...')
book_page = 0
while True:
    time.sleep(0.5) # Half a second between pages

    response = session.get('https://kindle.amazon.com/your_reading/0/{book_page}/0'.format(book_page = book_page))
    soup = bs4.BeautifulSoup(response.text)
    found_book = False

    ...

    if found_book:
        book_page += 25
    else:
        break</code></pre>
<p>Within that page, there are a series of <code>td</code> elements linking to books, each with the class <code>titleAndAuthor</code>. That's the beauty of BeautifulSoup:</p>
<pre class="python"><code>...

# For each page of books, find all of the individual book links
# The last part of each URL is Amazon's internal ID for that book
for el in soup.findAll('td', {'class': 'titleAndAuthor'}, recursive = True):
    time.sleep(0.1) # 1/10 of a second between books

    found_book = True

    book_id = el.find('a')['href'].split('/')[-1]
    title = el.find('a').text
    sys.stdout.write(title + ' ... ')

    highlights = []
    cursor = 0

    ...</code></pre>
<p>Luckily, the next part is a little easier to deal with. There is actually an API of sorts of Kindle highlights, once you have a user ID. All you have to do is hit <code>https://kindle.amazon.com/kcw/highlights?asin={book_id}</code> (potentially many times, it's <a href="https://en.wikipedia.org/wiki/paginated">paginated</a>):</p>
<pre class="python"><code>...

# Ask the Amazon API for highlights one page of 10 at a time until we have them all
while True:
    response = session.get('https://kindle.amazon.com/kcw/highlights?asin={book_id}&cursor={cursor}&count=10'.format(
        book_id = book_id,
        cursor = cursor,
    ))
    js = response.json()

    found_highlight = False
    for item in js['items']:
        found_highlight = True
        item['highlight'] = html_unescape(item['highlight'])
        highlights.append(item)

    if found_highlight:
        cursor +=1
    else:
        break

...</code></pre>
<p>One caveat is that we don't want to store HTML entities (like <code>&amp;rsquo;</code>), we want the real characters. This is a little annoying, since the library to parse that has moved around in various Python versions:</p>
<pre class="python"><code># Get a function to unescape html entites
try:
    import html
    html_unescape = html.unescape
except:
    try:
        import html.parser
        html_unescape = html.parser.HTMLParser().unescape
    except:
        import HTMLParser
        html_unescape = HTMLParser.HTMLParser().unescape</code></pre>
<p>Yeah...</p>
<p>Now that we have a list of highlights, let's save them to disk. Generate a filename from the book title, and use the <code>json</code> library to write them out. Make sure that we're writing everything as UTF8 so that any more unusual characters (like more interesting quotes) save correctly:</p>
<pre class="python"><code># Use book title as filename, but strip out 'dangerous' characters
print('{count} highlights found'.format(count = len(highlights)))
if highlights:
    filename = re.sub(r'[\/:*?"&lt;&gt;|"\']', '', title).strip() + '.json'
    path = os.path.join('Kindle Highlights', filename)

    with open(path, 'w', encoding = 'utf8') as fout:
        fout.write(json.dumps(highlights, fout, indent = 4, sort_keys = True, ensure_ascii = False))</code></pre>
<p>And there you have it. A simple(ish) way to download your Kindle highlights.</p>
<p>Unfortunately... that's not all she wrote. After running my script for a few days, it started to fail. Why? Because Amazon detected some strange activity on my account and started displaying a captcha. I can detect it easily enough:</p>
<pre class="python"><code>warning = soup.find('div', {'id': 'message_warning'})
if warning:
    print('Failed to login: {0}'.format(warning.text))
    sys.exit(0)</code></pre>
<p>Put that just after the previous 'Failed to login' block and you'll seem some text to the order of 'please enter these characters to continue'. It's actually not that hard to solve a catcha programmatically... but we'll save that for another post.</p>
<p>And that's it for today. So far I have 308 highlights spread over 20 books and it's only growing. It's fun to go back and read them again.</p>]]></content></entry><entry><title>Generating YouTube user RSS feeds</title><link href="http://blog.jverkamp.com/2015/05/11/generating-youtube-user-rss-feeds" /><id>urn:uuid:a097ad77-6800-c1be-c4de-26a9af4348d9</id><updated>2015-05-11T00:00:00Z</updated><summary type="html"><![CDATA[<p>On 4 March 2014, YouTube deprecated the v2.0 API for YouTube (<a href="https://developers.google.com/youtube/2.0/developers_guide_protocol_deprecated">source</a>). One of the unfortunate side effects was that RSS feeds for user uploads were included in what was deprecated.</p>
<p>Previously, you could get an RSS feed with a link of the form: <code>https://gdata.youtube.com/feeds/base/users/{user}/uploads</code> For the longest time, even after the deprecation, those links still worked, but a couple weeks ago, more and more of the video feeds I was subscribed to started redirecting to <a href="https://www.youtube.com/channel/UCMDQxm7cUx3yXkfeHa5zJIQ/videos">YouTube Help account</a>. As thrilling as that channel is, it's not what I'm looking for.</p>
<p>Let's fix it.</p>
]]></summary><content type="html"><![CDATA[<p>On 4 March 2014, YouTube deprecated the v2.0 API for YouTube (<a href="https://developers.google.com/youtube/2.0/developers_guide_protocol_deprecated">source</a>). One of the unfortunate side effects was that RSS feeds for user uploads were included in what was deprecated.</p>
<p>Previously, you could get an RSS feed with a link of the form: <code>https://gdata.youtube.com/feeds/base/users/{user}/uploads</code> For the longest time, even after the deprecation, those links still worked, but a couple weeks ago, more and more of the video feeds I was subscribed to started redirecting to <a href="https://www.youtube.com/channel/UCMDQxm7cUx3yXkfeHa5zJIQ/videos">YouTube Help account</a>. As thrilling as that channel is, it's not what I'm looking for.</p>
<p>Let's fix it.</p>
<!--more-->
<p>First step, we need a YouTube Data API (v3) key. Unfortunately it doesn't look like they provide un-authenticated use of the API as before. That's easy enough though, just <a href="https://developers.google.com/youtube/registering_an_application">go through the steps to register an application</a>. Next, dig through the APIs. It doesn't look like there is a way to directly get a user's videos, but you can get a list of a users 'uploads' playlist, which functions much the same way.</p>
<p>Using Python's <a href="http://docs.python-requests.org/en/latest/">requests</a> library, we just have to hit the correct endpoint:</p>
<pre class="python"><code># Use the channel to get the 'uploads' playlist id
response = requests.get(
    'https://www.googleapis.com/youtube/v3/channels',
    params = {
        'part': 'contentDetails',
        'forUsername': user,
        'key': API_KEY,
    }
)</code></pre>
<p>One example response:</p>
<pre class="json"><code>{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/6wRGj4eVz7tGNiDQjCMuhP6B4vQ\"",
 "items": [{"contentDetails": {"googlePlusUserId": "112244684143881021368",
                               "relatedPlaylists": {"likes": "LL6nSFpj9HTCZ5t-N3Rm3-HA",
                                                    "uploads": "UU6nSFpj9HTCZ5t-N3Rm3-HA"}},
            "etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/yMieoczWtu9QiK_MEdJrC0hqmdU\"",
            "id": "UC6nSFpj9HTCZ5t-N3Rm3-HA",
            "kind": "youtube#channel"}],
 "kind": "youtube#channelListResponse",
 "pageInfo": {"resultsPerPage": 5, "totalResults": 1}}</code></pre>
<p>That's some progress. Specifically, you can get the playlist ID for the user uploads:</p>
<pre class="python"><code>playlistId = response.json()['items'][0]['contentDetails']['relatedPlaylists']['uploads']</code></pre>
<p>From there, we can query the API again in order to get the most recent 20 items from that specific playlist:</p>
<pre class="python"><code># Get the most recent 20 videos on the 'uploads' playlist
response = requests.get(
    'https://www.googleapis.com/youtube/v3/playlistItems',
    params = {
        'part': 'snippet',
        'maxResults': 20,
        'playlistId': playlistId,
        'key': API_KEY
    }
)</code></pre>
<p>Some snippets from that output (it's rather large):</p>
<pre class="json"><code>{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/PH2ohKtd9aLBba_d7dVtVUfFle0\"",
 "items": [{"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/-LUTubHPIceTTTPMrBW-Qs9KOZQ\"",
            "id": "UUKzDohq4XHVIEl9O19Nd8rKuqCo1VravR",
            "kind": "youtube#playlistItem",
            "snippet": {"channelId": "UC6nSFpj9HTCZ5t-N3Rm3-HA",
                        "channelTitle": "Vsauce",
                        "description": "Vsauce is nominated for a Webby "
                                       "in Science & Education! You can "
                                       ...,
                        "playlistId": "UU6nSFpj9HTCZ5t-N3Rm3-HA",
                        "position": 0,
                        "publishedAt": "2015-04-13T19:26:03.000Z",
                        "resourceId": {"kind": "youtube#video",
                                       "videoId": "f8WsO__XcI0"},
                        "thumbnails": {"default": {"height": 90,
                                                   "url": "https://i.ytimg.com/vi/f8WsO__XcI0/default.jpg",
                                                   "width": 120},
                                       ...},
                       "title": "When Will We Run Out Of Names?"}},
           {"etag": "\"tbWC5XrSXxe1WOAx6MK9z4hHSU8/kCpPYobMQgr7w9gfxaR-_cfkJkc\"",
           ...]}</code></pre>
<p>In that snippets blob, we have everything we need. Specifically, the <code>title</code>, <code>thumbnails</code>, and <code>link</code> (by way of <code>resourceID.videoId</code>). Specifically, we can start to construct an RSS feed using the <a href="https://pypi.python.org/pypi/feedgen/">feedgen</a> library<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>:</p>
<pre class="python"><code># Generate a list of results that can be used as feed items
feed = feedgen.feed.FeedGenerator()
feed.title(user + ' (YRSS)')
feed.author({'name': user + ' (YRSS)'})
feed.id('YRSS:' + user)

for item in response.json()['items']:
    title = item['snippet']['title']
    video_id = item['snippet']['resourceId']['videoId']
    published = item['snippet']['publishedAt']
    thumbnail = item['snippet']['thumbnails']['high']['url']
    video_url = 'https://www.youtube.com/watch?v=' + video_id

    item = feed.add_entry()
    item.title(title)
    item.link(href = video_url)
    item.published(dateutil.parser.parse(published))
    item.updated(dateutil.parser.parse(published))
    item.id(video_id)
    item.content('''
&lt;a href="{url}"&gt;&lt;img src="{img}" /&gt;&lt;/a&gt;
&lt;a href="{url}"&gt;{title}&lt;/a&gt;
'''.format(
        url = video_url,
        img = thumbnail,
        title = title,
    ))</code></pre>
<p>And generate the feed:</p>
<pre class="python"><code>feed.atom_str()</code></pre>
<p>I love how (relatively) elegant that was. You don't have to worry about or even know anything about how the underlying XML will be structured.</p>
<p>Since eventually I want this to be a web service, I used Flask to generate a simple API:</p>
<pre class="python"><code>app = flask.Flask(__name__)

@app.route('/&lt;user&gt;.xml')
@app.route('/&lt;user&gt;/atom.xml')
def generatefeed(user):
    ...

    return feed.atom_str()</code></pre>
<p>That way, if you go to <code>http://myserver.com/{user}.xml</code>, you would get an RSS feed for that user's most recent 20 videos. There are a few other considerations to keep in mind (For example, I have a cache that only re-queries the YouTube API once per hour and otherwise re-serves the same feed. And better error handling.)</p>
<p>If you'd like to see the full source in all it's glory, it's available on GitHub: <a href="https://github.com/jpverkamp/yrss">jpverkamp/yrss</a>. You will have to supply an <code>API_KEY</code> as an environment variable to run it, but that should be relatively straight forward.</p>]]></content></entry><entry><title>Tupper's self-referential formula</title><link href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula" /><id>urn:uuid:bf58a9a0-f27e-d83e-acd1-97ca1db67a9b</id><updated>2015-05-07T00:00:00Z</updated><summary type="html"><![CDATA[<p>Quick post today. Let's implement <a href="https://en.wikipedia.org/wiki/Tupper's_self-referential formula">Tupper's self-referential formula</a> in Racket!</p>
<div>$$ \frac{1}{2} < \left \lfloor mod \left ( \left \lfloor \frac{y}{17} 2^{-17 \lfloor x \rfloor - mod(\lfloor y \rfloor, 2)} \right \rfloor, 2 \right ) \right \rfloor $$</div>
<pre class="racket"><code> (tupper 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719) </code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" /></a></p>
<p>That's the result of graphing the above function at a point rather far away from the origin. Specifically, where <code>y</code> is around that crazy big number. Look familiar?</p>
]]></summary><content type="html"><![CDATA[<p>Quick post today. Let's implement <a href="https://en.wikipedia.org/wiki/Tupper's_self-referential formula">Tupper's self-referential formula</a> in Racket!</p>
<div>$$ \frac{1}{2} < \left \lfloor mod \left ( \left \lfloor \frac{y}{17} 2^{-17 \lfloor x \rfloor - mod(\lfloor y \rfloor, 2)} \right \rfloor, 2 \right ) \right \rfloor $$</div>
<pre class="racket"><code> (tupper 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719) </code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.png" /></a></p>
<p>That's the result of graphing the above function at a point rather far away from the origin. Specifically, where <code>y</code> is around that crazy big number. Look familiar?</p>
<!--more-->
<p>The basic idea behind the formula is that it can encode any arbitrary bitmap (so long as it's black and white and only 106x17 pixels). Essentially under the hood everything is in base 17. First, let's fairly directly translate the original formula into Racket:</p>
<pre class="racket"><code>; Tupper's "self-referential" formula
; Encodes a bitmap as an integer
(define (tupper k)
  (flomap-&gt;bitmap
   (build-flomap*
    1 106 17
    (λ (x y)
      (set! y (+ y k))
      (set! x (- 105 x))
      (cond
        [(&lt; 1/2 (floor (mod (* (floor (/ y 17)) (expt 2 (- (* -17 (floor x)) (mod (floor y) 17)))) 2)))
         (vector 0)]
        [else
         (vector 1)])))))</code></pre>
<p>One amusing caveat that we have to deal with here is that <code>modulus</code> doesn't work on numbers this large. So instead, we're going to have to do it manually:</p>
<pre class="racket"><code>; Modulus that will work with really large numbers
(define (mod a b)
  (define q (floor (/ a b)))
  (define r (- a (* b q)))
  r)</code></pre>
<p>Whee!</p>
<p>Another neat trick I was playing with is "rendering" the image by adding one digit at a time (in base 10, so it's mostly noise):</p>
<pre class="racket"><code>(define (render-to target)
  (define str-target (number-&gt;string target))
  (define str-buffer (make-string (string-length str-target) #\0))

  (for/list ([i (in-range (sub1 (string-length str-target)) -1)])
    (string-set! str-buffer i (string-ref str-target i))
    (tupper (string-&gt;number str-buffer))))

&gt; (write-animated-gif
   (render-to 960939379918958884971672962127852754715004339660129306651505519271702802395266424689642842174350718121267153782770623355993237280874144307891325963941337723487857735749823926629715517173716995165232890538221612403238855866184013235585136048828693337902491454229288667081096184496091705183454067827731551705405381627380967602565625016981482083418783163849115590225610003652351370343874461848378737238198224849863465033159410054974700593138339226497249461751545728366702369745461014655997933798537483143786841806593422227898388722980000748404719)
   5
   "tupper.gif"
   #:last-frame-delay 50)</code></pre>
<p><a href="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.gif" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/05/07/tuppers-self-referential-formula/tupper.gif" /></a></p>
<p>If you look carefully, you'll occasionally see flashes of the final image being rendered. This happens whenever the base-10 numbers that we're adding line up with the base-17 encoding.</p>
<p>I'm not sure it's particularly useful for anything, but I found it amusing.</p>
<p>Code: <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/tupper.rkt">tupper.rkt</a></p>]]></content></entry><entry><title>It's all Greek to me</title><link href="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me" /><id>urn:uuid:b361ed4c-c170-609c-a31d-3fbc5642e648</id><updated>2015-04-17T00:00:00Z</updated><summary type="html"><![CDATA[<p>A few days ago an interesting article came across my RSS feeds: <a href="http://flowingdata.com/2015/04/14/its-all-greek-or-chinese-or-spanish-or-to-me/">It’s All Greek (or Chinese or Spanish or…) to Me</a>. Basically, in English, when you're confused, you'll often say 'It's all Greek to me'. It turns out that man (if not all) languages around the world have a similar saying, but the target varies. Luckily, Wikipedia has a lovely page about it: <a href="https://en.wikipedia.org/wiki/Greek_to me">Greek to me</a>.</p>
]]></summary><content type="html"><![CDATA[<p>A few days ago an interesting article came across my RSS feeds: <a href="http://flowingdata.com/2015/04/14/its-all-greek-or-chinese-or-spanish-or-to-me/">It’s All Greek (or Chinese or Spanish or…) to Me</a>. Basically, in English, when you're confused, you'll often say 'It's all Greek to me'. It turns out that man (if not all) languages around the world have a similar saying, but the target varies. Luckily, Wikipedia has a lovely page about it: <a href="https://en.wikipedia.org/wiki/Greek_to me">Greek to me</a>.</p>
<!--more-->
<p>When I posted the link to Facebook, I got a quick question: are there any cycles? While one could just scan through the document, it would be a lot more interesting (at least to me!) if you could do it automatically. Let's toss together a quick script to do it.</p>
<p>First thing we need: a way to get the content of the Wikipedia page. Python is great for this, with <a href="http://docs.python-requests.org/en/latest/">requests</a> to grab the page and <a href="http://www.crummy.com/software/BeautifulSoup/">BeautifulSoup</a> to process it:</p>
<pre class="python"><code>content = requests.get('https://en.wikipedia.org/wiki/Greek_to_me').text
soup = bs4.BeautifulSoup(content)

table = soup.find('table', {'class': 'wikitable sortable'})

pairs = collections.defaultdict(set)

for row in table.findAll('tr'):
    cols = row.findAll('td')
    if not cols:
        continue

    if len(cols) == 5:
        srcs = [src.strip() for src in cols[0].text.split(',')]

    dsts = [dst.strip() for dst in cols[-1].text.split(',')]
    for i, dst in enumerate(dsts):
        dsts[i] = re.sub(r'[\[(].*?[\])]', '', dst)

    for src in srcs:
        if ' ' in src: continue

        for dst in dsts:
            if ' ' in dst: continue

            pairs[src].add(dst)</code></pre>
<p>Basically, we download the page. Then we go through each of the rows (<code>tr</code>). Skip any rows without column elements (<code>td</code>) as that's probably the header, otherwise, pull them out. The first column (index <code>0</code>) is the language with the idiom (English in the example) while the last column (index <code>-1</code>) is the target (Greek). There's one caveat though, that sometimes the table uses a <code>rowspan</code> when one source can have multiple targets but is only listed once. We check that by only changing the <code>srcs</code> when there are 5 columns.</p>
<p>Parse through all of that and what do you have?</p>
<pre class="python"><code>&gt;&gt;&gt; import pprint
&gt;&gt;&gt; pprint.pprint(dict(pairs))
{u'': set([]),
 u'Afrikaans': set([u'Greek']),
 u'Albanian': set([u'Chinese']),
 u'Arabic': set([u'Chinese', u'Garshuni']),
 ...
 u'Vietnamese': set([u'Cambodian']),
 u'Volap\xfck': set([]),
 u'Yiddish': set([u'Aramaic'])}</code></pre>
<p>Exactly what I was looking for. Okay, next step. Find any cycles in the graph. This is straight forward enough by performing a <a href="https://en.wikipedia.org/wiki/depth_first search">depth first search</a>:</p>
<pre class="python"><code>def cycle(node, seen):

    for neighbor in pairs[node]:
        new_seen = seen + [neighbor]

        if neighbor in seen:
            yield new_seen[new_seen.index(neighbor):]
        else:
            for recur in cycle(neighbor, new_seen):
                yield recur</code></pre>
<p>The basic idea is to make a generator that returns each cycle as it finds it. It does so by search down each branch, maintaining a list of all nodes it has <code>seen</code>. If it sees the same node twice, that's a cycle. Otherwise, try all of the neighbors. We avoid infinite loops since there's a guaranteed base case to the recursion: <code>seen</code> is always one bigger on each step and it's maximum size is the number of nodes in the graph.</p>
<p>So how does it work?</p>
<pre class="python"><code>&gt;&gt;&gt; for result in cycle('English', ['English']):
...     print result
...
['English', u'Greek', u'Chinese', u'English']
['English', u'Greek', u'Turkish', u'Arabic', u'Chinese', u'English']
['English', u'Greek', u'Turkish', u'French', u'Chinese', u'English']
['English', u'Greek', u'Turkish', u'French', u'Hebrew', u'Chinese', u'English']
['English', u'Dutch', u'Chinese', u'English']</code></pre>
<p>Neat! We've already found 5 cycles that involve English alone. But how many cycles are there all together? For that, we need a way to determine if a cycle is actually unique. If you have the cycles <code>A -> B -> C -> A</code>, that's the same as <code>B -> C -> A -> B</code>. You can do this by putting the cycles in <a href="https://en.wikipedia.org/wiki/lexical_order">lexical order</a> (so that the 'smallest' element in the cycle is first).</p>
<pre class="python"><code>def reorder(cycle):
    if cycle[0] == cycle[-1]:
        cycle = cycle[1:]

    smallest = min(cycle)
    for el in list(cycle):
        if el == smallest:
            break
        else:
            cycle = cycle[1:] + [cycle[0]]

    return cycle</code></pre>
<p>It also is smart enough that if we pass it a list with the first and last node the same (as we will), it trims that off automatically.</p>
<pre class="python"><code>&gt;&gt;&gt; reorder(['A', 'B', 'C', 'A'])
['A', 'B', 'C']
&gt;&gt;&gt; reorder(['B', 'C', 'A', 'B'])
['A', 'B', 'C']</code></pre>
<p>Bam. So we use that and a <code>set</code> to keep track of what we've seen:</p>
<pre class="python"><code>&gt;&gt;&gt; seen = set()
&gt;&gt;&gt; for src in pairs.keys():
...     for result in cycle(src, [src]):
...         result = reorder(result)
...         if not str(result) in seen:
...             print(result)
...             seen.add(str(result))
...
[u'Chinese', u'English', u'Greek']
[u'Chinese', u'English', u'Dutch']
[u'Arabic', u'Chinese', u'English', u'Greek', u'Turkish']
[u'Chinese', u'English', u'Greek', u'Turkish', u'French']
[u'Chinese', u'English', u'Greek', u'Turkish', u'French', u'Hebrew']</code></pre>
<p>Huh. So they all go through English. I didn't actually expect that. :) Still, it's cool to be able to unify them like that.</p>
<p>Okay, one last trick. Let's visualize them. Luckily, there's a nice Python interface for <a href="https://pypi.python.org/pypi/graphviz">graphviz</a> that we can use:</p>
<pre class="python"><code># --- Render a nice graph ---

g = graphviz.Digraph()
for src in pairs.keys():
    for dst in pairs[src]:
        g.edge(src, dst)

g.graph_attr['overlap'] = 'false'
g.graph_attr['splines'] = 'true'

g.format = 'png'
g.engine = 'neato'

g.render('greek-to-me')</code></pre>
<p><a href="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me.png" /></a></p>
<p>Awesome.</p>
<p>It's not the easiest thing in the world to read, but if you look carefully you can pick out a few interesting things. Let's tweak it a bit to color nodes if and only if they have both an inward edge and an outward one:</p>
<pre class="python"><code>for src in pairs.keys():
    # Does this node lead to another
    has_out = pairs[src]

    # Does any node lead to this one
    has_in = False
    for dst in pairs.keys():
        if src in pairs[dst]:
            has_in = True
            break

    # If both, color it
    if has_out and has_in:
        g.node(src, color = 'blue')
</code></pre>
<p><a href="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me-color-nodes.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me-color-nodes.png" /></a></p>
<p>That's a little better, all of the nodes in any cycle are in there. Let's go ahead and show all of the edges in any cycle:</p>
<pre class="python"><code># Get all edges that are part of a cycle
cycle_edges = set()
for cycle in cycles:
    for src, dst in zip(cycle, cycle[1:]):
        cycle_edges.add((src, dst))
    cycle_edges.add((cycle[-1], cycle[0]))

for src in pairs.keys():
    for dst in pairs[src]:
        if (src, dst) in cycle_edges:
            g.edge(src, dst, color = 'blue')
        else:
            g.edge(src, dst)</code></pre>
<p><a href="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me-color.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/17/its-all-greek-to-me/greek-to-me-color.png" /></a></p>
<p>So they're all in that pocket. If I had a few more minutes, I could show all of the cycles as different colors, but that gets complicated in that many re-use the same paths. So it goes.</p>
<p>If you'd like to see / run the code, you can grab it from GitHub: <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/greek-to-me.py">greek-to-me.py</a></p>]]></content></entry><entry><title>A Quick Look at RC4</title><link href="http://blog.jverkamp.com/2015/04/14/a-quick-look-at-rc4" /><id>urn:uuid:7faa7241-8deb-6230-5db2-37d89e5af00c</id><updated>2015-04-14T00:00:00Z</updated><summary type="html"><![CDATA[<p>In cryptography work, <a href="https://en.wikipedia.org/wiki/RC4">RC4</a> (Rivest Cipher 4) is well known as both one of the easiest to implement and fastest to run <a href="https://en.wikipedia.org/wiki/symmetric_encryption">symmetric encryption</a> algorithms. Unfortunately, over time there have been a number of attacks on RC4, both in poorly written protocols (such as in the case of <a href="https://en.wikipedia.org/wiki/WEP">WEP</a>) or statistical attacks against the protocol itself.</p>
<p>Still, for how well it formed, it's an amazingly simple algorithm, so I decided to try my hand at implementing it.</p>
]]></summary><content type="html"><![CDATA[<p>In cryptography work, <a href="https://en.wikipedia.org/wiki/RC4">RC4</a> (Rivest Cipher 4) is well known as both one of the easiest to implement and fastest to run <a href="https://en.wikipedia.org/wiki/symmetric_encryption">symmetric encryption</a> algorithms. Unfortunately, over time there have been a number of attacks on RC4, both in poorly written protocols (such as in the case of <a href="https://en.wikipedia.org/wiki/WEP">WEP</a>) or statistical attacks against the protocol itself.</p>
<p>Still, for how well it formed, it's an amazingly simple algorithm, so I decided to try my hand at implementing it.</p>
<!--more-->
<p>Basically, RC4 is what is known as a '<a href="https://en.wikipedia.org/wiki/stream_cipher">stream cipher</a>', implying that each byte in the input message is encrypted individually (generally taking into account feedback from previous bytes). This runs counter to the perhaps more well known <a href="https://en.wikipedia.org/wiki/block_ciphers">block ciphers</a> such as DES and AES, where bytes are instead encrypted together (although feedback between blocks is still of course possible).</p>
<p>The first step of the algorithm is to take your encryption key (a password or the like) and convert it into a sequence of bytes at least as long as your input. For RC4, this is done in two pieces. First, prepare the index:</p>
<pre class="python"><code>def rc4(key, msg):
    S = list(range(256))

    j = 0
    for i in range(256):
        j = (j + S[i] + key[i % len(key)]) % 256
        S[i], S[j] = S[j], S[i]

    ...</code></pre>
<p>Or in Racket:</p>
<pre class="racket"><code>(define (rc4 key msg)
  (define (mod256 n) (modulo n 256))

  (define permutation (make-bytes 256))
  (for ([i (in-range 256)])
    (bytes-set! permutation i i))

  (define (S i)
    (bytes-ref permutation i))

  (define (swap! i j)
    (let ([pi (bytes-ref permutation i)]
          [pj (bytes-ref permutation j)])
      (bytes-set! permutation i pj)
      (bytes-set! permutation j pi)))

  ; Key-scheduling algorithm
  (for/fold ([j 0]) ([i (in-range 256)])
    (let ([j (mod256 (+ j
                        (S i)
                        (bytes-ref key (modulo i (bytes-length key)))))])
      (swap! i j)
      j))

  ...)</code></pre>
<p>I made the Racket version a little more verbose with helper functions, since I know I'll both be indexing the permutation and swapping values again in the next step. That's one of the reasons that I'll sometimes go for Python over Racket in on off scripts.</p>
<p>Still, relatively simple in both cases.</p>
<p>The next step is to turn that into a stream, essentially creating an infinite number generator. Luckily, both Python and Racket have generators, which are perfectly suited for this sort of thing (assuming in both cases that <code>S</code> / <code>permutation</code> are in scope from above):</p>
<pre class="python"><code>def rc4(key, msg):
    ...

    def prga():
        i = j = 0
        while True:
            i = (i + 1) % 256
            j = (j + S[i]) % 256
            S[i], S[j] = S[j], S[i]
            yield S[(S[i] + S[j]) % 256]

    return prga # DEBUG</code></pre>
<pre class="racket"><code>(define (rc4 key msg)
  ...

  ; Pseudo-random generation algorithm
  (define prga
    (generator ()
      (let loop ([i 1] [j (S 1)])
        (swap! i j)
        (yield (S (mod256 (+ (S i) (S j)))))
        (loop (mod256 (+ i 1)) (mod256 (+ j (S (+ i 1))))))))

  prng) ; DEBUG</code></pre>
<p>Now that we have a stream, we can generate a few bytes and take a look if we wanted:</p>
<pre class="python"><code>&gt;&gt;&gt; import binascii, itertools
&gt;&gt;&gt; prga = rc4(b'Secret', b'Attack at dawn')
&gt;&gt;&gt; print(binascii.hexlify(bytes(itertools.islice(prga(), 10))))
b'04d46b053ca87b594172'</code></pre>
<pre class="racket"><code>(define (bytes-&gt;hex b*)
  (apply ~a (for/list ([b (in-bytes b*)])
        (~a (number-&gt;string (quotient b 16) 16)
            (number-&gt;string (modulo b 16) 16)))))

&gt; (define prga (rc4 "Secret" "Attack at dawn"))
&gt; (bytes-&gt;hex (apply bytes (for/list ([i (in-range 10)] [b (in-producer prga)]) b)))
"04d46b053ca87b594172"</code></pre>
<p>Both of them the same? Good sign. Both matching the example on the Wikipedia page? Even better!</p>
<p>So, we have an infinite stream of bytes. What next?</p>
<p>Well, this is actually the crazy part: You just <a href="https://en.wikipedia.org/wiki/xor">xor</a> them.</p>
<pre class="python"><code>def rc4(key, msg):
    ...

    return bytes(msgbyte ^ keybyte for msgbyte, keybyte in zip(msg, prga()))</code></pre>
<pre class="racket"><code>(define (rc4 key msg)
  ...

  ; Encryption
  (apply bytes
    (for/list ([input-byte (in-bytes msg)] [key-byte (in-producer prga)])
      (bitwise-xor input-byte key-byte))))</code></pre>
<p>And now we can encrypt!</p>
<pre class="python"><code>&gt;&gt;&gt; print(binascii.hexlify(rc4(b'Secret', b'Attack at dawn')))
b'45a01f645fc35b383552544b9bf5'</code></pre>
<pre class="racket"><code>&gt; (bytes-&gt;hex (rc4 "Secret" "Attack at dawn"))
"45a01f645fc35b383552544b9bf5"</code></pre>
<p>And decrypt!</p>
<pre class="python"><code>&gt;&gt;&gt; rc4(b'Secret', rc4(b'Secret', b'Attack at dawn'))
b'Attack at dawn'</code></pre>
<pre class="racket"><code>&gt; (rc4 "Secret" (rc4 "Secret" "Attack at dawn"))
#"Attack at dawn"</code></pre>
<p>Very cool. I'm really starting to see the appeal of RC4. A couple dozen lines of Python/Racket and you're encrypting. Bam. As mentioned, it's not really an algorithm you should use in encryption any more (the author has released a slightly more complicated algorithm called Spritz that works very similarly).</p>
<p>And that's it. If you'd like to see the entire code in one place (along with some fiddling in both cases to deal with Unicode keys/messages as well as pure bytes), it's on GitHub: <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/rc4.py">rc4.py</a>, <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/rc4.rkt">rc4.rkt</a>.</p>
<p><code>7b82 c5cf 12c4 e168 8a4a 5cbe 9300</code></p>
<p><img alt="smile" class="emoji" src="/emoji/smile.svg" /></p>]]></content></entry><entry><title>Generating perfect portmanteaus</title><link href="http://blog.jverkamp.com/2015/04/07/generating-perfect-portmanteaus" /><id>urn:uuid:0b6a158d-e441-c880-5fcf-4d4a1394e61d</id><updated>2015-04-07T00:00:00Z</updated><summary type="html"><![CDATA[<p>A quick programming post, since it's been a while, inspired by this video:</p>
<p><iframe width="560" height="315" src="//www.youtube.com/embed/QVn2PZGZxaI" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>I'm not going to go quite as far as that, but I thought it would be interesting to write up some quick code to generate portmanteaus<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>.</p>
]]></summary><content type="html"><![CDATA[<p>A quick programming post, since it's been a while, inspired by this video:</p>
<p><iframe width="560" height="315" src="//www.youtube.com/embed/QVn2PZGZxaI" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>I'm not going to go quite as far as that, but I thought it would be interesting to write up some quick code to generate portmanteaus<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>.</p>
<!--more-->
<p>Basically<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span>, a portmanteau is a combination of two words, smooshing them together<span class="footnote"><sup><a href="#footnote-3">[3]</a></sup></span> and dropping some letters from each. In this case, what I'm specifically interested in is 'perfect' portmanteaus (I'm not sure if there is a better term for it), where the suffix of one word exactly matches the prefix of the other.</p>
<p>As an example, consider the words <code>hamster</code> and <code>termine</code>. The last three letters of the former, perfectly matches the first three of the latter, so let's overlap them. <code>hamstermite</code>. Bam.</p>
<p>So how do we do it?</p>
<pre class="racket"><code>(define current-minimum-overlap (make-parameter 3))

(define (portmanteau left right)
  (define maximum-overlap (- (min (string-length left) (string-length right)) 1))

  (for*/first ([overlap (in-range maximum-overlap (- (current-minimum-overlap) 1) -1)]
               #:when (equal? (substring left (- (string-length left) overlap))
                              (substring right 0 overlap)))
    (list left
          right
          (string-append
           (substring left 0 (- (string-length left) overlap))
           right))))</code></pre>
<p>Should be straight forward enough. Basically, we start with the longest possible overlap (1 less than the length of the shorter word, since we don't want to completely subsume a word), counting down until we reach some minimum overlap. For each possible sequence, we compare the prefix and suffix of the two words, only proceeding into the body of the loop when they match. That's the beauty of <code><a href="http://docs.racket-lang.org/search/index.html?q=for*/first">for*/first</a></code>, it will loop until it gets a valid value, returning when it does.</p>
<p>And that's really it. Try it out with the example from earlier:</p>
<pre class="racket"><code>&gt; (portmanteau "hamster" "termite")
'("hamster" "termite" "hamstermite")</code></pre>
<p>Since that was so quick, let's put some simple wrapper code around it in order to find all portmanteaus from a given word list. First, do the heavy lifting of finding portmanteaus:</p>
<pre class="racket"><code>(define (portmanteaus)
  (define words
    (for*/list ([raw-line (in-lines)]
                [line (in-value (string-trim (string-downcase raw-line)))]
                #:when (not (equal? "" line)))
      line))

  (for*/list ([left (in-list words)]
              [right (in-list words)]
              #:when (not (eq? left right))
              [portmanteau (in-value (portmanteau left right))]
              #:when portmanteau)
    portmanteau))</code></pre>
<p><code><a href="http://docs.racket-lang.org/search/index.html?q=in-value">in-value</a></code> is useful in <code><a href="http://docs.racket-lang.org/search/index.html?q=for*">for*</a></code> since it lets you bind a single value for future <code>#:when</code> blocks without having to recalculate anything.</p>
<p>After that, a wrapper to process some command line parameters and render output in a few different ways:</p>
<pre class="racket"><code>(define paths
  (command-line
   #:program "portmanteau"
   #:once-each
   [("--minimum-overlap")
    overlap
    "Specify the minimum necessary overlap (default = 3)"
    (cond
      [(string-&gt;number overlap) =&gt; current-minimum-overlap]
      [else (error '--minimum-overlap "must specify a number")])]
   #:once-any
   [("--verbose")
    "Print in verbose mode (default = false)"
    (verbose-mode #t)]
   [("--graph")
    "Print out a dotfile"
    (graph-mode #t)]
   #:args paths

   paths))

(when (null? paths)
  (set! paths '("-")))

(for ([path (in-list paths)])
  (define results
    (cond
      [(equal? path "-")
       (portmanteaus)]
      [else
       (with-input-from-file path portmanteaus)]))

  (define g (unweighted-graph/directed '()))

  (for ([result (in-list results)])
    (match-define (list left right portmanteau) result)
    (cond
      [(verbose-mode)
       (printf "~a + ~a = ~a\n" left right portmanteau)]
      [(graph-mode)
       (add-edge! g (~a "\"" left "\"") (~a "\"" right "\""))]
      [else
       (displayln portmanteau)]))

  (when (graph-mode)
    (displayln (graphviz g))))</code></pre>
<p>Now you can do some interesting things:</p>
<pre class="bash"><code>$ racket portmanteau.rkt animals.txt

brown recluse spider monkey
gila monstermite
grasshopperegrine falcon
hamstermite
leechidna
ottermite</code></pre>
<p>Just in case you cannot figure out what animals actually went into that list:</p>
<pre class="bash"><code>$ racket portmanteau.rkt --verbose animals.txt

brown recluse spider + spider monkey = brown recluse spider monkey
gila monster + termite = gila monstermite
grasshopper + peregrine falcon = grasshopperegrine falcon
hamster + termite = hamstermite
leech + echidna = leechidna
otter + termite = ottermite</code></pre>
<p>Or if you want to be a little more general, matching with only 2 characters rather than the default 3:</p>
<pre class="bash"><code>$ racket portmanteau.rkt --minimum-overlap 2 --verbose animals.txt

armadillo + loon = armadilloon
armadillo + lorikeet = armadillorikeet
armadillo + louse = armadillouse
black mamba + badger = black mambadger
brown bear + armadillo = brown bearmadillo
brown recluse spider + spider monkey = brown recluse spider monkey
chinchilaa + aardvark = chinchilaardvark
copperhead snake + kestrel = copperhead snakestrel
coyote + termite = coyotermite
crow + owl = crowl
eagle + leech = eagleech
eagle + leopard seal = eagleopard seal
echidna + narwhal = echidnarwhal
gecko + koala = geckoala
gila monster + termite = gila monstermite
grasshopper + peregrine falcon = grasshopperegrine falcon
hamster + termite = hamstermite
hyena + narwhal = hyenarwhal
jackal + albatross = jackalbatross
king cobra + rattlesnake = king cobrattlesnake
king cobra + raven = king cobraven
kingsnake + kestrel = kingsnakestrel
kiwi + wild boar = kiwild boar
leech + chinchilaa = leechinchilaa
leech + echidna = leechidna
leopard seal + albatross = leopard sealbatross
narwhal + albatross = narwhalbatross
ostrich + chinchilaa = ostrichinchilaa
otter + termite = ottermite
polar bear + armadillo = polar bearmadillo
rattlesnake + kestrel = rattlesnakestrel
sloth bear + armadillo = sloth bearmadillo
snapping turtle + leech = snapping turtleech
snapping turtle + leopard seal = snapping turtleopard seal
sparrow + owl = sparrowl
sperm whale + leech = sperm whaleech
sperm whale + leopard seal = sperm whaleopard seal
sponge + gecko = spongecko
swan + anaconda = swanaconda
wild boar + armadillo = wild boarmadillo</code></pre>
<p>Heh. Narwhalbatross. Wild boarmadillo. <img alt="smile" class="emoji" src="/emoji/smile.svg" /></p>
<p>And as a final bonus, using the <a href="https://github.com/stchang/graph/tree/master">graph</a> library I've used (and contributed to) before, we can render the structure of the thing):</p>
<pre class="bash"><code>$ racket portmanteau.rkt --graph --minimum-overlap 2 animals.txt \
    | sed "s/edge \[dir=none\];//g" \
    | fdp -Tpng &gt; animals.png \
    && open animals.png</code></pre>
<p><a href="http://blog.jverkamp.com/2015/04/07/generating-perfect-portmanteaus/animals.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/07/generating-perfect-portmanteaus/animals.png" /></a></p>
<p>Fun. :)</p>
<p>Think of the arrows as going from the stuck on word to where it's sticking rather than in the order the words would be written. It's easy enough to change though if you'd like, just swap the arguments in the <code>add-edge!</code> call above.</p>
<p>And... that's it. Not much more to do with this one, unless I want to duplicate the above video and portmanteau all the things! We'll see.</p>
<p>As with all my code, you can see the entire thing on GitHub: <a href="https://github.com/jpverkamp/small-projects/blob/master/blog/portmanteau.rkt">portmanteau.rkt</a></p>]]></content></entry><entry><title>Performance problems with Flask and Docker</title><link href="http://blog.jverkamp.com/2015/04/03/performance-problems-with-flask-and-docker" /><id>urn:uuid:8d7d8e5b-effe-34a6-b190-d0068d5879a0</id><updated>2015-04-03T00:00:00Z</updated><summary type="html"><![CDATA[<p>I had an interesting problem recently on a project I was working on. It's a simple <a href="http://flask.pocoo.org/">Flask</a>-based webapp, designed to be deployed to <a href="https://aws.amazon.com/">AWS</a> using <a href="https://www.docker.com/">Docker</a>. The application worked just fine when I was running it locally, but as soon as I pushed the docker container...</p>
<p>Latency spikes. Bad enough that the application was failing AWS's healthy host checks, cycling in and out of existence<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>:</p>
<p><a href="http://blog.jverkamp.com/2015/04/03/performance-problems-with-flask-and-docker/health-check.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/03/performance-problems-with-flask-and-docker/health-check.png" /></a></p>
]]></summary><content type="html"><![CDATA[<p>I had an interesting problem recently on a project I was working on. It's a simple <a href="http://flask.pocoo.org/">Flask</a>-based webapp, designed to be deployed to <a href="https://aws.amazon.com/">AWS</a> using <a href="https://www.docker.com/">Docker</a>. The application worked just fine when I was running it locally, but as soon as I pushed the docker container...</p>
<p>Latency spikes. Bad enough that the application was failing AWS's healthy host checks, cycling in and out of existence<span class="footnote"><sup><a href="#footnote-1">[1]</a></sup></span>:</p>
<p><a href="http://blog.jverkamp.com/2015/04/03/performance-problems-with-flask-and-docker/health-check.png" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/04/03/performance-problems-with-flask-and-docker/health-check.png" /></a></p>
<!--more-->
<p>At that time, the only traffic to the container was the health checks, every 30 seconds, as regular as clockwork. So it wasn't load that was making them fail. And it was exactly the same code each time<span class="footnote"><sup><a href="#footnote-2">[2]</a></sup></span><span class="footnote"><sup><a href="#footnote-3">[3]</a></sup></span>:</p>
<pre class="python"><code>@app.route('/', methods = ['GET'])
def healthcheck():
    return "I'm a teapot"</code></pre>
<p>So not that either. So what in the world was going on?</p>
<p>Google to the rescue! <code><a href="https://www.google.com/search?q=flask application periodically slow">flask application periodically slow</a></code></p>
<p>The very first link is a response on StackOverflow:</p>
<blockquote>
    On operating systems that support ipv6 and have it configured such as modern Linux systems, OS X 10.4 or higher as well as Windows Vista some browsers can be painfully slow if accessing your local server. The reason for this is that sometimes “localhost” is configured to be available on both ipv4 and ipv6 socktes and some browsers will try to access ipv6 first and then ivp4. -- <a href="http://stackoverflow.com/questions/11150343/slow-requests-on-local-flask-server">Slow Requests on Local Flask Server</a>
</blockquote>
<p>Huh. Get a shell into my docker container, and what do you know:</p>
<pre class="bash"><code>$ cat /etc/hosts
172.17.1.112	27392a3e0fa5
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters</code></pre>
<p>Yup. <code>localhost</code> routes to both IPv4's <code>127.0.0.1</code> and IPv6's <code>::1</code>. Comment out the <code>::1</code> line and give it a shot... Yup. That did it. Waited ten minutes and the hosts weren't marked unhealthy once. All I should need to do is add it to the <code>Dockerfile</code> and we should be golden, yes?</p>
<pre class="text"><code>$ vi Dockerfile
...
RUN sed -i "s/::1.*//g"
...

$ docker build .
...
Step 9 : RUN sed -i "s/::1.*//g" /etc/hosts
 ---&gt; Running in 7c73dc473507
sed: cannot rename /etc/sedXZv0Yy: Device or resource busy</code></pre>
<p>What.</p>
<pre class="text"><code>$ vi Dockerfile
...
RUN sed "s/::1.*//g" /etc/hosts &gt; /etc/hosts-new && mv /etc/hosts-new /etc/hosts
...

$ docker build .
...
RUN sed "s/::1.*//g" /etc/hosts &gt; /etc/hosts-new && mv /etc/hosts-new /etc/hosts
 ---&gt; Running in d6b896f4fc9e
sed: cannot rename /etc/sedqYrfxO: Device or resource busy</code></pre>
<p>Double what.</p>
<p>Back to Google: <code><a href="https://www.google.com/search?q=docker edit hosts">docker edit hosts</a></code></p>
<p>Specifically: <a href="https://github.com/docker/docker/issues/1951">Unable to modify /etc/hosts file in a container #1951</a>. Looks like there was a fix that would let you edit <code>/etc/hosts</code> if you were in a container (that used to not be possible), but (because it's actually mounted rather than just a container file), it's non-trivial to edit it as part of a build.</p>
<p>All righty then.</p>
<p>That's about when I decided to listen to the Flask documentation:</p>
<blockquote>You can use the builtin server during development, but you should use a full deployment option for production applications. (Do not use the builtin development server in production.)</blockquote>
<p>All right. Not only is it what I'm actually supposed to be doing, but if I used CGI, I can avoid Flask trying to resolve <code>localhost</code> at all. I've worked with <a href="http://wiki.nginx.org/Main">nginx</a> before. Let's use that.</p>
<p>Picking some documentation from a hat, I decided to use <a href="https://uwsgi-docs.readthedocs.org/en/latest/">uWSGI</a> as the glue between nginx and Flask. Easy enough to install with pip (although I had to grab a C compiler from the apt package <code>build-essential</code>) and off we go.</p>
<p>First, a small <code>nginx</code> config:</p>
<pre class="nginx"><code>location / { try_files $uri @project; }
location @project {
    include uwsgi_params;
    uwsgi_pass unix:/tmp/uwsgi.sock;
}</code></pre>
<p>Then, to start it all up, a change to the <code>Dockerfile</code> <code>CMD</code>:</p>
<pre class="bash"><code>CMD uwsgi -s /tmp/uwsgi.sock -w project:app --chown-socket=www-data:www-data --enable-threads & \
    nginx -g 'daemon off;'</code></pre>
<p>That <code>--chown-socket</code> flag really drove me a bit batty. Basically, <code>uwsgi</code> was starting as the <code>root</code> user (within the Docker container). <code>nginx</code> was starting as <code>root</code>. But the <code>nginx</code> threads were not. They were starting as <code>www-data</code> and thus couldn't read the Unix socket between the two.</p>
<p>All righty then.</p>
<p>Let's go!</p>
<p>Starting successfully... And it's running. Not on the first try or even the 10th (I left out quite a bit of fumbling around tweaking flags), but eventually as was well in the world.</p>
<p>Push it out to AWS...</p>
<p>Health check passed.</p>
<p>Bam.</p>
<p>Awesome.</p>
<p>Now I not only have a neat little webapp, I have one that doesn't randomly decide to take forever on every other request or so.</p>
<p>If you're looking for the bare minimum <code>requirements.txt</code> and <code>Dockerfile</code> that I'm using (in addition to that <code>nginx</code> host configuration file above), here they are:</p>
<p><code>requirements.txt</code></p>
<pre class="text"><code>flask
flup6
uwsgi</code></pre>
<p><code>Dockerfile</code>:</p>
<pre class="text"><code>FROM ubuntu:14.04

RUN apt-get update && apt-get install -y build-essential nginx python3.4 python3.4-dev
RUN easy_install3 pip

WORKDIR /project

ADD requirements.txt /project/requirements.txt
RUN pip install -r requirements.txt

ADD . /project

ADD nginx /etc/nginx

CMD uwsgi -s /tmp/uwsgi.sock -w project:app --chown-socket=www-data:www-data --enable-threads & \
    nginx -g 'daemon off;'</code></pre>
<p>It's for moments like these that I do software. That little moment when everything comes together just right and it all just ... works.</p>]]></content></entry><entry><title>Parsing AWS instance data with jq</title><link href="http://blog.jverkamp.com/2015/04/01/parsing-aws-instance-data-with-jq" /><id>urn:uuid:db7917d7-1267-4fde-d9a4-c2d153f23979</id><updated>2015-04-01T00:00:00Z</updated><summary type="html"><![CDATA[<p>Semi-random amusing code snippet of the day:</p>
<pre class="bash"><code>aws ec2 describe-instances | jq &lt;&lt; EOF
    .[][].Instances[]
    | select(.Tags[]?.Value == "production")
    | .PrivateIpAddress
EOF</code></pre>
]]></summary><content type="html"><![CDATA[<p>Semi-random amusing code snippet of the day:</p>
<pre class="bash"><code>aws ec2 describe-instances | jq &lt;&lt; EOF
    .[][].Instances[]
    | select(.Tags[]?.Value == "production")
    | .PrivateIpAddress
EOF</code></pre>
<!--more-->
<p>Basically, it's combining the <a href="https://aws.amazon.com/cli/">AWS command line tools</a> and the excellent <a href="https://stedolan.github.io/jq/"><code>jq</code></a> tool for parsing JSON to extract a field from all instances with a particular tag on your AWS account (whatever account you have configured in your <code>~/.aws/</code> directory).</p>
<p>To describe it a little bit more, the data is structured as a list of <code>Instance</code> objects. The first line of the <code>jq</code> query loops over each instance object.</p>
<p>Next, each of those has zero or more <code>Tags</code> (the <code>[]?</code> is to not fail if the tag object is empty), with <code>Key</code> and <code>Value</code> entries. <code>select</code> is a new feature I hadn't seen before which will pass along an object if the condition holds. These are essentially equivalent:</p>
<pre class="text"><code> select(condition) </code></pre>
<pre class="text"><code> if condition then . else empty end </code></pre>
<p>After that, we extract a given field. In this particular case, I wanted IP addresses, but there are a bunch of other fields you can access. Here are a few other interesting ones:</p>
<ul>
    <li>AmiLaunchIndex</li>
    <li>Architecture</li>
    <li>ImageId</li>
    <li>InstanceId</li>
    <li>InstanceType</li>
    <li>LaunchTime</li>
    <li>PrivateDnsName</li>
    <li>PrivateIpAddress</li>
    <li>PublicDnsName</li>
    <li>PublicIpAddress</li>
    <li>SecurityGroups</li>
    <li>State</li>
    <li>SubnetId</li>
    <li>Tags</li>
</ul>
<p>The beauty of doing this directly in the shell is that you can then chain it to something else. For example, what if I wanted to log into every production server in turn and ask how much free disk space they have:</p>
<pre class="bash"><code>for IP in aws ec2 describe-instances | jq &lt;&lt; EOF
    .[][].Instances[]
    | select(.Tags[]?.Value == "production")
    | .PrivateIpAddress
EOF
do
    echo $IP
    ssh $IP du -h
    echo
done</code></pre>
<p>I'm really starting to admire the 'Do One Thing and Do It Well' philosophy of Unix and chaining things together.</p>]]></content></entry><entry><title>gif shrinkage with ImageMagick</title><link href="http://blog.jverkamp.com/2015/03/05/gif-shrinkage-with-imagemagick" /><id>urn:uuid:ca361209-13d0-9725-3b15-9d0d7f368a98</id><updated>2015-03-05T00:00:00Z</updated><summary type="html"><![CDATA[<p>I have a gif collection now. :)</p>
<p><a href="http://blog.jverkamp.com/2015/03/05/gif-shrinkage-with-imagemagick/dun-dun-dunnnnn.gif" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/03/05/gif-shrinkage-with-imagemagick/dun-dun-dunnnnn.gif" /></a></p>
]]></summary><content type="html"><![CDATA[<p>I have a gif collection now. :)</p>
<p><a href="http://blog.jverkamp.com/2015/03/05/gif-shrinkage-with-imagemagick/dun-dun-dunnnnn.gif" data-toggle="lightbox"><img src="http://blog.jverkamp.com/2015/03/05/gif-shrinkage-with-imagemagick/dun-dun-dunnnnn.gif" /></a></p>
<!--more-->
<p>One problem with gifs is that they tend to be somewhat sizable. To keep that at least a little under control, I've added a quick script to my <a href="http://blog.jverkamp.com/category/programming/by-topic/dotfiles">dotfiles</a> to trim all files passed on the command line to a maximum edge size of 256 pixels:</p>
<pre class="bash"><code>#!/bin/bash

tmpdir=&lt;code&gt;mktemp -d /tmp/shrink-gifs.XXXX&lt;/code&gt;
echo "$tmpdir"

for file in "$@"
do
  echo "$file"
  convert "$file" -alpha on -channel rgba -coalesce -resize 256x256 -layers OptimizeFrame -colors 64 "$tmpdir/$file"
  mv "$tmpdir/$file" "$file"
done</code></pre>
<p>Basically, I'm using the excellent <a href="http://www.imagemagick.org/">ImageMagick</a> software, specifically the <code>convert</code> utility. All of those flags are necessary since gifs have layers. This results in both a properly converted gif but also a somewhat optimized palette.</p>
<p>Also, we're using a temporary directory rather than using the in place version of <code>convert</code>: <code>mogrify</code>. For whatever reason, <code>mogrify</code> doesn't seem to work on gifs. So it goes.</p>
<p>As a side note, <code>identify</code> (another tool that comes with ImageMagick) is really useful. Give it an image and it will tell you how large it is, all on the command line.</p>
<p>This script (and all of my <a href="http://blog.jverkamp.com/category/programming/by-topic/dotfiles">dotfiles</a>) is available on GitHub: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/shrink-gifs">shrink-gifs</a></p>]]></content></entry><entry><title>ts: Timestamping stdout</title><link href="http://blog.jverkamp.com/2015/02/26/ts-timestamping-stdout" /><id>urn:uuid:43f98a4d-4ef7-1979-023a-32bf8724a10d</id><updated>2015-02-26T00:00:00Z</updated><summary type="html"><![CDATA[<p>Loving data as much as I do, I like to <a href="http://blog.jverkamp.com/category/programming/by-topic/optimization">optimize</a> things. To make sure I'm actually going the right way, it's useful to time things. While it's trivial in most languages to add timing, it's even easier if you don't have to.</p>
]]></summary><content type="html"><![CDATA[<p>Loving data as much as I do, I like to <a href="http://blog.jverkamp.com/category/programming/by-topic/optimization">optimize</a> things. To make sure I'm actually going the right way, it's useful to time things. While it's trivial in most languages to add timing, it's even easier if you don't have to.</p>
<!--more-->
<p>To that end, here is <code>ts</code>, a tool for adding timestamps to each line of <code>stdin</code>:</p>
<pre class="python"><code>#!/usr/bin/env python3

import sys
import time

def stamp(line):
    now = time.strftime("[%Y-%m-%d %H:%M:%S]", time.localtime())
    sys.stdout.write('{0} {1}\n'.format(now, line.strip('\n')))
    sys.stdout.flush()

stamp('--- &lt;ts&gt; ---')

for line in sys.stdin:
    stamp(line)

stamp('--- &lt;/ts&gt; ---')</code></pre>
<p>For example:</p>
<pre class="bash"><code>$ python long-running-script.py | ts

[2015-02-25 17:05:35] --- &lt;ts&gt; ---
[2015-02-25 17:05:35] things
[2015-02-25 17:05:43] stuff
[2015-02-25 17:05:53] all done
[2015-02-25 17:05:53] --- &lt;/ts&gt; ---</code></pre>
<p>Whee!</p>
<p>If you'd like to download this or any of my other <a href="http://blog.jverkamp.com/category/programming/by-topic/dotfiles">dotfiles</a>, you can do so on on GitHub: <a href="https://github.com/jpverkamp/dotfiles/blob/master/bin/ts">ts</a>.</p>]]></content></entry></feed>