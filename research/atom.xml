<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Research on jverkamp.com</title><link>https://blog.jverkamp.com/research/</link><description>Recent content in Research on jverkamp.com</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 17 Aug 2013 00:00:14 +0000</lastBuildDate><atom:link href="https://blog.jverkamp.com/research/atom.xml" rel="self" type="application/rss+xml"/><item><title>USENIX 2013 - Day 3</title><link>https://blog.jverkamp.com/2013/08/17/usenix-2013-day-3/</link><pubDate>Sat, 17 Aug 2013 00:00:14 +0000</pubDate><guid>https://blog.jverkamp.com/2013/08/17/usenix-2013-day-3/</guid><description>&lt;p>Today&amp;rsquo;s the third and final day. Since I had to fly out in the afternoon, I didn&amp;rsquo;t get a chance to go to as many talks today, but so it goes. There was really interesting talk that I&amp;rsquo;m sad to have missed (&lt;a href="https://www.usenix.org/conference/usenixsecurity13/dismantling-megamos-crypto-wirelessly-lockpicking-vehicle-immobilizer">Dismantling Megamos Crypto: Wirelessly Lockpicking a Vehicle Immobilizer&lt;/a>) but it&amp;rsquo;ll be nice to be home. Here are the talks that I did make it to and found particularly interesting though:&lt;/p></description></item><item><title>USENIX 2013 - Day 2</title><link>https://blog.jverkamp.com/2013/08/16/usenix-2013-day-2/</link><pubDate>Fri, 16 Aug 2013 00:00:33 +0000</pubDate><guid>https://blog.jverkamp.com/2013/08/16/usenix-2013-day-2/</guid><description>&lt;p>Day 2/3. There&amp;rsquo;s really not much more to say, so how about getting right to the interesting talks:&lt;/p></description></item><item><title>USENIX 2013 - Day 1</title><link>https://blog.jverkamp.com/2013/08/15/usenix-2013-day-1/</link><pubDate>Thu, 15 Aug 2013 00:00:30 +0000</pubDate><guid>https://blog.jverkamp.com/2013/08/15/usenix-2013-day-1/</guid><description>&lt;p>Perhaps unsurprisingly, there were fewer papers today that I was particularly interested&amp;ndash;given that FOCI is directly related to my area of research. Still, computer security is a very useful field and one that I&amp;rsquo;m keen to learn more about. I only went to two of the sessions today (it&amp;rsquo;s always unfortunate when they run two interesting sessions at the same time) and here are some of the talks I found particularly interesting:&lt;/p></description></item><item><title>FOCI 2013</title><link>https://blog.jverkamp.com/2013/08/14/foci-2013/</link><pubDate>Wed, 14 Aug 2013 00:00:30 +0000</pubDate><guid>https://blog.jverkamp.com/2013/08/14/foci-2013/</guid><description>&lt;p>Today was the &lt;a href="https://blog.jverkamp.com/2013/08/13/usenix/foci-2013-five-incidents-one-theme-twitter-spam-as-a-weapon-to-drown-voices-of-protest/">Five incidents, one theme&lt;/a>. Here are a few short summaries of the other papers that are particularly related to my own interests:&lt;/p></description></item><item><title>Usenix/FOCI 2013 - Five incidents, one theme: Twitter spam as a weapon to drown voices of protest</title><link>https://blog.jverkamp.com/2013/08/13/usenix/foci-2013-five-incidents-one-theme-twitter-spam-as-a-weapon-to-drown-voices-of-protest/</link><pubDate>Tue, 13 Aug 2013 14:00:03 +0000</pubDate><guid>https://blog.jverkamp.com/2013/08/13/usenix/foci-2013-five-incidents-one-theme-twitter-spam-as-a-weapon-to-drown-voices-of-protest/</guid><description>Another year, another Usenix Security Symposium. Like last year, I&amp;rsquo;ll be presenting a paper at FOCI1 (Free and Open Communications on the Internet) entitled: Five incidents, one theme: Twitter spam as a weapon to drown voices of protest:
Social networking sites, such as Twitter and Facebook, have become an impressive force in the modern world with user bases larger than many individual countries. With such influence, they have become important in the process of worldwide politics.</description></item><item><title>ISMA 2013 AIMS-5 - DNS Based Censorship</title><link>https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/</link><pubDate>Sat, 09 Feb 2013 15:00:06 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/09/isma-2013-aims-5-dns-based-censorship/</guid><description>I gave a presentation about research that I&amp;rsquo;m just starting out studying DNS-based censorship in specific around the world. In particularly, preliminary findings in China have confirmed that the Great Firewall is responding via packet injection to many queries for either Facebook or Twitter (among others). Interestingly, the pool of IPs that they return is consistent yet none of the IPs seem to resolve to anything interesting. In addition, there is fallout in South Korea where some percentage of packets go through China and thus have the same behaviors.</description></item><item><title>AIMS-5 - Day 3</title><link>https://blog.jverkamp.com/2013/02/09/aims-5-day-3/</link><pubDate>Sat, 09 Feb 2013 14:00:02 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/09/aims-5-day-3/</guid><description>&lt;p>Yesterday was the third and final day of AIMS-5. With the main topic being &lt;em>Detection of Censorship, Filtering, and Outages&lt;/em>, many of these talks were much more in line with what I know and what I&amp;rsquo;m working on. I gave my presentation as well, you can see it (along with a link to my slides) down below.&lt;/p></description></item><item><title>AIMS-5 - Day 2</title><link>https://blog.jverkamp.com/2013/02/08/aims-5-day-2/</link><pubDate>Fri, 08 Feb 2013 14:00:06 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/08/aims-5-day-2/</guid><description>&lt;p>Today&amp;rsquo;s agenda had discussions on Mobile Measurements and IPv6 Annotations, none of which are areas that I find myself particularly interested in. Still, I did learn a few things.&lt;/p></description></item><item><title>AIMS-5 - Workshop on Active Internet Measurements</title><link>https://blog.jverkamp.com/2013/02/07/aims-5-workshop-on-active-internet-measurements/</link><pubDate>Thu, 07 Feb 2013 14:00:41 +0000</pubDate><guid>https://blog.jverkamp.com/2013/02/07/aims-5-workshop-on-active-internet-measurements/</guid><description>&lt;p>Yesterday was the first of three days for the fifth annual &lt;a href="https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/">ISC/CAIDA Workshop&lt;/a> I went to in Baltimore back in October at least, but even the ones that weren&amp;rsquo;t have still been interesting.&lt;/p>
&lt;p>I&amp;rsquo;ll be presenting on Friday and I&amp;rsquo;ll share my slides when I get that far (they aren&amp;rsquo;t actually finished yet). I&amp;rsquo;ll be talking about new work that I&amp;rsquo;m just getting off the ground focusing specifically on DNS-based censorship. There is a lot of interesting ground to cover there and this should be only the first in a series of updates about that work (I hope).&lt;/p></description></item><item><title>Scanning for DNS resolvers</title><link>https://blog.jverkamp.com/2013/01/31/scanning-for-dns-resolvers/</link><pubDate>Thu, 31 Jan 2013 14:00:00 +0000</pubDate><guid>https://blog.jverkamp.com/2013/01/31/scanning-for-dns-resolvers/</guid><description>&lt;p>For a research project I&amp;rsquo;m working on, it has become necessary to scan potentially large &lt;a href="https://en.wikipedia.org/wiki/Cidr">IPv4 prefixes&lt;/a> in order to find any &lt;a href="https://en.wikipedia.org/wiki/DNS%20resolver">DNS revolvers&lt;/a> that I can and classify them as either open (accepting queries from anyone) or closed.&lt;/p>
&lt;p>Disclaimer: This is a form of &lt;a href="https://en.wikipedia.org/wiki/port%20scanning">port scanning&lt;/a> and thus has associated ethical and legal considerations. Use it at your own risk. &lt;/p>
&lt;p>This project is available on GitHub: &lt;a href="https://github.com/jpverkamp/dnsscan" title="GitHub: jpverkamp: dnsscan">jpverkamp/dnsscan&lt;/a>&lt;/p></description></item><item><title>ISC/CAIDA Workshop</title><link>https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/</link><pubDate>Mon, 22 Oct 2012 23:00:58 +0000</pubDate><guid>https://blog.jverkamp.com/2012/10/22/isc/caida-workshop/</guid><description>&lt;p>I&amp;rsquo;ve spent the day in Baltimore at the &lt;a title="ISC/CAIDA Workshop" href="http://rsf.isc.org/events/data-collab-workshop-2-2012/">ISC/CAIDA Data Collaboration Workshop&lt;/a> learning about and presenting about all things DNS related. It&amp;rsquo;s not really the sort of thing that my PhD work is focusing on but it&amp;rsquo;s still interesting.&lt;/p></description></item><item><title>Usenix/FOCI 2012 - Inferring Mechanics of Web Censorship Around the World</title><link>https://blog.jverkamp.com/2012/08/06/usenix/foci-2012-inferring-mechanics-of-web-censorship-around-the-world/</link><pubDate>Mon, 06 Aug 2012 13:00:28 +0000</pubDate><guid>https://blog.jverkamp.com/2012/08/06/usenix/foci-2012-inferring-mechanics-of-web-censorship-around-the-world/</guid><description>For the next week or so, I&amp;rsquo;ll be in Seattle attending the Usenix Security Symposium and specifically the FOCI workshop. Why? Because I&amp;rsquo;m presenting a paper at FOCI.
Entitled Inferring Mechanics of Web Censorship Around the World, here&amp;rsquo;s the abstract:
While mechanics of Web censorship in China are well studied, those of other countries are less understood. Through a combination of personal contacts and Planet-Lab nodes, we conduct experiments to explore the mechanics of Web censorship in 11 countries around the world, including China.</description></item><item><title>Facebot: An Undiscoverable Botnet Based on Treasure Hunting Social Networks</title><link>https://blog.jverkamp.com/2011/08/17/facebot-an-undiscoverable-botnet-based-on-treasure-hunting-social-networks/</link><pubDate>Wed, 17 Aug 2011 14:00:14 +0000</pubDate><guid>https://blog.jverkamp.com/2011/08/17/facebot-an-undiscoverable-botnet-based-on-treasure-hunting-social-networks/</guid><description>Co-authors: Parag Malshe, Minaxi Gupta, and Chris Dunn
Abstract: Popular botnets earn millions of dollars for their operators by enabling many types of cyberfraud activities, including spam and phishing. Current and past botnet architectures revolve around the idea of bots communicating with their masters to carry out their functionality. Given that many take-down eorts leverage this feature, future botnet architectures may evolve to overcome this limitation. In order to enable pro-active defenses against such botnets, in this paper we design a botnet whose bots never explicitly communicate with their master.</description></item><item><title>AudioVision: A Stereophonic Analogue to Visual Systems</title><link>https://blog.jverkamp.com/2010/12/13/audiovision-a-stereophonic-analogue-to-visual-systems/</link><pubDate>Mon, 13 Dec 2010 14:00:56 +0000</pubDate><guid>https://blog.jverkamp.com/2010/12/13/audiovision-a-stereophonic-analogue-to-visual-systems/</guid><description>Abstract: AudioVision is designed to take a visual representation of the world&amp;ndash;inthe form form of one or more video feeds&amp;ndash;and convert it into a related stereophonic audio representation. With such a representation, it should be possible for someone who has minimal or no use of their visual system to avoid obstacles using their sense of hearing rather than vision. To this end, several different vision algorithms, including single and multiple image disparity, disparity from motion, and optical flow were investigated.</description></item><item><title>FLAIRS 2010 - Augmenting n-gram Based Authorship Attribution With Neural Networks</title><link>https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/</link><pubDate>Fri, 21 May 2010 14:00:23 +0000</pubDate><guid>https://blog.jverkamp.com/2010/05/21/flairs-2010-augmenting-n-gram-based-authorship-attribution-with-neural-networks/</guid><description>Co-authors: Michael Wollowski, and Maki Hirotani
Abstract: While using statistical methods to determine authorship attribution is not a new idea and neural networks have been applied to a number of statistical problems, the two have not often been used together. We show that the use of articial neural networks, specically self-organizing maps, combined with n-grams provides a success rate on the order of previous work with purely statistical methods. Using a collection of documents including the works of Shakespeare, William Blake, and the King James Version of the Bible, we were able to demonstrate classication of documents into individual groups.</description></item><item><title>AnnGram - nGrams vs Words</title><link>https://blog.jverkamp.com/2010/03/17/anngram-ngrams-vs-words/</link><pubDate>Wed, 17 Mar 2010 05:05:37 +0000</pubDate><guid>https://blog.jverkamp.com/2010/03/17/anngram-ngrams-vs-words/</guid><description>&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;p>For another comparison, I&amp;rsquo;ve been looking for a way to replace the nGrams with another way of turning a document into a vector.  Based on word frequency instead of nGrams, I&amp;rsquo;ve run a number of tests to see how the accuracy and speed of the algorithm compares for the two.&lt;/p>
&lt;p>&lt;strong>nGrams&lt;/strong>&lt;/p>
&lt;figure>&lt;img src="https://blog.jverkamp.com/embeds/2010/SOM-ngram.png"/>
&lt;/figure>
&lt;p>I still intend to look into why the Tragedy of Macbeth does not stay with the rest of Shakespeare&amp;rsquo;s plays.  I still believe that it is because portions of it were possible written by another author.&lt;/p></description></item><item><title>AnnGram vs k-means</title><link>https://blog.jverkamp.com/2010/02/10/anngram-vs-k-means/</link><pubDate>Wed, 10 Feb 2010 04:05:32 +0000</pubDate><guid>https://blog.jverkamp.com/2010/02/10/anngram-vs-k-means/</guid><description>Overview
As a set of benchmarks to test whether or not the new AnnGram algorithm is actually working correctly, I&amp;rsquo;ve been trying to come up with different yet similar methods to compare it too. Primarily, there are two possibilities:
Replace the nGram vectors with another form Process the nGrams using something other than Self-Organizing Maps I&amp;rsquo;m still looking through the related literature to decide if there is some way to use something other than the nGrams to feed into the SOM; however, I haven&amp;rsquo;t been having any luck.</description></item><item><title>AnnGram - Self-Organizing Map GUI</title><link>https://blog.jverkamp.com/2010/02/03/anngram-self-organizing-map-gui/</link><pubDate>Wed, 03 Feb 2010 05:05:20 +0000</pubDate><guid>https://blog.jverkamp.com/2010/02/03/anngram-self-organizing-map-gui/</guid><description>&lt;p>They say a picture is worth a thousand words:&lt;/p>
&lt;p>&lt;strong>One Thousand Words&lt;/strong>&lt;/p>
&lt;figure>&lt;img src="https://blog.jverkamp.com/embeds/2010/som-results-11.png"/>
&lt;/figure></description></item><item><title>AnnGram - New GUI</title><link>https://blog.jverkamp.com/2010/01/28/anngram-new-gui/</link><pubDate>Thu, 28 Jan 2010 05:05:36 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/28/anngram-new-gui/</guid><description>&lt;p>The old GUI framework just wasn&amp;rsquo;t working out (so far as adding new features went).  So, long story short, I&amp;rsquo;ve switched GUI layout.&lt;/p></description></item><item><title>AnnGram - Neural Network Progress</title><link>https://blog.jverkamp.com/2010/01/21/anngram-neural-network-progress/</link><pubDate>Thu, 21 Jan 2010 05:05:19 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/21/anngram-neural-network-progress/</guid><description>&lt;p>&lt;a href="https://blog.jverkamp.com/2010/01/12/anngram-neuralnetwork-library/">As expected&lt;/a>, I&amp;rsquo;ve decided to change libraries from the** **&lt;a href="https://blog.jverkamp.com/2010/01/13/anngram-initial-ann-results/">poor results with the original tests&lt;/a> may have been a direct results of a misunderstanding with the code base.  I think that the layers were not being hooked up correctly, resulting in low/random values.&lt;/p></description></item><item><title>AnnGram - Ideas for improvement</title><link>https://blog.jverkamp.com/2010/01/15/anngram-ideas-for-improvement/</link><pubDate>Fri, 15 Jan 2010 05:05:30 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/15/anngram-ideas-for-improvement/</guid><description>&lt;p>After my meeting yesterday with my thesis advisers, I have a number of new ideas to try to improve the efficiency of the neural networks.  The most promising of those are described below.&lt;/p>
&lt;p>&lt;strong>Sliding window&lt;/strong>&lt;/p>
&lt;p>The first idea was to replace the idea of applying the most common frequencies directly with a sliding window (almost a directly analogue to the nGrams themselves).  The best way that we could come up to implent this would be to give the neural networks some sort of memory which brought up recurring networks (see below).&lt;/p></description></item><item><title>AnnGram - Initial ANN Results</title><link>https://blog.jverkamp.com/2010/01/13/anngram-initial-ann-results/</link><pubDate>Wed, 13 Jan 2010 05:05:14 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/13/anngram-initial-ann-results/</guid><description>&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;p>For now, I&amp;rsquo;ve chosen to work with &lt;a href="http://franck.fleurey.free.fr/NeuralNetwork/">C# Neural network&lt;/a> library.  It was the easiest to get off the ground and running, so it seemed like a good place to start.&lt;/p></description></item><item><title>AnnGram - NeuralNetwork Library</title><link>https://blog.jverkamp.com/2010/01/12/anngram-neuralnetwork-library/</link><pubDate>Tue, 12 Jan 2010 05:05:54 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/12/anngram-neuralnetwork-library/</guid><description>&lt;p>I&amp;rsquo;ve been looking for a good Neural Network library to use with the AnnGram project and so far I&amp;rsquo;ve come across a couple of possibilities:&lt;/p>
&lt;p>&lt;a href="http://franck.fleurey.free.fr/NeuralNetwork/">&lt;strong>C# Neural network library&lt;/strong>&lt;/a>&lt;/p>
&lt;p>The top link on Google was an aptly named C# Neural network library.  Overall, it looks clean and easy to use and is licensed under the &lt;a href="http://www.gnu.org/licenses/gpl.html">GPL&lt;/a>, so should work well for my needs.   The framework has two types of training methods: genetic algorithms and backward propagation.  In addition, there are at least three different activation functions included: linear, signmoid, and heaviside functions.  The main problem with this framework is the spare documentation.  The only that I&amp;rsquo;ve been able to find so far is a generated API reference and a few examples (using their included GUI framework).&lt;/p></description></item><item><title>AnnGram - Initial GUI</title><link>https://blog.jverkamp.com/2010/01/05/anngram-initial-gui/</link><pubDate>Tue, 05 Jan 2010 05:05:55 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/05/anngram-initial-gui/</guid><description>&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;p>Basically, I got tired of modifying the command line every time I wanted to test new values.  To that end, I spent a small bit of time coding up a GUI to make further experiments easier.&lt;/p></description></item><item><title>AnnGram - Cosine Distance</title><link>https://blog.jverkamp.com/2010/01/01/anngram-cosine-distance/</link><pubDate>Fri, 01 Jan 2010 05:05:00 +0000</pubDate><guid>https://blog.jverkamp.com/2010/01/01/anngram-cosine-distance/</guid><description>&lt;p>&lt;strong>Overview&lt;/strong>&lt;/p>
&lt;p>The first algorithm that I&amp;rsquo;ve chosen to implement is a simple cosine difference between the n-gram vectors.  This was the first method used in multiple of the papers that I&amp;rsquo;ve read and it seems like a good benchmark.&lt;/p>
&lt;p>Essentially, this method gives the similarity of two n-gram documents (either Documents or Authors) as an angle ranging from 0 (identical documents) to &lt;span class="latex-inline">\pi/2&lt;/span>
(completely different documents).  Documents written by the same author should have the lowest values.&lt;/p></description></item><item><title>AnnGram - Framework</title><link>https://blog.jverkamp.com/2009/12/29/anngram-framework/</link><pubDate>Tue, 29 Dec 2009 05:05:28 +0000</pubDate><guid>https://blog.jverkamp.com/2009/12/29/anngram-framework/</guid><description>&lt;p>&lt;strong>Document Framework&lt;/strong>&lt;/p>
&lt;p>The first portion of the framework that it was necessary to code was the ability to load documents.  To reduce the load on the processor when first loading the document, only a minimal amount of computation is done.  Further computation is pushed off until necessary.&lt;/p>
&lt;p>To avoid duplicating work, the n-grams are stored using &lt;a href="https://en.wikipedia.org/wiki/memoization">memoization&lt;/a>.  The basic idea is that when a function (in this case, a particular length of n-gram) is first requested, the calculation is done and the result is stored in memory.  During any future calls, the cached result is directly returned, greatly increasing speed at the cost of memory.  Luckily, modern computers have more than sufficient memory for the task at hand.&lt;/p></description></item><item><title>AnnGram - Overview</title><link>https://blog.jverkamp.com/2009/12/21/anngram-overview/</link><pubDate>Mon, 21 Dec 2009 05:05:34 +0000</pubDate><guid>https://blog.jverkamp.com/2009/12/21/anngram-overview/</guid><description>&lt;p>&lt;strong>Basic Premise&lt;/strong>&lt;/p>
&lt;p>For my senior thesis at Rose-Hulman Institute of Technology, I am attempting to combine the fields of Computational Linguistics and Artificial Intelligence in a new and useful manner.  Specifically, I am planning on making use of Artificial Neural Networks to enhance the performance of n-gram based document classification.  Over the next few months, I will be updating this category with background and information and further progress.&lt;/p>
&lt;p>First, I&amp;rsquo;ll start with some basic background information.&lt;/p></description></item><item><title>SIGCSE 2009 - RASQL Query Grammar Conversion Project</title><link>https://blog.jverkamp.com/2009/03/07/sigcse-2009-rasql-query-grammar-conversion-project/</link><pubDate>Sat, 07 Mar 2009 14:00:52 +0000</pubDate><guid>https://blog.jverkamp.com/2009/03/07/sigcse-2009-rasql-query-grammar-conversion-project/</guid><description>Abstract: While variety of language structures, there still exists room for an extensible grammatical structure based through the implementation of such a grammar, translations between languages can be made relatively easy using preexisting tools such as XSLT.</description></item><item><title>AudioVision Update</title><link>https://blog.jverkamp.com/2009/02/26/audiovision-update/</link><pubDate>Thu, 26 Feb 2009 08:05:58 +0000</pubDate><guid>https://blog.jverkamp.com/2009/02/26/audiovision-update/</guid><description>The quarter is ending and so is my current work on AudioVision. I have successfully managed to convert a basic two camera view into stereophonic 3d audio, using OpenCV (C++). I hope to continue this work some time in the future, so keep an eye out here for any future developments.</description></item><item><title>AudioVision Update</title><link>https://blog.jverkamp.com/2009/01/19/audiovision-update/</link><pubDate>Mon, 19 Jan 2009 05:05:26 +0000</pubDate><guid>https://blog.jverkamp.com/2009/01/19/audiovision-update/</guid><description>&lt;p>Since deciding that I cannot use MATLAB because of the additional addons necessary to use webcams, I have been deciding between C# and Python as the next language to try. I&amp;rsquo;ve settled on Python for the time being, using &lt;a href="http://videocapture.sourceforge.net/">VideoCapture&lt;/a> to connect to the webcams and &lt;a href="http://numpy.scipy.org/">Numpy&lt;/a> to process the data. It turns out that Python + VideoCapture + Numpy is actually rather similar in functionality and syntax to MATLAB with its image processing library.&lt;/p></description></item><item><title>AudioVision Update</title><link>https://blog.jverkamp.com/2009/01/05/audiovision-update/</link><pubDate>Mon, 05 Jan 2009 08:05:51 +0000</pubDate><guid>https://blog.jverkamp.com/2009/01/05/audiovision-update/</guid><description>The original plan to use Make3D for the visual depth determination has mostly fallen through, partially because it has several dependencies that I cannot get to build correctly and partially because it is written in a combination of C and MATLAB. I have nothing against either of these languages; however, I do not have the addons necessary for MATLAB to connect to a webcam.
As such, I&amp;rsquo;ve decided to switch from a monocular vision algorithm to a more traditional stereo vision algorithm.</description></item><item><title>AudioVision Overview</title><link>https://blog.jverkamp.com/2008/12/19/audiovision-overview/</link><pubDate>Fri, 19 Dec 2008 08:05:02 +0000</pubDate><guid>https://blog.jverkamp.com/2008/12/19/audiovision-overview/</guid><description>&lt;p>I am taking an independent study course this winter in Image Recognition / Computer Vision. The primary goal of my independent study is to look into determining depth information from video feed(s) in real time and then representing that depth information using a 3D audio map (headphones).&lt;/p></description></item></channel></rss>